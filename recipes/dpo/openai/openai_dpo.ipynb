{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49ee840c-d247-4c7e-ab3f-d31cc7dd1fef",
   "metadata": {},
   "source": [
    "# OpenAI Supervised Fine-Tuning using Direct Preference Optimization (DPO)\n",
    "\n",
    "This recipe allows TensorZero users to fine-tune OpenAI models using Direct Preference Optimization (DPO) and their own data. Since TensorZero automatically logs all inferences and feedback, it is straightforward to fine-tune a model using your own data and any prompt you want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899c588-7265-4589-a636-c595d818c81b",
   "metadata": {},
   "source": [
    "To get started:\n",
    "\n",
    "- Set the `TENSORZERO_CLICKHOUSE_URL` environment variable. For example: `TENSORZERO_CLICKHOUSE_URL`=`\"http://chuser:chpassword@localhost:8123/tensorzero\"`\n",
    "- Set the `OPENAI_API_KEY` environment variable.\n",
    "- Update the following parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26cfcec-a2dd-4f89-b3df-5f8623002e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"../../../examples/data-extraction-ner/config/tensorzero.toml\"\n",
    "\n",
    "FUNCTION_NAME = \"extract_entities\"\n",
    "\n",
    "# The name of the variant to use to grab the templates used for fine-tuning\n",
    "TEMPLATE_VARIANT_NAME = \"gpt_4o_mini\"  # It's OK that this variant uses a different model than the one we're fine-tuning\n",
    "\n",
    "# Fraction of the data to use for validation\n",
    "VAL_FRACTION = 0.2\n",
    "\n",
    "# Maximum number of samples to use for fine-tuning\n",
    "MAX_SAMPLES = 1000\n",
    "\n",
    "#  Model \"gpt-4o-2024-08-06\" is to our knowledge the only base model supported for this method.\n",
    "#  You can can use the base model as below or fine-tunes derived from it for this recipe.\n",
    "MODEL_NAME = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb9147-8dfa-4a1a-82b7-6fa994e1f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import toml\n",
    "from clickhouse_connect import get_client\n",
    "from IPython.display import clear_output\n",
    "from minijinja import Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fe2dbd-edb8-4630-a91e-5a9aa754f237",
   "metadata": {},
   "source": [
    "Load the TensorZero configuration file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69892de5-ec2a-401d-a674-ac5dcd11f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(CONFIG_PATH)\n",
    "\n",
    "assert config_path.exists(), f\"{CONFIG_PATH} does not exist\"\n",
    "assert config_path.is_file(), f\"{CONFIG_PATH} is not a file\"\n",
    "\n",
    "with config_path.open(\"r\") as f:\n",
    "    config = toml.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91982a3b-cdcf-4b35-a3b3-683bce76b16f",
   "metadata": {},
   "source": [
    "Ensure that the function and variant being fine-tuned are present in the provided config.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0a41e-871d-45c1-a05e-02a02665d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"functions\" in config, \"No `[functions]` section found in config\"\n",
    "assert \"variants\" in config[\"functions\"][FUNCTION_NAME], (\n",
    "    f\"No variants section found for function `{FUNCTION_NAME}`\"\n",
    ")\n",
    "assert TEMPLATE_VARIANT_NAME in config[\"functions\"][FUNCTION_NAME][\"variants\"], (\n",
    "    f\"No variant named `{TEMPLATE_VARIANT_NAME}` found in function `{FUNCTION_NAME}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e11f8-f24f-430e-97a3-78edd815c9aa",
   "metadata": {},
   "source": [
    "Retrieve the configuration for the variant with the templates we will use for fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f71686-f62c-4df2-99f0-fb2b48269926",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_type = config[\"functions\"][FUNCTION_NAME][\"type\"]\n",
    "variant = config[\"functions\"][FUNCTION_NAME][\"variants\"][TEMPLATE_VARIANT_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab21e02-6584-4422-abb0-ba7400d26c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {}\n",
    "\n",
    "if \"assistant_template\" in variant:\n",
    "    assistant_template_path = config_path.parent / variant[\"assistant_template\"]\n",
    "    with assistant_template_path.open(\"r\") as f:\n",
    "        templates[\"assistant\"] = f.read()\n",
    "\n",
    "if \"system_template\" in variant:\n",
    "    system_template_path = config_path.parent / variant[\"system_template\"]\n",
    "    with system_template_path.open(\"r\") as f:\n",
    "        templates[\"system\"] = f.read()\n",
    "\n",
    "if \"user_template\" in variant:\n",
    "    user_template_path = config_path.parent / variant[\"user_template\"]\n",
    "    with user_template_path.open(\"r\") as f:\n",
    "        templates[\"user\"] = f.read()\n",
    "\n",
    "env = Environment(templates=templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc95bd3a-3fdc-484c-8f1d-3a3776f2c6d0",
   "metadata": {},
   "source": [
    "Initialize the ClickHouse client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f03fce-dd4a-42bc-8e0b-47d12f767f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"TENSORZERO_CLICKHOUSE_URL\" in os.environ, (\n",
    "    \"TENSORZERO_CLICKHOUSE_URL environment variable not set\"\n",
    ")\n",
    "\n",
    "clickhouse_client = get_client(dsn=os.environ[\"TENSORZERO_CLICKHOUSE_URL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd8383-bedf-4564-8db4-1581e110b201",
   "metadata": {},
   "source": [
    "Determine the ClickHouse table name for the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca296a-1ee8-4ace-97e4-d7c9dd33e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_table_name = {\"json\": \"JsonInference\"}.get(function_type)\n",
    "\n",
    "if inference_table_name is None:\n",
    "    raise ValueError(f\"Unsupported function type: {function_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29099c61-d84c-4008-abc1-1d31615c83d2",
   "metadata": {},
   "source": [
    "Query ClickHouse for inference, feedback, and metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53976e1b-ee2a-4308-9372-a57965698121",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT\n",
    "    i.variant_name AS variant,\n",
    "    i.episode_id AS episode_id,\n",
    "    i.input AS input,\n",
    "    i.output AS non_preferred_output,\n",
    "    d.value AS preferred_output\n",
    "FROM \n",
    "    {inference_table_name} AS i\n",
    "INNER \n",
    "    JOIN DemonstrationFeedback AS d ON i.id = d.inference_id\n",
    "WHERE \n",
    "    (i.function_name = %(function_name)s)\n",
    "LIMIT %(max_samples)s\n",
    "\"\"\"\n",
    "\n",
    "params = {\n",
    "    \"max_samples\": MAX_SAMPLES,\n",
    "    \"function_name\": FUNCTION_NAME,\n",
    "}\n",
    "\n",
    "df = clickhouse_client.query_df(query, params)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c1620-e850-4fd7-a3d1-d005623f4f51",
   "metadata": {},
   "source": [
    "OpenAI requires the fine-tuning data (for DPO) to be structured in this [format](https://platform.openai.com/docs/guides/fine-tuning#preference)\n",
    "\n",
    "```\n",
    "{\n",
    "  \"input\": {\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"<string>\"\n",
    "      }\n",
    "    ],\n",
    "    \"tools\": [],\n",
    "    \"parallel_tool_calls\": true\n",
    "  },\n",
    "  \"preferred_output\": [\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"<string>\"\n",
    "    }\n",
    "  ],\n",
    "  \"non_preferred_output\": [\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"<string>\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6621131-bd25-42a1-8190-713415346c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_message(content: List[Dict[str, Any]], role: str) -> str:\n",
    "    assert role in [\"user\", \"assistant\"], f\"Invalid role: {role}\"\n",
    "\n",
    "    if len(content) != 1:\n",
    "        raise ValueError(f\"Message must have exactly one content block: {content}\")\n",
    "\n",
    "    if content[0][\"type\"] != \"text\":\n",
    "        raise ValueError(f\"Content block must be of the type text: {content}\")\n",
    "\n",
    "    content = content[0][\"value\"]\n",
    "\n",
    "    if isinstance(content, str):\n",
    "        return content\n",
    "    else:\n",
    "        return env.render_template(role, **content)\n",
    "\n",
    "\n",
    "def render_output_message(output):\n",
    "    if function_type == \"chat\":\n",
    "        if len(output) != 1:\n",
    "            raise ValueError(f\"Output {output} must have exactly one content block\")\n",
    "        if output[0][\"type\"] != \"text\":\n",
    "            raise ValueError(f\"Output {output} must be a text block\")\n",
    "        return {\"role\": \"assistant\", \"content\": output[0][\"text\"]}\n",
    "    elif function_type == \"json\":\n",
    "        return {\"role\": \"assistant\", \"content\": output[\"raw\"]}\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported function type: {function_type}\")\n",
    "\n",
    "\n",
    "def sample_to_openai_messages(sample) -> List[Dict[str, str]]:\n",
    "    function_input = json.loads(sample[\"input\"])\n",
    "\n",
    "    result = {\n",
    "        \"input\": {\"messages\": [], \"tools\": [], \"parallel_tool_calls\": True},\n",
    "        \"preferred_output\": [],\n",
    "        \"non_preferred_output\": [],\n",
    "    }\n",
    "\n",
    "    # Add the system message to the rendered messages\n",
    "    # If there is data passed in or a system template there must be a system message\n",
    "    system = function_input.get(\"system\", {})\n",
    "    if len(system) > 0 or system_template_path:\n",
    "        if system_template_path:\n",
    "            system_message = env.render_template(\"system\", **system)\n",
    "            result[\"input\"][\"messages\"].append(\n",
    "                {\"role\": \"system\", \"content\": system_message}\n",
    "            )\n",
    "        else:\n",
    "            result[\"input\"][\"messages\"].append(\n",
    "                {\"role\": \"system\", \"content\": system_message}\n",
    "            )\n",
    "\n",
    "    # Add the input messages to the rendered messages\n",
    "    for message in function_input[\"messages\"]:\n",
    "        rendered_message = render_message(message[\"content\"], message[\"role\"])\n",
    "        result[\"input\"][\"messages\"].append(\n",
    "            {\"role\": message[\"role\"], \"content\": rendered_message}\n",
    "        )\n",
    "\n",
    "    # Add the demonstration (preferred output)\n",
    "    preferred_output = json.loads(sample[\"preferred_output\"])\n",
    "    result[\"preferred_output\"].append(render_output_message(preferred_output))\n",
    "\n",
    "    # Add the inference output (non-preferred output)\n",
    "    non_preferred_output = json.loads(sample[\"non_preferred_output\"])\n",
    "    result[\"non_preferred_output\"].append(render_output_message(non_preferred_output))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "df[\"openai_messages\"] = df.apply(sample_to_openai_messages, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de02989d",
   "metadata": {},
   "source": [
    "Split data into training and validation sets for fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e227007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique episode_ids\n",
    "unique_episode_ids = df[\"episode_id\"].unique()\n",
    "\n",
    "# Shuffle the unique episode_ids\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_episode_ids)\n",
    "\n",
    "# Calculate the split index for episode_ids\n",
    "split_index = int(len(unique_episode_ids) * (1 - VAL_FRACTION))\n",
    "\n",
    "# Split the episode_ids into training and validation sets\n",
    "train_episode_ids = unique_episode_ids[:split_index]\n",
    "val_episode_ids = unique_episode_ids[split_index:]\n",
    "\n",
    "# Create training and validation DataFrames based on episode_ids\n",
    "train_df = df[df[\"episode_id\"].isin(train_episode_ids)]\n",
    "val_df = df[df[\"episode_id\"].isin(val_episode_ids)]\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Actual validation fraction: {len(val_df) / len(df):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c5db4d-420d-498c-99d2-83e3002fbece",
   "metadata": {},
   "source": [
    "Upload the prepared datasets to OpenAI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b8ce4-4578-4f86-87d0-e955640b067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dataset_to_openai(df, openai_client) -> str:\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".jsonl\", delete=False) as f:\n",
    "        for item in df[\"openai_messages\"]:\n",
    "            json.dump(item, f)\n",
    "            f.write(\"\\n\")\n",
    "        f.flush()\n",
    "\n",
    "        print(f\"File persisted on path [{f.name}]\")\n",
    "\n",
    "        with open(f.name, \"rb\") as file:\n",
    "            file_object = openai_client.files.create(file=file, purpose=\"fine-tune\")\n",
    "\n",
    "        return file_object.id\n",
    "\n",
    "\n",
    "openai_client = openai.OpenAI()\n",
    "\n",
    "dpo_fine_tuning_object_id = upload_dataset_to_openai(train_df, openai_client)\n",
    "val_file_object_id = upload_dataset_to_openai(val_df, openai_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e272d04d-f417-458f-acad-cff04a5b0b38",
   "metadata": {},
   "source": [
    "Launch the fine-tuning job and wait for it to complete.\n",
    "\n",
    "NOTE : This step takes a while and you can monitor the progress and estimated completion time using OpenAI's fine-tuning [dashboard](https://platform.openai.com/finetune/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a188ee-be0b-4403-86b1-fb56d951740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_job = openai_client.fine_tuning.jobs.create(\n",
    "    training_file=dpo_fine_tuning_object_id,\n",
    "    validation_file=val_file_object_id,\n",
    "    model=MODEL_NAME,\n",
    "    method={\n",
    "        \"type\": \"dpo\",\n",
    "        \"dpo\": {\n",
    "            \"hyperparameters\": {\"beta\": 0.2},\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    try:\n",
    "        job_status = openai_client.fine_tuning.jobs.retrieve(fine_tuning_job.id)\n",
    "        pprint(job_status.to_dict())\n",
    "        if job_status.status in (\"succeeded\", \"failed\", \"cancelled\"):\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "print(f\"The fine-tuning job has compeleted with result {job_status.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c5a943-987f-4458-970a-7bd3d6907e53",
   "metadata": {},
   "source": [
    "Once the fine-tuning job is complete, you can add the fine-tuned model to your config file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad4a87-8adb-4b59-8451-e5eda3942f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = job_status.fine_tuned_model\n",
    "model_config = {\n",
    "    \"models\": {\n",
    "        fine_tuned_model: {\n",
    "            \"routing\": [\"openai\"],\n",
    "            \"providers\": {\"openai\": {\"type\": \"openai\", \"model_name\": fine_tuned_model}},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(toml.dumps(model_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb6d0a-8160-4a3f-83c9-72dde3e1bec9",
   "metadata": {},
   "source": [
    "Finally, add a new variant to your function to use the fine-tuned model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01bfe4c-8cd4-41b8-8e1e-f5ded5d2210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_config = {\n",
    "    \"type\": \"chat_completion\",\n",
    "    \"model\": fine_tuned_model,\n",
    "}\n",
    "\n",
    "system_template = variant.get(\"system_template\")\n",
    "if system_template:\n",
    "    variant_config[\"system_template\"] = system_template\n",
    "\n",
    "user_template = variant.get(\"user_template\")\n",
    "if user_template:\n",
    "    variant_config[\"user_template\"] = user_template\n",
    "\n",
    "assistant_template = variant.get(\"assistant_template\")\n",
    "if assistant_template:\n",
    "    variant_config[\"assistant_template\"] = assistant_template\n",
    "\n",
    "full_variant_config = {\n",
    "    \"functions\": {FUNCTION_NAME: {\"variants\": {fine_tuned_model: variant_config}}}\n",
    "}\n",
    "\n",
    "print(toml.dumps(full_variant_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3907c28e-772e-48da-a453-8b4ef99e0175",
   "metadata": {},
   "source": [
    "You're all set!\n",
    "\n",
    "You can change the weight to enable a gradual rollout of the new model.\n",
    "\n",
    "You might also add other parameters (e.g. max_tokens, temperature) to the variant section in the config file.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
