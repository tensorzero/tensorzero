{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61862dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8033ce8",
   "metadata": {},
   "source": [
    "# Dynamic In-Context Learning\n",
    "\n",
    "This recipe allows TensorZero users to set up a dynamic in-context learning variant for any function.\n",
    "Since TensorZero automatically logs all inferences and feedback, it is straightforward to query a set of good examples and retrieve the most relevant ones to put them into context for future inferences.\n",
    "Since TensorZero allows users to add demonstrations for any inference it is also easy to include them in the set of examples as well.\n",
    "This recipe will show use the OpenAI embeddings API only, but we are working towards support for all embedding providers over time as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ecd77",
   "metadata": {},
   "source": [
    "To get started:\n",
    "\n",
    "- Set the `TENSORZERO_CLICKHOUSE_URL` environment variable. For example: `TENSORZERO_CLICKHOUSE_URL=\"http://chuser:chpassword@localhost:8123/tensorzero\"`\n",
    "- Set the `OPENAI_API_KEY` environment variable.\n",
    "- Update the following parameters\n",
    "- Uncomment query filters as appropriate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e136f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "CONFIG_PATH = \"../../examples/data-extraction-ner/config/tensorzero.toml\"\n",
    "\n",
    "FUNCTION_NAME = \"extract_entities\"\n",
    "\n",
    "METRIC_NAME: Optional[str] = None\n",
    "\n",
    "MAX_EXAMPLES = 1000\n",
    "\n",
    "# The name of the variant to use to grab the templates used for fine-tuning\n",
    "TEMPLATE_VARIANT_NAME = \"gpt_4o_mini\"\n",
    "\n",
    "# The name of the DICL variant you will want to use. Set this to a meaningful name that does not conflict\n",
    "# with other variants for the function selected above.\n",
    "DICL_VARIANT_NAME = \"gpt_4o_mini_dicl\"\n",
    "\n",
    "# The model to use for the DICL variant.\n",
    "DICL_EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "# The model to use for generation in the DICL variant.\n",
    "DICL_GENERATION_MODEL = \"gpt-4o-mini-2024-07-18\"\n",
    "\n",
    "# The number of examples to retrieve for the DICL variant.\n",
    "DICL_K = 10\n",
    "\n",
    "# If the metric is a float metric, you can set the threshold to filter the data\n",
    "FLOAT_METRIC_THRESHOLD = 0.5\n",
    "\n",
    "# Whether to use demonstrations for DICL examples\n",
    "USE_DEMONSTRATIONS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea49b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import toml\n",
    "from tensorzero import DiclOptimizationConfig, TensorZeroGateway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf141ac4",
   "metadata": {},
   "source": [
    "If you haven't, also include the embedding model in the config.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca57e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_config = {\n",
    "    \"embedding_models\": {\n",
    "        DICL_EMBEDDING_MODEL: {\n",
    "            \"routing\": [\"openai\"],\n",
    "            \"providers\": {\n",
    "                \"openai\": {\"type\": \"openai\", \"model_name\": DICL_EMBEDDING_MODEL}\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(toml.dumps(embedding_model_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f053ba2",
   "metadata": {},
   "source": [
    "Initialize the TensorZero Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = TensorZeroGateway.build_embedded(\n",
    "    clickhouse_url=os.environ[\"TENSORZERO_CLICKHOUSE_URL\"], config_file=CONFIG_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb667f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = None\n",
    "# To filter on a boolean metric, you can uncomment the following line\n",
    "# filters = BooleanMetricFilter(metric_name=METRIC_NAME, value=True) # or False as needed\n",
    "\n",
    "# To filter on a float metric, you can uncomment the following line\n",
    "# filters = FloatMetricFilter(metric_name=METRIC_NAME, value=0.5, comparison_operator=\">\")\n",
    "# or any other float value as needed\n",
    "# You can even use AND, OR, and NOT operators to combine multiple filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778352db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_inferences = t0.experimental_list_inferences(\n",
    "    function_name=FUNCTION_NAME,\n",
    "    filters=filters,\n",
    "    output_source=\"demonstration\",\n",
    "    # or \"inference\" if you don't want to use (or don't have) demonstrations\n",
    "    # if you use \"demonstration\" we will restrict to the subset of infereences\n",
    "    # that have demonstrations\n",
    "    limit=MAX_EXAMPLES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f52bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered_samples = t0.experimental_render_samples(\n",
    "    stored_samples=stored_inferences,\n",
    "    variants={FUNCTION_NAME: TEMPLATE_VARIANT_NAME},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_config = DiclOptimizationConfig(\n",
    "    embedding_model=DICL_EMBEDDING_MODEL,\n",
    "    variant_name=DICL_VARIANT_NAME,\n",
    "    function_name=FUNCTION_NAME,\n",
    "    k=DICL_K,\n",
    "    model=DICL_GENERATION_MODEL,\n",
    ")\n",
    "job_handle = t0.experimental_launch_optimization(\n",
    "    train_samples=rendered_samples,\n",
    "    val_samples=None,\n",
    "    optimization_config=optimization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a9e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_info = t0.experimental_poll_optimization(job_handle=job_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3e195",
   "metadata": {},
   "source": [
    "Finally, add a new variant to your function configuration to try out the Dynamic In-Context Learning variant in practice!\n",
    "\n",
    "If your embedding model name or generation model name in the config is different from the one you used above, you might have to update the config.\n",
    "Be sure and also give the variant some weight and if you are using a JSON function set the json_mode field to \"strict\" if you want.\n",
    "\n",
    "> **Tip:** DICL variants support additional parameters like system instructions or strict JSON mode. See [Configuration Reference](https://www.tensorzero.com/docs/gateway/configuration-reference).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_variant_config = {\n",
    "    \"functions\": {\n",
    "        FUNCTION_NAME: {\"variants\": {DICL_VARIANT_NAME: job_info.output[\"content\"]}}\n",
    "    }\n",
    "}\n",
    "\n",
    "print(toml.dumps(full_variant_config))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
