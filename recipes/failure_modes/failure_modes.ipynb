{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Failure Modes with AI Assisted Root Cause Analysis\n",
    "\n",
    "This recipe allows TensorZero users to analyze failure modes of their LLM application with help from Root Cause Analysis AI.\n",
    "Since TensorZero automatically logs all inferences and feedback, it is straightforward to analyze the failure modes of your LLM application on your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started:\n",
    "\n",
    "- Set the `TENSORZERO_CLICKHOUSE_URL` environment variable. For example: `TENSORZERO_CLICKHOUSE_URL=\"http://chuser:chpassword@localhost:8123/tensorzero\"`\n",
    "- Set the `OPENAI_API_KEY` environment variable.\n",
    "- Update the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"../../examples/data-extraction-ner/config/tensorzero.toml\"\n",
    "\n",
    "FUNCTION_NAME = \"extract_entities\"\n",
    "\n",
    "METRIC_NAME = \"jaccard_similarity\"\n",
    "\n",
    "# The name of the variant to analyze root cause analysis\n",
    "SUBJECT_VARIANT_NAME = \"gpt_4o_mini\"\n",
    "\n",
    "# Optional list of tools available if your function supports them.\n",
    "# Each entry is formatted as as a dictionary.\n",
    "# {\"name\": \"<The tool's identifier.>\", \"description\": \"<A brief description of what the tool does.>\"}\n",
    "# These will be passed to the assistant to aid in root cause analysis.\n",
    "TOOLS_AVAILABLE = []\n",
    "\n",
    "# If the metric is a float metric, you can set the threshold to define a failure and filter the data\n",
    "FLOAT_METRIC_THRESHOLD = 0.5\n",
    "\n",
    "# Maximum number of samples to use for root cause analysis\n",
    "MAX_SAMPLES = 100_000\n",
    "\n",
    "# The name of the variant to use for root cause and failure mode analysis\n",
    "ANALYSIS_VARIANT_NAME = \"gpt-5\"\n",
    "\n",
    "# Embedding model to use for root cause and failure mode analysis\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "# Number of root cause clusters to use\n",
    "N_CLUSTERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "tensorzero_path = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "if tensorzero_path not in sys.path:\n",
    "    sys.path.append(tensorzero_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Optional\n",
    "\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import AsyncOpenAI\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from tensorzero import (\n",
    "    AsyncTensorZeroGateway,\n",
    "    FloatMetricFilter,\n",
    "    TensorZeroGateway,\n",
    ")\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from utils import generate_root_causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_client = TensorZeroGateway.build_embedded(\n",
    "    config_file=CONFIG_PATH,\n",
    "    clickhouse_url=os.environ[\"TENSORZERO_CLICKHOUSE_URL\"],\n",
    "    timeout=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_operator = \"<=\"\n",
    "metric_node = FloatMetricFilter(\n",
    "    metric_name=METRIC_NAME,\n",
    "    value=FLOAT_METRIC_THRESHOLD,\n",
    "    comparison_operator=comparison_operator,\n",
    ")\n",
    "\n",
    "# from tensorzero import BooleanMetricFilter\n",
    "\n",
    "# metric_node = BooleanMetricFilter(\n",
    "#     metric_name=METRIC_NAME,\n",
    "#     value=False  #\n",
    "# )\n",
    "\n",
    "metric_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_inferences = data_client.experimental_list_inferences(\n",
    "    function_name=FUNCTION_NAME,\n",
    "    variant_name=SUBJECT_VARIANT_NAME,\n",
    "    output_source=\"inference\",  # could also be \"demonstration\"\n",
    "    filters=metric_node,\n",
    "    limit=MAX_SAMPLES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered_samples = data_client.experimental_render_inferences(\n",
    "    stored_inferences=stored_inferences,\n",
    "    variants={FUNCTION_NAME: SUBJECT_VARIANT_NAME},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rendered_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Cause Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a list of root causes for each failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_cause_client = await AsyncTensorZeroGateway.build_embedded(\n",
    "    config_file=\"config/tensorzero.toml\",\n",
    "    clickhouse_url=os.environ[\"TENSORZERO_CLICKHOUSE_URL\"],\n",
    ")\n",
    "semaphore = asyncio.Semaphore(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    generate_root_causes(\n",
    "        gateway=root_cause_client,\n",
    "        rendered_sample=rendered_sample,\n",
    "        variant_name=ANALYSIS_VARIANT_NAME,\n",
    "        semaphore=semaphore,\n",
    "        dryrun=True,\n",
    "    )\n",
    "    for rendered_sample in rendered_samples\n",
    "]\n",
    "\n",
    "root_causes = await tqdm_asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_causes_concat = [\n",
    "    \"\\n\".join(root_cause) for root_cause in root_causes if root_cause is not None\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure Mode Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Get a vector representation of each root cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = AsyncOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_embedding(text: str) -> Optional[list[float]]:\n",
    "    try:\n",
    "        async with semaphore:\n",
    "            response = await openai_client.embeddings.create(\n",
    "                input=text, model=EMBEDDING_MODEL\n",
    "            )\n",
    "            return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embedding: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [get_embedding(root_cause) for root_cause in root_causes_concat]\n",
    "\n",
    "embeddings = await tqdm_asyncio.gather(*tasks, desc=\"Embedding inputs\")\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Find failure modes by clustering the root cause embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Bayesian GMM instead of KMeans\n",
    "bgmm = BayesianGaussianMixture(\n",
    "    n_components=N_CLUSTERS,\n",
    "    covariance_type=\"full\",\n",
    "    weight_concentration_prior_type=\"dirichlet_process\",\n",
    "    random_state=42,\n",
    ")\n",
    "bgmm.fit(embeddings)\n",
    "labels = bgmm.predict(embeddings)\n",
    "\n",
    "# Assign root cause labels to DataFrame\n",
    "df = pd.DataFrame(data={\"root_cause\": root_causes_concat, \"cluster\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"root_cause\": root_causes_concat, \"cluster\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure embeddings is a NumPy array\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# Fit PCA and transform\n",
    "pca = PCA(n_components=2)\n",
    "vis_dims2 = pca.fit_transform(embeddings)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "pca_df = pd.DataFrame(\n",
    "    {\"PC1\": vis_dims2[:, 0], \"PC2\": vis_dims2[:, 1], \"failure_mode\": df[\"cluster\"]}\n",
    ")\n",
    "\n",
    "# Compute cluster centroids\n",
    "centroids_df = pca_df.groupby(\"failure_mode\")[[\"PC1\", \"PC2\"]].mean().reset_index()\n",
    "centroids_df[\"label\"] = centroids_df[\"failure_mode\"].apply(lambda c: f\"Cluster {c}\")\n",
    "\n",
    "# Scatter plot of points\n",
    "points_chart = (\n",
    "    alt.Chart(pca_df)\n",
    "    .mark_circle(opacity=0.3, size=60)\n",
    "    .encode(\n",
    "        x=alt.X(\"PC1\", title=\"Principal Component 1\"),\n",
    "        y=alt.Y(\"PC2\", title=\"Principal Component 2\"),\n",
    "        color=alt.Color(\"failure_mode:N\", title=\"Failure Mode\"),\n",
    "        tooltip=[\"failure_mode\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cross markers for centroids\n",
    "centroids_chart = (\n",
    "    alt.Chart(centroids_df)\n",
    "    .mark_point(filled=True, size=100, shape=\"cross\")\n",
    "    .encode(x=\"PC1\", y=\"PC2\", color=alt.Color(\"failure_mode:N\"), tooltip=[\"label\"])\n",
    ")\n",
    "\n",
    "# Combine\n",
    "(points_chart + centroids_chart).properties(\n",
    "    title=\"Failure Modes visualized using Principal Component Analysis (PCA)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Summarize the failure modes in natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summaries = []\n",
    "# for i in range(N_CLUSTERS):\n",
    "#     print(f\"Cluster {i}:\", end=\" \")\n",
    "\n",
    "#     # Sample for summarization\n",
    "#     root_causes_sample = df[df.cluster == i].root_cause.to_list()\n",
    "#     # break\n",
    "\n",
    "#     gateway_input = {\n",
    "#         \"messages\": [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"arguments\": {\n",
    "#                             \"root_causes\": root_causes_sample,\n",
    "#                             \"system_template\": system_template,\n",
    "#                         },\n",
    "#                     }\n",
    "#                 ],\n",
    "#             }\n",
    "#         ]\n",
    "#     }\n",
    "#     response = await gateway.inference(\n",
    "#         input=gateway_input,\n",
    "#         function_name=\"summarize_failure_modes\",\n",
    "#         variant_name=ANALYSIS_VARIANT_NAME,\n",
    "#     )\n",
    "#     summary = response.output.parsed[\"summary\"]\n",
    "\n",
    "#     # Sample for representative examples (different random seed to avoid duplication)\n",
    "#     examples = df[df.cluster == i][\"rendered_input\"].to_list()\n",
    "#     examples = [example[\"messages\"][1:] for example in examples]\n",
    "#     summaries.append(summary)\n",
    "#     pprint(f\"\\nSummary: {summary}\")\n",
    "\n",
    "#     # Show example root causes\n",
    "#     print(\"\\nRepresentative examples:\")\n",
    "#     for ex in examples[:10]:\n",
    "#         print(f\" - {ex}\")\n",
    "#     print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're all set!\n",
    "\n",
    "We encourage you to experiment with other parameters (e.g. `N_CLUSTERS`, `EMBEDDING_MODEL`, or the clustering algorithm).\n",
    "\n",
    "We use OpenAI o4-mini for the root cause and failure mode analysis.\n",
    "You can try using other models by adding variants to `config/tensorzero.toml` and updating `ANALYSIS_VARIANT_NAME`."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
