{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"../../examples/haiku_hidden_preferences/config/tensorzero.toml\"\n",
    "\n",
    "FUNCTION_NAME = \"write_haiku\"\n",
    "BASE_VARIANT_NAME = \"initial_prompt_gpt4o_mini\"\n",
    "\n",
    "\n",
    "METRIC_NAME = \"haiku_score\"\n",
    "MAX_SAMPLES = 1000\n",
    "FLOAT_METRIC_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import dspy\n",
    "import toml\n",
    "from clickhouse_driver import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the TensorZero configuration file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(CONFIG_PATH)\n",
    "\n",
    "assert config_path.exists(), f\"{CONFIG_PATH} does not exist\"\n",
    "assert config_path.is_file(), f\"{CONFIG_PATH} is not a file\"\n",
    "\n",
    "with config_path.open(\"r\") as f:\n",
    "    config = toml.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the function configuration for the function we are optimizing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_config = config[\"functions\"][FUNCTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_flat_schema(schema: dict):\n",
    "    \"\"\"Check if a JSON schema (given as a dict) is flat.\"\"\"\n",
    "    if not isinstance(schema, dict):\n",
    "        return False\n",
    "\n",
    "    if \"type\" not in schema or schema[\"type\"] != \"object\":\n",
    "        return False\n",
    "\n",
    "    if \"properties\" not in schema:\n",
    "        return True\n",
    "\n",
    "    for prop in schema[\"properties\"].values():\n",
    "        if prop.get(\"type\") in [\"object\", \"array\"]:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_json_schema(schema: dict) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Preprocess a flat JSON schema to create a mapping of field names to their types.\n",
    "\n",
    "    Args:\n",
    "    user_schema (dict): A flat JSON schema.\n",
    "\n",
    "    Returns:\n",
    "    Dict[str, str]: A dictionary mapping field names to their types (number, string, bool, or integer).\n",
    "    \"\"\"\n",
    "    assert is_flat_schema(schema), f\"JSON schema is not flat: {schema}\"\n",
    "    result = {}\n",
    "    properties = schema.get(\"properties\", {})\n",
    "\n",
    "    for field_name, field_info in properties.items():\n",
    "        field_type = field_info.get(\"type\", \"\")\n",
    "        if field_type == \"number\":\n",
    "            result[field_name] = \"number\"\n",
    "        elif field_type == \"string\":\n",
    "            result[field_name] = \"string\"\n",
    "        elif field_type == \"boolean\":\n",
    "            result[field_name] = \"bool\"\n",
    "        elif field_type == \"integer\":\n",
    "            result[field_name] = \"integer\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonschema_type_to_python_type(field_type: str) -> str:\n",
    "    if field_type == \"number\":\n",
    "        return \"float\"\n",
    "    elif field_type == \"string\":\n",
    "        return \"str\"\n",
    "    elif field_type == \"boolean\":\n",
    "        return \"bool\"\n",
    "    elif field_type == \"integer\":\n",
    "        return \"int\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported field type: {field_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_config_to_dspy_signature(function_name: str, function_config: dict):\n",
    "    assert (\n",
    "        \"system_schema\" not in function_config\n",
    "    ), \"System schema not supported by DSPy recipe\"\n",
    "    assert (\n",
    "        \"assistants_schema\" not in function_config\n",
    "    ), \"Assistant schema not supported by DSPy recipe\"\n",
    "    assert \"user_schema\" in function_config, \"User schema not found in function config\"\n",
    "    user_schema_path = config_path.parent / function_config[\"user_schema\"]\n",
    "    with user_schema_path.open(\"r\") as f:\n",
    "        user_schema = preprocess_json_schema(json.load(f))\n",
    "    output_schema_path = function_config.get(\"output_schema\", None)\n",
    "    if output_schema_path:\n",
    "        output_schema_path = config_path.parent / output_schema_path\n",
    "        with output_schema_path.open(\"r\") as f:\n",
    "            output_schema = preprocess_json_schema(json.load(f))\n",
    "    else:\n",
    "        output_schema = None\n",
    "    input_signature = \"\"\n",
    "    for field_name, field_type in user_schema.items():\n",
    "        input_signature += f\"{field_name}:{jsonschema_type_to_python_type(field_type)},\"\n",
    "    input_signature = input_signature[:-1]\n",
    "    ## we don't need to trim the trailing comma because DSPy will handle it correctly (ignore it)\n",
    "    if output_schema:\n",
    "        output_signature = \"\"\n",
    "        for field_name, field_type in output_schema.items():\n",
    "            output_signature += (\n",
    "                f\"{field_name}:{jsonschema_type_to_python_type(field_type)},\"\n",
    "            )\n",
    "        # we don't need to trim the trailing comma because DSPy will handle it correctly (ignore it)\n",
    "    else:\n",
    "        output_signature = \"output\"\n",
    "    string_signature = f\"{input_signature} -> {output_signature}\"\n",
    "    return dspy.make_signature(string_signature, signature_name=function_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_signature = function_config_to_dspy_signature(FUNCTION_NAME, function_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the database name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"clickhouse\" in config and \"database\" in config[\"clickhouse\"]:\n",
    "    database_name = config[\"clickhouse\"][\"database\"]\n",
    "else:\n",
    "    database_name = \"tensorzero\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the ClickHouse client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    \"CLICKHOUSE_NATIVE_URL\" in os.environ\n",
    "), \"CLICKHOUSE_NATIVE_URL environment variable not set\"\n",
    "\n",
    "url_with_database = urljoin(os.environ[\"CLICKHOUSE_NATIVE_URL\"], database_name)\n",
    "\n",
    "clickhouse_client = Client.from_url(url_with_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the metric configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"metrics\" in config, \"No `[metrics]` section found in config\"\n",
    "assert (\n",
    "    METRIC_NAME in config[\"metrics\"]\n",
    "), f\"No metric named `{METRIC_NAME}` found in config\"\n",
    "\n",
    "metric = config[\"metrics\"][METRIC_NAME]\n",
    "\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the ClickHouse table name for the metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_table_name = {\n",
    "    \"float\": \"FloatMetricFeedback\",\n",
    "    \"boolean\": \"BooleanMetricFeedback\",\n",
    "}.get(metric[\"type\"])\n",
    "\n",
    "if feedback_table_name is None:\n",
    "    raise ValueError(f\"Unsupported metric type: {metric['type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"type\" in metric, \"Metric is missing the `type` field\"\n",
    "assert \"optimize\" in metric, \"Metric is missing the `optimize` field\"\n",
    "\n",
    "threshold = FLOAT_METRIC_THRESHOLD if metric[\"type\"] == \"float\" else 0.5\n",
    "comparison_operator = \">=\" if metric[\"optimize\"] == \"max\" else \"<=\"\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    i.variant_name, \n",
    "    i.input, \n",
    "    i.output, \n",
    "    f.value\n",
    "FROM \n",
    "    tensorzero.Inference i\n",
    "JOIN \n",
    "    tensorzero.BooleanMetricFeedback f ON i.id = f.target_id\n",
    "WHERE \n",
    "    i.function_name = %(function_name)s\n",
    "    AND f.value {comparison_operator} %(threshold)s\n",
    "LIMIT %(max_samples)s\n",
    "\"\"\"\n",
    "\n",
    "params = {\n",
    "    \"database_name\": database_name,\n",
    "    \"feedback_table_name\": feedback_table_name,\n",
    "    \"function_name\": FUNCTION_NAME,\n",
    "    \"comparison_operator\": comparison_operator,\n",
    "    \"threshold\": threshold,\n",
    "    \"max_samples\": MAX_SAMPLES,\n",
    "}\n",
    "\n",
    "df = clickhouse_client.query_dataframe(query, params)\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
