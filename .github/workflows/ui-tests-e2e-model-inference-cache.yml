name: UI E2E tests with model inference cache

on:
  workflow_call:
    secrets:
      S3_ACCESS_KEY_ID:
        required: true
      S3_SECRET_ACCESS_KEY:
        required: true
      OPENAI_API_KEY:
        required: false
      FIREWORKS_ACCOUNT_ID:
        required: false
      FIREWORKS_API_KEY:
        required: false
      ANTHROPIC_API_KEY:
        required: false
      TOGETHER_API_KEY:
        required: false
    inputs:
      regen_cache:
        required: true
        type: boolean
      is_merge_group:
        required: true
        type: boolean
      force_no_auth:
        description: 'Force auth_enabled to be false only (skip auth matrix)'
        required: false
        type: boolean
        default: false

permissions:
  contents: read
  actions: write

jobs:
  ui-tests-e2e-model-inference-cache:
    name: ui-tests-e2e-model-inference-cache (auth=${{ matrix.auth_enabled }})
    runs-on: namespace-profile-tensorzero-8x16
    # We currently only run this job when we have secrets available, since we need to use an S3 object_store
    # In the future, we might want to fix this so that it can run in PR CI for external (forked) PRs
    # For now, it just runs in the merge queue and on prs from the main repo
    if: github.repository == 'tensorzero/tensorzero' && ((github.event.pull_request.head.repo.full_name == github.repository && github.actor != 'dependabot[bot]') || inputs.is_merge_group || github.event_name == 'workflow_dispatch')

    strategy:
      matrix:
        auth_enabled: ${{ inputs.force_no_auth && fromJSON('[false]') || (inputs.is_merge_group && fromJSON('[true, false]') || fromJSON('[false]')) }}

    steps:
      # TODO - investigate why using the Namespace checkout action causes
      # 'tensorzero_core::built_info::GIT_COMMIT_HASH_SHORT' to be `None`
      - name: Check out the repo
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Cleanup disk space
        run: ./ci/free-disk-space.sh

      - name: Setup Node
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020
        with:
          node-version: "24.11.0"

      - name: Setup `pnpm`
        run: |
          for attempt in 1 2 3; do
            if npm install -g pnpm@latest; then
              break
            fi
            if [ $attempt -eq 3 ]; then
              echo "Failed to install pnpm after 3 attempts"
              exit 1
            fi
            sleep $((10 * attempt))
          done
        shell: bash

      - name: Install `pnpm` dependencies
        run: pnpm install --frozen-lockfile

      - name: Setup Playwright
        run: pnpm --filter=tensorzero-ui exec playwright install --with-deps chromium

      - name: Download container images
        uses: actions/download-artifact@95815c38cf2ff2164869cbab79da8d1f422bc89e
        with:
          pattern: build-*-container
          merge-multiple: true

      - name: Load `gateway` and `ui` containers
        # These containers may not exist if we manually triggered this workflow (or merge-queue.yml),
        # We'll automatically build the container locally if they don't exist, so let this step fail.
        continue-on-error: true
        run: |
          docker load < gateway-container.tar
          docker load < ui-container.tar

      # This allows us to use 'no-build' on subsequent steps
      - name: Build needed docker images
        working-directory: ui
        run: |
          docker compose -f fixtures/docker-compose.e2e.yml -f fixtures/docker-compose.ui.yml build fixtures mock-inference-provider

      - name: Set common fixture environment variables
        working-directory: ui
        run: |
          # Environment variables shared by the gateway and ui containers
          echo "TENSORZERO_CLICKHOUSE_URL=http://chuser:chpassword@clickhouse:8123/tensorzero_ui_fixtures" >> fixtures/.env
          echo "TENSORZERO_GATEWAY_URL=http://gateway:3000" >> fixtures/.env
          echo "TENSORZERO_GATEWAY_TAG=sha-${{ github.sha }}" >> fixtures/.env
          echo "TENSORZERO_UI_TAG=sha-${{ github.sha }}" >> fixtures/.env
          # We need these set in the ui container, so that we construct the correct optimizer config
          # to pass to 'experimentalLaunchOptimizationWorkflow'
          echo "FIREWORKS_BASE_URL=http://mock-inference-provider:3030/fireworks/" >> fixtures/.env
          echo "OPENAI_BASE_URL=http://mock-inference-provider:3030/openai/" >> fixtures/.env
          echo "TOGETHER_BASE_URL=http://mock-inference-provider:3030/together/" >> fixtures/.env
          echo "FIREWORKS_ACCOUNT_ID=fake_fireworks_account" >> fixtures/.env
          echo "VITE_TENSORZERO_FORCE_CACHE_ON=1" >> fixtures/.env

      - name: Enable authentication in config
        if: matrix.auth_enabled == true
        working-directory: ui
        run: |
          sed -i '2a\\n[gateway.auth]\nenabled = true' fixtures/config/tensorzero.toml

      - name: Regenerate model inference cache
        working-directory: ui
        if: inputs.regen_cache == true
        env:
          TENSORZERO_CI: 1
        run: |
          echo "FIREWORKS_ACCOUNT_ID=${{ secrets.FIREWORKS_ACCOUNT_ID }}" >> fixtures/.env-gateway
          echo "FIREWORKS_API_KEY=${{ secrets.FIREWORKS_API_KEY }}" >> fixtures/.env-gateway
          echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" >> fixtures/.env-gateway
          echo "ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}" >> fixtures/.env-gateway
          echo "S3_ACCESS_KEY_ID=${{ secrets.S3_ACCESS_KEY_ID }}" >> fixtures/.env-gateway
          echo "S3_SECRET_ACCESS_KEY=${{ secrets.S3_SECRET_ACCESS_KEY }}" >> fixtures/.env-gateway
          echo "TOGETHER_API_KEY=${{ secrets.TOGETHER_API_KEY }}" >> fixtures/.env-gateway
          # Save the old cache file for comparison
          cp ./fixtures/model_inference_cache_e2e.jsonl ./fixtures/model_inference_cache_e2e.jsonl.old
          # Run up to 3 times if it fails. We need to retry *outside* of playwright, so that we wipe the
          # model inference cache each time. Retrying an individual playwright test without wiping the database
          # will pollute the cache with duplicate entries.
          for i in {1..3}; do
            if ./fixtures/regenerate-model-inference-cache.sh; then
              break
            elif [ $i -eq 3 ]; then
              echo "Failed after 3 attempts"
              exit 1
            else
              echo "Attempt $i failed, retrying..."
            fi
          done
          # Check that the old and new cache files have the same number of rows
          OLD_ROWS=$(wc -l < ./fixtures/model_inference_cache_e2e.jsonl.old)
          NEW_ROWS=$(wc -l < ./fixtures/model_inference_cache_e2e.jsonl)
          echo "Old cache file has $OLD_ROWS rows, new cache file has $NEW_ROWS rows"
          if [ "$OLD_ROWS" != "$NEW_ROWS" ]; then
            echo "ERROR: Row count mismatch between old and new cache files"
            echo "Old rows:"
            echo "$OLD_ROWS"
            echo "New rows:"
            echo "$NEW_ROWS"
            # Temporarily disabled
            # exit 1
          fi
          # Note that we cannot check the file contents - we will legitimately get some different cache keys when
          # regenerating, since the output from some cache entries get fed into judge models (affecting the cache key)
          echo "Cache file validation passed: same number of rows"
          # Take down and destroy the containers, so that our subsequent test run starts with a fresh ClickHouse
          # server, and inserts our regenerated fixtures from scratch
          docker compose -f ./fixtures/docker-compose.e2e.yml -f ./fixtures/docker-compose.ui.yml down
          docker compose -f ./fixtures/docker-compose.e2e.yml -f ./fixtures/docker-compose.ui.yml rm -f

      - name: Upload new model inference cache
        if: always() && inputs.regen_cache == true
        uses: namespace-actions/upload-artifact@9a78c62e083914789d908952f9773e42744b9f68
        with:
          name: model-inference-cache
          path: |
            ui/fixtures/model_inference_cache_e2e.jsonl

      - name: Generate API key
        if: matrix.auth_enabled == true
        working-directory: ui
        run: |
          echo "Starting postgres..."
          docker compose -f fixtures/docker-compose.e2e.yml up postgres -d

          echo "Waiting for postgres to be healthy (timeout: 2 minutes)..."
          # Wait with explicit timeout and show progress
          timeout 120 bash -c '
            while true; do
              # Parse JSON - handle both array and object formats
              STATUS=$(docker compose -f fixtures/docker-compose.e2e.yml ps postgres --format json | jq -r "if type == \"array\" then .[0].Health else .Health end")
              echo "Postgres health status: $STATUS"
              if [ "$STATUS" = "healthy" ]; then
                echo "Postgres is healthy!"
                break
              fi
              sleep 2
            done
          ' || {
            echo "ERROR: Timeout waiting for postgres to become healthy"
            echo "=== Postgres container status ==="
            docker compose -f fixtures/docker-compose.e2e.yml ps postgres
            echo "=== Postgres container logs ==="
            docker compose -f fixtures/docker-compose.e2e.yml logs postgres
            echo "=== Postgres container inspect ==="
            docker inspect $(docker compose -f fixtures/docker-compose.e2e.yml ps -q postgres)
            exit 1
          }

          echo "Running gateway postgres migrations..."
          docker run --rm \
            --network fixtures_default \
            -e TENSORZERO_POSTGRES_URL="postgres://postgres:postgres@postgres:5432/tensorzero_ui_fixtures" \
            tensorzero/gateway:sha-${{ github.sha }} \
            --run-postgres-migrations

          echo "Migrations complete"

          echo "Checking docker networks..."
          docker network ls | grep fixtures || echo "No fixtures network found"

          echo "Checking postgres container..."
          docker compose -f fixtures/docker-compose.e2e.yml ps postgres

          echo "Generating API key using gateway:sha-${{ github.sha }}..."
          API_KEY=$(docker run --rm \
            --network fixtures_default \
            -e TENSORZERO_POSTGRES_URL="postgres://postgres:postgres@postgres:5432/tensorzero_ui_fixtures" \
            tensorzero/gateway:sha-${{ github.sha }} \
            --create-api-key)

          echo "API key generated successfully"
          # Only the UI needs the API key to make requests to the gateway
          echo "TENSORZERO_API_KEY=$API_KEY" >> fixtures/.env
          echo "API key written to fixtures/.env"

      - name: Start dependency Docker containers and apply fixtures
        working-directory: ui
        run: |
          # Environment variables only used by the gateway container
          # We deliberately leave these unset when starting the UI container, to ensure
          # that it doesn't depend on them being set
          # When the secrets are not passed in to this workflow
          # (which happens when we test our existing cache file in PR CI),
          # we set them to dummy values
          echo "FIREWORKS_ACCOUNT_ID=${{ secrets.FIREWORKS_ACCOUNT_ID || 'not_used' }}" >> fixtures/.env-gateway
          echo "FIREWORKS_API_KEY=${{ secrets.FIREWORKS_API_KEY || 'not_used' }}" >> fixtures/.env-gateway
          echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY || 'not_used' }}" >> fixtures/.env-gateway
          echo "ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY || 'not_used' }}" >> fixtures/.env-gateway
          echo "TOGETHER_API_KEY=${{ secrets.TOGETHER_API_KEY || 'not_used' }}" >> fixtures/.env-gateway
          echo "S3_ACCESS_KEY_ID=${{ secrets.S3_ACCESS_KEY_ID }}" >> fixtures/.env-gateway
          echo "S3_SECRET_ACCESS_KEY=${{ secrets.S3_SECRET_ACCESS_KEY }}" >> fixtures/.env-gateway
          docker compose -f fixtures/docker-compose.e2e.yml up --no-build -d
          docker compose -f fixtures/docker-compose.e2e.yml wait fixtures

      - name: Start UI Docker container
        working-directory: ui
        run: |
          docker compose -f fixtures/docker-compose.ui.yml up --no-build -d --wait

      - name: Run UI E2E tests
        id: e2e_tests
        env:
          TENSORZERO_CI: 1
          TENSORZERO_CLICKHOUSE_URL: "http://chuser:chpassword@localhost:8123/tensorzero_ui_fixtures"
          TENSORZERO_POSTGRES_URL: "postgres://postgres:postgres@localhost:5432/tensorzero-e2e-tests"
          # These 2 vars are set so the env.server code doesn't complain
          TENSORZERO_UI_CONFIG_PATH: "ui/fixtures/config/tensorzero.toml"
          TENSORZERO_GATEWAY_URL: "placeholder"
        run: pnpm ui:test:e2e --grep-invert "@credentials"

      - name: Print Docker Compose logs
        if: always()
        working-directory: ui
        run: docker compose -f fixtures/docker-compose.e2e.yml -f fixtures/docker-compose.ui.yml logs -t

      - name: Print container health checks
        if: always()
        working-directory: ui
        run: docker inspect --format "{{json .State.Health }}" $(docker compose -f fixtures/docker-compose.e2e.yml -f fixtures/docker-compose.ui.yml ps -q ui) | jq

      - name: Make sure the current commit short hash is in the Docker Compose gateway logs
        if: always()
        working-directory: ui
        run: |
          SHORT_HASH=$(echo "${{ github.sha }}" | cut -c1-7)
          docker compose -f fixtures/docker-compose.e2e.yml logs gateway | grep "(commit: ${SHORT_HASH})" || {
            echo "ERROR: Commit hash ${SHORT_HASH} not found in gateway logs"
            exit 1
          }

      - name: Print ClickHouse error logs
        if: always()
        run: docker exec fixtures-clickhouse-1 cat /var/log/clickhouse-server/clickhouse-server.err.log

      - name: Print ClickHouse trace logs
        if: always()
        run: docker exec fixtures-clickhouse-1 cat /var/log/clickhouse-server/clickhouse-server.log

      - name: Upload Playwright artifacts (GitHub runner)
        if: failure() && inputs.regen_cache == false
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: playwright-report-auth-${{ matrix.auth_enabled }}
          path: |
            ui/playwright-report/
            ui/test-results/
          retention-days: 7

      - name: Upload Playwright artifacts (Namespace runner)
        if: failure() && inputs.regen_cache == true
        uses: namespace-actions/upload-artifact@9a78c62e083914789d908952f9773e42744b9f68
        with:
          name: playwright-report-auth-${{ matrix.auth_enabled }}
          path: |
            ui/playwright-report/
            ui/test-results/
          retention-days: 7
