name: UI E2E tests with model inference cache

on:
  workflow_call:
    secrets:
      S3_ACCESS_KEY_ID:
        required: true
      S3_SECRET_ACCESS_KEY:
        required: true
      OPENAI_API_KEY:
        required: false
      FIREWORKS_ACCOUNT_ID:
        required: false
      FIREWORKS_API_KEY:
        required: false
    inputs:
      regen_cache:
        required: true
        type: boolean

jobs:
  ui-tests-e2e:
    runs-on: namespace-profile-tensorzero-8x16
    # We currently only run this job when we have secrets available, since we need to use an S3 object_store
    # In the future, we might want to fix this so that it can run in PR CI for external (forked) PRs
    # For now, it just runs in the merge queue and on prs from the main repo
    if: ${{ (github.event.pull_request.head.repo.full_name == github.repository && github.actor != 'dependabot[bot]') || github.event_name == 'merge_group' }}

    steps:
      # TODO - investigate why using the Namespace checkout action causes
      # 'tensorzero_core::built_info::GIT_COMMIT_HASH_SHORT' to be `None`
      - name: Check out the repo
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Setup Node
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020
        with:
          node-version: "22.9.0"

      - name: Setup `pnpm`
        uses: pnpm/action-setup@a7487c7e89a18df4991f7f222e4898a00d66ddda

      - name: Install `pnpm` dependencies
        run: pnpm install --frozen-lockfile

      - name: Setup Playwright
        run: pnpm --filter=tensorzero-ui exec playwright install --with-deps chromium

      - name: Cache `s3-fixtures`
        uses: namespacelabs/nscloud-cache-action@2f50e7d0f70475e6f59a55ba0f05eec9108e77cc
        with:
          path: |
            ./ui/fixtures/s3-fixtures

      # When we're regenerating the model inference cache, don't download the container images
      # The images will get built by `regenerate-model-inference-cache.sh`
      - name: Download container images
        if: inputs.regen_cache == false
        uses: namespace-actions/download-artifact@5c070f7d7ebdc47682b04aa736c76e46ff5f6e1e
        with:
          pattern: build-*-container
          merge-multiple: true

      - name: Load `gateway` and `ui` containers
        if: inputs.regen_cache == false
        run: |
          docker load < gateway-container.tar
          docker load < ui-container.tar

      # This allows us to use 'no-build' on subsequent steps
      - name: Build needed docker images
        working-directory: ui
        run: |
          docker compose -f fixtures/docker-compose.e2e.yml -f fixtures/docker-compose.ui.yml build fixtures mock-inference-provider

      - name: Set common fixture environment variables
        working-directory: ui
        run: |
          # Environment variables shared by the gateway and ui containers
          echo "TENSORZERO_CLICKHOUSE_URL=http://chuser:chpassword@clickhouse:8123/tensorzero_ui_fixtures" >> fixtures/.env
          echo "TENSORZERO_GATEWAY_URL=http://gateway:3000" >> fixtures/.env
          echo "TENSORZERO_GATEWAY_TAG=sha-${{ github.sha }}" >> fixtures/.env
          echo "TENSORZERO_UI_TAG=sha-${{ github.sha }}" >> fixtures/.env
          # We need these set in the ui container, so that we construct the correct optimizer config
          # to pass to 'experimentalLaunchOptimizationWorkflow'
          echo "FIREWORKS_BASE_URL=http://mock-inference-provider:3030/fireworks/" >> fixtures/.env
          echo "OPENAI_BASE_URL=http://mock-inference-provider:3030/openai/" >> fixtures/.env
          echo "FIREWORKS_ACCOUNT_ID=fake_fireworks_account" >> fixtures/.env
          echo "TENSORZERO_FORCE_CACHE_ON=1" >> fixtures/.env

      - name: Regenerate model inference cache
        working-directory: ui
        if: inputs.regen_cache == true
        run: |
          echo "FIREWORKS_ACCOUNT_ID=${{ secrets.FIREWORKS_ACCOUNT_ID }}" >> fixtures/.env-gateway
          echo "FIREWORKS_API_KEY=${{ secrets.FIREWORKS_API_KEY }}" >> fixtures/.env-gateway
          echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" >> fixtures/.env-gateway
          echo "S3_ACCESS_KEY_ID=${{ secrets.S3_ACCESS_KEY_ID }}" >> fixtures/.env-gateway
          echo "S3_SECRET_ACCESS_KEY=${{ secrets.S3_SECRET_ACCESS_KEY }}" >> fixtures/.env-gateway
          ./fixtures/regenerate-model-inference-cache.sh
          # Take down and destroy the containers, so that our subsequent test run starts with a fresh ClickHouse
          # server, and inserts our regenerated fixtures from scratch
          docker compose -f ./fixtures/docker-compose.e2e.yml -f ./fixtures/docker-compose.ui.yml down
          docker compose -f ./fixtures/docker-compose.e2e.yml -f ./fixtures/docker-compose.ui.yml rm -f


      - name: Upload new model inference cache
        if: inputs.regen_cache == true
        uses: namespace-actions/upload-artifact@9a78c62e083914789d908952f9773e42744b9f68
        with:
          name: model-inference-cache
          path: |
            ui/fixtures/model_inference_cache_e2e.jsonl

      - name: Start dependency Docker containers and apply fixtures
        working-directory: ui
        run: |
          # Environment variables only used by the gateway container
          # We deliberately leave these unset when starting the UI container, to ensure
          # that it doesn't depend on them being set
          # When the secrets are not passed in to this workflow
          # (which happens when we test our existing cache file in PR CI),
          # we set them to dummy values
          echo "FIREWORKS_ACCOUNT_ID=${{ secrets.FIREWORKS_ACCOUNT_ID || 'not_used' }}" >> fixtures/.env-gateway
          echo "FIREWORKS_API_KEY=${{ secrets.FIREWORKS_API_KEY || 'not_used' }}" >> fixtures/.env-gateway
          echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY || 'not_used' }}" >> fixtures/.env-gateway
          echo "S3_ACCESS_KEY_ID=${{ secrets.S3_ACCESS_KEY_ID }}" >> fixtures/.env-gateway
          echo "S3_SECRET_ACCESS_KEY=${{ secrets.S3_SECRET_ACCESS_KEY }}" >> fixtures/.env-gateway
          docker compose -f fixtures/docker-compose.e2e.yml up --no-build -d
          docker compose -f fixtures/docker-compose.e2e.yml wait fixtures

      - name: Start UI Docker container
        working-directory: ui
        run: |
          docker compose -f fixtures/docker-compose.ui.yml up --no-build -d --wait

      - name: Run UI E2E tests
        id: e2e_tests
        env:
          TENSORZERO_CI: 1
        continue-on-error: true
        run: pnpm ui:test:e2e --grep-invert "@credentials"

      - name: Print Docker Compose logs
        if: always()
        working-directory: ui
        run: docker compose -f fixtures/docker-compose.e2e.yml -f fixtures/docker-compose.ui.yml logs -t

      - name: Print container health checks
        if: always()
        working-directory: ui
        run: docker inspect --format "{{json .State.Health }}" $(docker compose -f fixtures/docker-compose.e2e.yml -f fixtures/docker-compose.ui.yml ps -q ui) | jq

      - name: Make sure the current commit short hash is in the Docker Compose gateway logs
        if: always()
        working-directory: ui
        run: |
          SHORT_HASH=$(echo "${{ github.sha }}" | cut -c1-7)
          docker compose -f fixtures/docker-compose.e2e.yml logs gateway | grep "(commit: ${SHORT_HASH})" || {
            echo "ERROR: Commit hash ${SHORT_HASH} not found in gateway logs"
            exit 1
          }

      - name: Print ClickHouse error logs
        if: always()
        run: docker exec fixtures-clickhouse-1 cat /var/log/clickhouse-server/clickhouse-server.err.log

      - name: Print ClickHouse trace logs
        if: always()
        run: docker exec fixtures-clickhouse-1 cat /var/log/clickhouse-server/clickhouse-server.log

      - name: Upload Playwright artifacts
        if: steps.e2e_tests.outcome == 'failure'
        uses: namespace-actions/upload-artifact@9a78c62e083914789d908952f9773e42744b9f68
        with:
          name: playwright-report
          path: |
            ui/playwright-report/
            ui/test-results/
          retention-days: 7

      - name: Exit if tests failed
        if: steps.e2e_tests.outcome == 'failure'
        run: exit 1
