name: Merge Queue Checks
run-name: Merge Queue Checks for ${{ github.ref }}

on:
  workflow_dispatch:
  merge_group:

env:
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_REGION: "us-east-1"
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AZURE_OPENAI_API_BASE: ${{secrets.AZURE_OPENAI_API_BASE }}
  AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
  AZURE_OPENAI_DEPLOYMENT_ID: ${{secrets.AZURE_OPENAI_DEPLOYMENT_ID }}
  DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
  FIREWORKS_API_KEY: ${{ secrets.FIREWORKS_API_KEY }}
  FIREWORKS_ACCOUNT_ID: ${{ secrets.FIREWORKS_ACCOUNT_ID }}
  FORCE_COLOR: 1
  GCP_VERTEX_CREDENTIALS_PATH: ${{ github.workspace }}/gcp_jwt_key.json
  GCP_STORAGE_ACCESS_KEY_ID: ${{ secrets.GCP_STORAGE_ACCESS_KEY_ID }}
  GCP_STORAGE_SECRET_ACCESS_KEY: ${{ secrets.GCP_STORAGE_SECRET_ACCESS_KEY }}
  GOOGLE_AI_STUDIO_API_KEY: ${{ secrets.GOOGLE_AI_STUDIO_API_KEY }}
  HYPERBOLIC_API_KEY: ${{secrets.HYPERBOLIC_API_KEY}}
  MODAL_KEY: ${{ secrets.MODAL_KEY }}
  MODAL_SECRET: ${{ secrets.MODAL_SECRET }}
  MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
  R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
  SGLANG_API_KEY: ${{ secrets.SGLANG_API_KEY }}
  TGI_API_KEY: ${{ secrets.TGI_API_KEY }}
  TOGETHER_API_KEY: ${{ secrets.TOGETHER_API_KEY }}
  VLLM_API_KEY: ${{ secrets.VLLM_API_KEY }}
  VLLM_API_BASE: ${{ secrets.VLLM_API_BASE }}
  VLLM_MODEL_NAME: "microsoft/Phi-3.5-mini-instruct"
  XAI_API_KEY: ${{ secrets.XAI_API_KEY }}

jobs:
  live-tests:
    runs-on: namespace-profile-tensorzero-8x16

    timeout-minutes: 15

    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Warm up modal instances
        run: |
          curl -H "Modal-Key: $MODAL_KEY" -H "Modal-Secret: $MODAL_SECRET" https://tensorzero--vllm-inference-vllm-inference.modal.run/docs > vllm_modal_logs.txt &
          curl -H "Modal-Key: $MODAL_KEY" -H "Modal-Secret: $MODAL_SECRET" https://tensorzero--sglang-inference-sglang-inference.modal.run/ > sglang_modal_logs.txt &

      - name: Install Namespace CLI
        uses: namespacelabs/nscloud-setup@d1c625762f7c926a54bd39252efff0705fd11c64

      - name: Configure Namespace-powered Buildx
        uses: namespacelabs/nscloud-setup-buildx-action@84ca8c58fdf372d6a4750476cd09b7b96ee778ca

      - uses: Swatinem/rust-cache@9d47c6ad4b02e050fd481d890b2ea34778fd09d6
        with:
          cache-provider: "buildjet"

      - name: Print Rust version
        run: rustc --version

      - name: Install uv
        run: curl -LsSf https://astral.sh/uv/0.6.4/install.sh | sh

      - name: Install pnpm
        uses: pnpm/action-setup@a7487c7e89a18df4991f7f222e4898a00d66ddda
        with:
          version: 10

      - name: Configure Namespace cache for Rust, Python (uv), and pnpm
        uses: namespacelabs/nscloud-cache-action@2f50e7d0f70475e6f59a55ba0f05eec9108e77cc
        with:
          cache: |
            pnpm
            rust
            uv

      - name: Login to DockerHub
        uses: docker/login-action@74a5d142397b4f367a81961eba4e8cd7edddf772
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Install cargo-nextest
        uses: taiki-e/install-action@37bdc826eaedac215f638a96472df572feab0f9b
        with:
          tool: cargo-nextest

      - name: Write GCP JWT key to file
        env:
          GCP_JWT_KEY: ${{ secrets.GCP_JWT_KEY }}
        run: echo "$GCP_JWT_KEY" > $GITHUB_WORKSPACE/gcp_jwt_key.json

      - name: Set up TENSORZERO_CLICKHOUSE_URL for E2E tests
        run: |
          echo "TENSORZERO_CLICKHOUSE_URL=http://chuser:chpassword@localhost:8123/tensorzero_e2e_tests" >> $GITHUB_ENV

      - name: Launch ClickHouse container for E2E tests
        run: |
          # 'docker compose' will exit with status code 1 if any container exits, even if the container exits with status code 0
          docker compose -f tensorzero-internal/tests/e2e/docker-compose.yml up -d --wait || true

      - name: Launch the provider-proxy cache for E2E tests
        run: |
          ./ci/run-provider-proxy.sh ci

      - name: Launch the gateway for E2E tests
        run: |
          TENSORZERO_E2E_PROXY="http://localhost:3003" cargo run-e2e > e2e_logs.txt 2>&1 &
          while ! curl -s -f http://localhost:3000/health >/dev/null 2>&1; do
            echo "Waiting for gateway to be healthy..."
            sleep 1
          done
          echo "GATEWAY_PID=$!" >> $GITHUB_ENV

      # We set 'TENSORZERO_E2E_PROXY' here so that embedded gateway tests can use it
      # The 'CARGO_NEXTEST_FLAKY_TESTS' variable allows us to mark tests as flaky without merging a PR (if a provider happens to break or goes down)
      # We run the tests without the flaky tests, and require them to pass
      - name: Run all tests (including E2E tests)
        run: |
          TENSORZERO_E2E_PROXY="http://localhost:3003" cargo test-all --profile ci ${{ vars.CARGO_NEXTEST_EXTRA_ARGS }} -E "not (${{ vars.CARGO_NEXTEST_FLAKY_TESTS }})"

      # As a separate step, we run just the flaky tests, and allow them to fail.
      # This lets us see if any flaky tests have started succeeding (by looking at the job output),
      # so that we can decide to mark them as non-flaky.
      - name: Run flaky E2E tests
        run: |
          TENSORZERO_E2E_PROXY="http://localhost:3003" cargo test-all --profile ci --no-fail-fast ${{ vars.CARGO_NEXTEST_EXTRA_ARGS }} -E "${{ vars.CARGO_NEXTEST_FLAKY_TESTS }}"
        continue-on-error: true

      - name: Print e2e logs
        if: always()
        run: cat e2e_logs.txt

      - name: Print provider-proxy logs
        if: always()
        run: cat provider_proxy_logs.txt

      - name: Print vLLM modal logs
        if: always()
        run: cat vllm_modal_logs.txt

      - name: Print SGLang modal logs
        if: always()
        run: cat sglang_modal_logs.txt

      - name: Upload provider-proxy cache
        if: ${{ false }} # Change to `if: ${{ always() }}` to start uploading the cache
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: provider-proxy-cache
          path: ./ci/provider-proxy-cache/

      - name: Install Python for python async client tests
        run: uv python install 3.9

      - name: "Python: PyO3 Client: pytest"
        working-directory: clients/python
        run: |
          bash ./test.sh

      - name: "Python: OpenAI Client: Install dependencies"
        working-directory: clients/openai-python
        run: |
          uv venv
          uv pip sync requirements.txt

      - name: "Python: OpenAI Client: pytest"
        working-directory: clients/openai-python
        run: |
          uv run pytest

      - name: "Node.js: OpenAI Client: Install dependencies"
        working-directory: clients/openai-node
        run: |
          pnpm install

      - name: "Node.js: OpenAI Client: test"
        working-directory: clients/openai-node
        run: |
          pnpm run test

      - name: Install Go
        uses: actions/setup-go@29694d72cd5e7ef3b09496b39f28a942af47737e
        with:
          go-version: "1.24"

      - name: "Go: OpenAI Client: test"
        working-directory: clients/openai-go/tests
        run: go test -v

      - name: "Python: Recipes: pytest"
        working-directory: recipes
        run: |
          uv run pytest

      - name: Terminate the gateway
        run: |
          echo "Killing gateway with pid $GATEWAY_PID"
          kill $GATEWAY_PID

  check-production-docker-container:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
      - name: Build Docker container for production deployment tests
        run: docker build -t tensorzero/gateway -f gateway/Dockerfile .

      - name: Launch ClickHouse container for E2E tests
        run: |
          # 'docker compose' will exit with status code 1 if any container exits, even if the container exits with status code 0
          docker compose -f tensorzero-internal/tests/e2e/docker-compose.yml up -d --wait || true

      - name: Set up .env file for production deployment tests
        run: |
          echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" > examples/production-deployment/.env
          echo "TENSORZERO_CLICKHOUSE_URL=http://chuser:chpassword@host.docker.internal:8123/tensorzero" >> examples/production-deployment/.env

      - name: Run docker compose for production deployment tests
        run: docker compose -f examples/production-deployment/docker-compose.yml up -d --wait

      - name: Run inference for production deployment tests
        run: examples/production-deployment/run.sh

      - name: Take down docker compose for production deployment tests
        run: |
          docker compose -f examples/production-deployment/docker-compose.yml down
          docker compose -f tensorzero-internal/tests/e2e/docker-compose.yml down

  # See 'ci/README.md' at the repository root for more details.
  check-all-live-tests-passed:
    if: always()
    needs: [check-production-docker-container, live-tests]
    runs-on: ubuntu-latest
    steps:
      - if: ${{ contains(needs.*.result, 'failure') || contains(needs.*.result, 'cancelled') }}
        run: exit 1
