"""
Auto-generated Python dataclasses from JSON schemas.

This file is generated from JSON schemas in the tensorzero-core crate.
Do not edit this file manually - it will be overwritten.

Generated from schemas in: tensorzero-core/schemas/

To regenerate, run:
    python generate_schema_types.py
"""

from __future__ import annotations


class _UnsetType:
    """Sentinel value to distinguish between omitted fields and null values."""

    def __repr__(self):
        return "UNSET"


UNSET = _UnsetType()
"""
Sentinel value to distinguish between omitted and null in API requests.

Usage:
- UNSET: Field is omitted (don't change existing value)
- None: Field is explicitly set to null
- value: Field is set to the provided value

Example:
    # Omit the field entirely (don't update it)
    update = UpdateRequest(name=UNSET)

    # Set the field to null (clear the existing value)
    update = UpdateRequest(name=None)

    # Set the field to a value
    update = UpdateRequest(name="new_value")
"""


from __future__ import annotations

from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Literal

Model = Any


class Detail(Enum):
    """
    Detail level for input images (affects fidelity and token cost)
    """

    low = 'low'
    high = 'high'
    auto = 'auto'


@dataclass
class ToolCall:  # Field exstras: {}
    id: str  # Field exstras: {}
    name: str  # Field exstras: {}
    arguments: str


@dataclass
class FileUrl:  # Field exstras: {}
    url: str  # Field exstras: {}
    mime_type: str | None = None  # Field exstras: {}
    detail: Detail | None = None


@dataclass
class ObjectStorageFile:
    """
    A file stored in an object storage backend, with data.
    This struct can NOT be stored in the database.
    Note: `File` supports both `ObjectStorageFilePointer` and `ObjectStorageFile`.
    """  # Field exstras: {}

    mime_type: str  # Field exstras: {}
    storage_path: str  # Field exstras: {}
    data: str  # Field exstras: {}
    source_url: str | None = None  # Field exstras: {}
    detail: Detail | None = None


@dataclass
class Base64FileMetadata:
    """
    Like `Base64File`, but without the data field.
    """  # Field exstras: {}

    mime_type: str  # Field exstras: {}
    source_url: str | None = None  # Field exstras: {}
    detail: Detail | None = None


@dataclass
class ThoughtSummaryBlock1:  # Field exstras: {}
    text: str  # Field exstras: {'const': 'summary_text'}
    type: Literal['summary_text'] = 'summary_text'


ThoughtSummaryBlock = ThoughtSummaryBlock1


@dataclass
class Thought:
    """
    Struct that represents a model's reasoning
    """  # Field exstras: {}

    text: str | None = (
        None  # Field exstras: {'description': 'An optional signature - currently, this is only used with Anthropic,\nand is ignored by other providers.'}
    )
    signature: str | None = None
    """
    An optional signature - currently, this is only used with Anthropic,
    and is ignored by other providers.
    """  # Field exstras: {}
    summary: list[ThoughtSummaryBlock] | None = (
        None  # Field exstras: {'description': "When set, this 'Thought' block will only be used for providers\nmatching this type (e.g. `anthropic`). Other providers will emit\na warning and discard the block."}
    )
    field_internal_provider_type: str | None = None
    """
    When set, this 'Thought' block will only be used for providers
    matching this type (e.g. `anthropic`). Other providers will emit
    a warning and discard the block.
    """


@dataclass
class InferenceResponseToolCall:
    """
    An InferenceResponseToolCall is a request by a model to call a Tool
    in the form that we return to the client / ClickHouse
    """  # Field exstras: {'description': 'A Tool Call ID to match up with tool call responses. See #4058.'}

    id: str
    """
    A Tool Call ID to match up with tool call responses. See #4058.
    """  # Field exstras: {'description': 'The name of the tool to call, as generated by the model.'}
    raw_name: str
    """
    The name of the tool to call, as generated by the model.
    """  # Field exstras: {'description': 'The raw arguments JSON string of the tool to call, as generated by the model.'}
    raw_arguments: str
    """
    The raw arguments JSON string of the tool to call, as generated by the model.
    """  # Field exstras: {'description': 'The name of the tool to call, validated against tool configs. If not present, it means the tool call was invalid.'}
    name: str | None = None
    """
    The name of the tool to call, validated against tool configs. If not present, it means the tool call was invalid.
    """  # Field exstras: {'description': 'The arguments of the tool to call, validated against tool configs. If not present, it means the tool call arguments were invalid.'}
    arguments: Any | None = None
    """
    The arguments of the tool to call, validated against tool configs. If not present, it means the tool call arguments were invalid.
    """


@dataclass
class Tool:
    """
    A Tool object describes how a tool can be dynamically configured by the user.
    """  # Field exstras: {}

    description: str  # Field exstras: {}
    parameters: Any  # Field exstras: {}
    name: str  # Field exstras: {}
    strict: bool | None = False


class ToolChoice1(Enum):
    """
    Most inference providers allow the user to force a tool to be used
    and even specify which tool to be used.

    This enum is used to denote this tool choice.
    """

    none = 'none'
    auto = 'auto'
    required = 'required'


@dataclass
class ToolChoice2:
    """
    Most inference providers allow the user to force a tool to be used
    and even specify which tool to be used.

    This enum is used to denote this tool choice.
    """  # Field exstras: {}

    specific: str


@dataclass
class ProviderToolScope1:  # Field exstras: {}
    model_name: str  # Field exstras: {}
    model_provider_name: str


@dataclass
class UrlFile:
    """
    A file that can be located at a URL
    """  # Field exstras: {}

    url: str  # Field exstras: {}
    mime_type: str | None = None  # Field exstras: {}
    detail: Detail | None = None


@dataclass
class Base64File:
    """
    A file already encoded as base64
    """  # Field exstras: {}

    mime_type: str  # Field exstras: {}
    data: str  # Field exstras: {}
    source_url: str | None = None  # Field exstras: {}
    detail: Detail | None = None


@dataclass
class ObjectStoragePointer:
    """
    A file stored in an object storage backend, without data.
    This struct can be stored in the database. It's used by `StoredFile` (`StoredInput`).
    Note: `File` supports both `ObjectStorageFilePointer` and `ObjectStorageFile`.
    """  # Field exstras: {}

    mime_type: str  # Field exstras: {}
    storage_path: str  # Field exstras: {}
    source_url: str | None = None  # Field exstras: {}
    detail: Detail | None = None


@dataclass
class ObjectStorageError:
    """
    A file that we failed to read from object storage.
    This struct can NOT be stored in the database.
    """  # Field exstras: {}

    mime_type: str  # Field exstras: {}
    storage_path: str  # Field exstras: {}
    source_url: str | None = None  # Field exstras: {}
    detail: Detail | None = None  # Field exstras: {}
    error: str | None = None


@dataclass
class Arguments:
    """
    A newtype wrapper around Map<String, Value> for template and system arguments
    """


class Role(Enum):
    user = 'user'
    assistant = 'assistant'


@dataclass
class InputMessageContent1:
    """
    InputMessages are validated against the input schema of the Function
    and then templated and transformed into RequestMessages for a particular Variant.
    They might contain tool calls or tool results along with text.
    The abstraction we use to represent this is ContentBlock, which is a union of Text, ToolCall, and ToolResult.
    ContentBlocks are collected into RequestMessages.
    These RequestMessages are collected into a ModelInferenceRequest,
    which should contain all information needed by a ModelProvider to perform the
    inference that is called for.
    """  # Field exstras: {}

    text: str  # Field exstras: {'const': 'text'}
    type: Literal['text'] = 'text'


@dataclass
class InputMessageContent2:  # Field exstras: {}
    name: str  # Field exstras: {}
    arguments: Arguments  # Field exstras: {'const': 'template'}
    type: Literal['template'] = 'template'


@dataclass
class InputMessageContent3(ToolCall):
    """
    `ToolCallWrapper` helps us disambiguate between `ToolCall` (no `raw_*`) and `InferenceResponseToolCall` (has `raw_*`).
    """  # Field exstras: {'const': 'tool_call'}

    type: Literal['tool_call'] = 'tool_call'


@dataclass
class InputMessageContent4(InferenceResponseToolCall):
    """
    `ToolCallWrapper` helps us disambiguate between `ToolCall` (no `raw_*`) and `InferenceResponseToolCall` (has `raw_*`).
    """  # Field exstras: {'const': 'tool_call'}

    type: Literal['tool_call'] = 'tool_call'


@dataclass
class InputMessageContent5:
    """
    A ToolResult is the outcome of a ToolCall, which we may want to present back to the model
    """  # Field exstras: {}

    name: str  # Field exstras: {}
    result: str  # Field exstras: {}
    id: str  # Field exstras: {'const': 'tool_result'}
    type: Literal['tool_result'] = 'tool_result'


@dataclass
class InputMessageContent6:
    """
    Struct that represents raw text content that should be passed directly to the model
    without any template processing or validation
    """  # Field exstras: {}

    value: str  # Field exstras: {'const': 'raw_text'}
    type: Literal['raw_text'] = 'raw_text'


@dataclass
class InputMessageContent7:
    """
    Struct that represents a model's reasoning
    """  # Field exstras: {'const': 'thought'}

    type: Literal['thought'] = 'thought'  # Field exstras: {}
    text: str | None = (
        None  # Field exstras: {'description': 'An optional signature - currently, this is only used with Anthropic,\nand is ignored by other providers.'}
    )
    signature: str | None = None
    """
    An optional signature - currently, this is only used with Anthropic,
    and is ignored by other providers.
    """  # Field exstras: {}
    summary: list[ThoughtSummaryBlock] | None = (
        None  # Field exstras: {'description': "When set, this 'Thought' block will only be used for providers\nmatching this type (e.g. `anthropic`). Other providers will emit\na warning and discard the block."}
    )
    field_internal_provider_type: str | None = None
    """
    When set, this 'Thought' block will only be used for providers
    matching this type (e.g. `anthropic`). Other providers will emit
    a warning and discard the block.
    """


@dataclass
class InputMessageContent8(UrlFile):
    """
    A file for an inference or a datapoint.
    """  # Field exstras: {'const': 'file'}

    type: Literal['file'] = 'file'


@dataclass
class InputMessageContent9(Base64File):
    """
    A file for an inference or a datapoint.
    """  # Field exstras: {'const': 'file'}

    type: Literal['file'] = 'file'


@dataclass
class InputMessageContent10(ObjectStoragePointer):
    """
    A file for an inference or a datapoint.
    """  # Field exstras: {'const': 'file'}

    type: Literal['file'] = 'file'


@dataclass
class InputMessageContent11(ObjectStorageFile):
    """
    A file for an inference or a datapoint.
    """  # Field exstras: {'const': 'file'}

    type: Literal['file'] = 'file'


@dataclass
class InputMessageContent12(ObjectStorageError):
    """
    A file for an inference or a datapoint.
    """  # Field exstras: {'const': 'file'}

    type: Literal['file'] = 'file'


@dataclass
class InputMessageContent13:
    """
    An unknown content block type, used to allow passing provider-specific
    content blocks (e.g. Anthropic's `redacted_thinking`) in and out
    of TensorZero.
    The `data` field holds the original content block from the provider,
    without any validation or transformation by TensorZero.
    """  # Field exstras: {'description': 'The underlying content block to be passed to the model provider.'}

    data: Any
    """
    The underlying content block to be passed to the model provider.
    """  # Field exstras: {'const': 'unknown'}
    type: Literal['unknown'] = (
        'unknown'  # Field exstras: {'description': 'A fully-qualified name specifying when this content block should\nbe included in the model provider input.'}
    )
    model_provider_name: str | None = None
    """
    A fully-qualified name specifying when this content block should
    be included in the model provider input.
    """


ToolCallWrapper = ToolCall | InferenceResponseToolCall


@dataclass
class File1:
    """
    A file that can be located at a URL
    """  # Field exstras: {}

    url: str  # Field exstras: {'const': 'url'}
    file_type: Literal['url'] = 'url'  # Field exstras: {}
    mime_type: str | None = None  # Field exstras: {}
    detail: Detail | None = None


@dataclass
class File2:
    """
    A file already encoded as base64
    """  # Field exstras: {}

    mime_type: str  # Field exstras: {}
    data: str  # Field exstras: {'const': 'base64'}
    file_type: Literal['base64'] = 'base64'  # Field exstras: {}
    source_url: str | None = None  # Field exstras: {}
    detail: Detail | None = None


@dataclass
class File3:
    """
    A file stored in an object storage backend, without data.
    This struct can be stored in the database. It's used by `StoredFile` (`StoredInput`).
    Note: `File` supports both `ObjectStorageFilePointer` and `ObjectStorageFile`.
    """  # Field exstras: {}

    mime_type: str  # Field exstras: {}
    storage_path: str  # Field exstras: {'const': 'object_storage_pointer'}
    file_type: Literal['object_storage_pointer'] = (
        'object_storage_pointer'  # Field exstras: {}
    )
    source_url: str | None = None  # Field exstras: {}
    detail: Detail | None = None


@dataclass
class File4:
    """
    A file stored in an object storage backend, with data.
    This struct can NOT be stored in the database.
    Note: `File` supports both `ObjectStorageFilePointer` and `ObjectStorageFile`.
    """  # Field exstras: {}

    mime_type: str  # Field exstras: {}
    storage_path: str  # Field exstras: {}
    data: str  # Field exstras: {'const': 'object_storage'}
    file_type: Literal['object_storage'] = 'object_storage'  # Field exstras: {}
    source_url: str | None = None  # Field exstras: {}
    detail: Detail | None = None


@dataclass
class File5:
    """
    A file that we failed to read from object storage.
    This struct can NOT be stored in the database.
    """  # Field exstras: {}

    mime_type: str  # Field exstras: {}
    storage_path: str  # Field exstras: {'const': 'object_storage_error'}
    file_type: Literal['object_storage_error'] = (
        'object_storage_error'  # Field exstras: {}
    )
    source_url: str | None = None  # Field exstras: {}
    detail: Detail | None = None  # Field exstras: {}
    error: str | None = None


File = File1 | File2 | File3 | File4 | File5


@dataclass
class NestedMetadata:  # Field exstras: {}
    key: str  # Field exstras: {}
    value: str


@dataclass
class ContentBlockChatOutput1:
    """
    InputMessages are validated against the input schema of the Function
    and then templated and transformed into RequestMessages for a particular Variant.
    They might contain tool calls or tool results along with text.
    The abstraction we use to represent this is ContentBlock, which is a union of Text, ToolCall, and ToolResult.
    ContentBlocks are collected into RequestMessages.
    These RequestMessages are collected into a ModelInferenceRequest,
    which should contain all information needed by a ModelProvider to perform the
    inference that is called for.
    """  # Field exstras: {}

    text: str  # Field exstras: {'const': 'text'}
    type: Literal['text'] = 'text'


@dataclass
class ContentBlockChatOutput2:
    """
    An InferenceResponseToolCall is a request by a model to call a Tool
    in the form that we return to the client / ClickHouse
    """  # Field exstras: {'description': 'A Tool Call ID to match up with tool call responses. See #4058.'}

    id: str
    """
    A Tool Call ID to match up with tool call responses. See #4058.
    """  # Field exstras: {'description': 'The name of the tool to call, as generated by the model.'}
    raw_name: str
    """
    The name of the tool to call, as generated by the model.
    """  # Field exstras: {'description': 'The raw arguments JSON string of the tool to call, as generated by the model.'}
    raw_arguments: str
    """
    The raw arguments JSON string of the tool to call, as generated by the model.
    """  # Field exstras: {'const': 'tool_call'}
    type: Literal['tool_call'] = (
        'tool_call'  # Field exstras: {'description': 'The name of the tool to call, validated against tool configs. If not present, it means the tool call was invalid.'}
    )
    name: str | None = None
    """
    The name of the tool to call, validated against tool configs. If not present, it means the tool call was invalid.
    """  # Field exstras: {'description': 'The arguments of the tool to call, validated against tool configs. If not present, it means the tool call arguments were invalid.'}
    arguments: Any | None = None
    """
    The arguments of the tool to call, validated against tool configs. If not present, it means the tool call arguments were invalid.
    """


@dataclass
class ContentBlockChatOutput3:
    """
    Struct that represents a model's reasoning
    """  # Field exstras: {'const': 'thought'}

    type: Literal['thought'] = 'thought'  # Field exstras: {}
    text: str | None = (
        None  # Field exstras: {'description': 'An optional signature - currently, this is only used with Anthropic,\nand is ignored by other providers.'}
    )
    signature: str | None = None
    """
    An optional signature - currently, this is only used with Anthropic,
    and is ignored by other providers.
    """  # Field exstras: {}
    summary: list[ThoughtSummaryBlock] | None = (
        None  # Field exstras: {'description': "When set, this 'Thought' block will only be used for providers\nmatching this type (e.g. `anthropic`). Other providers will emit\na warning and discard the block."}
    )
    field_internal_provider_type: str | None = None
    """
    When set, this 'Thought' block will only be used for providers
    matching this type (e.g. `anthropic`). Other providers will emit
    a warning and discard the block.
    """


@dataclass
class ContentBlockChatOutput4:
    """
    Defines the types of content block that can come from a `chat` function
    """  # Field exstras: {}

    data: Any  # Field exstras: {'const': 'unknown'}
    type: Literal['unknown'] = 'unknown'  # Field exstras: {}
    model_provider_name: str | None = None


@dataclass
class DatapointMetadataUpdate:
    """
    A request to update the metadata of a datapoint.
    """  # Field exstras: {'description': 'Datapoint name. If omitted, it will be left unchanged. If specified as `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.'}

    name: str | None = None
    """
    Datapoint name. If omitted, it will be left unchanged. If specified as `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.
    """


@dataclass
class JsonDatapointOutputUpdate:
    """
    A request to update the output of a JSON datapoint.
    We intentionally only accept the `raw` field (in a JSON-serialized string), because datapoints can contain invalid outputs, and it's desirable
    for users to run evals against them.
    """  # Field exstras: {'description': 'The raw output of the datapoint. For valid JSON outputs, this should be a JSON-serialized string.'}

    raw: str
    """
    The raw output of the datapoint. For valid JSON outputs, this should be a JSON-serialized string.
    """


@dataclass
class ContentBlock1:
    """
    InputMessages are validated against the input schema of the Function
    and then templated and transformed into RequestMessages for a particular Variant.
    They might contain tool calls or tool results along with text.
    The abstraction we use to represent this is ContentBlock, which is a union of Text, ToolCall, and ToolResult.
    ContentBlocks are collected into RequestMessages.
    These RequestMessages are collected into a ModelInferenceRequest,
    which should contain all information needed by a ModelProvider to perform the
    inference that is called for.
    """  # Field exstras: {}

    text: str  # Field exstras: {'const': 'text'}
    type: Literal['text'] = 'text'


@dataclass
class ContentBlock2:
    """
    Core representation of the types of content that could go into a model provider
    The `PartialEq` impl will panic if we try to compare a `LazyFile`, so we make it
    test-only to prevent production code from panicking.
    This *does not* implement `Deserialize`, since we need object store information
    to produce a `LazyFile::Url`
    """  # Field exstras: {}

    id: str  # Field exstras: {}
    name: str  # Field exstras: {}
    arguments: str  # Field exstras: {'const': 'tool_call'}
    type: Literal['tool_call'] = 'tool_call'


@dataclass
class ContentBlock3:
    """
    A ToolResult is the outcome of a ToolCall, which we may want to present back to the model
    """  # Field exstras: {}

    name: str  # Field exstras: {}
    result: str  # Field exstras: {}
    id: str  # Field exstras: {'const': 'tool_result'}
    type: Literal['tool_result'] = 'tool_result'


@dataclass
class Url:  # Field exstras: {}
    file_url: FileUrl


@dataclass
class ContentBlock4:
    """
    Core representation of the types of content that could go into a model provider
    The `PartialEq` impl will panic if we try to compare a `LazyFile`, so we make it
    test-only to prevent production code from panicking.
    This *does not* implement `Deserialize`, since we need object store information
    to produce a `LazyFile::Url`
    """  # Field exstras: {'const': 'file'}

    type: Literal['file'] = 'file'  # Field exstras: {}
    Url: Url


@dataclass
class ObjectStoragePointer1:  # Field exstras: {}
    metadata: Base64FileMetadata  # Field exstras: {}
    storage_path: str


@dataclass
class ContentBlock6:
    """
    Core representation of the types of content that could go into a model provider
    The `PartialEq` impl will panic if we try to compare a `LazyFile`, so we make it
    test-only to prevent production code from panicking.
    This *does not* implement `Deserialize`, since we need object store information
    to produce a `LazyFile::Url`
    """  # Field exstras: {'const': 'file'}

    type: Literal['file'] = 'file'  # Field exstras: {}
    ObjectStoragePointer: ObjectStoragePointer1


@dataclass
class ContentBlock7:
    """
    Core representation of the types of content that could go into a model provider
    The `PartialEq` impl will panic if we try to compare a `LazyFile`, so we make it
    test-only to prevent production code from panicking.
    This *does not* implement `Deserialize`, since we need object store information
    to produce a `LazyFile::Url`
    """  # Field exstras: {'const': 'file'}

    type: Literal['file'] = 'file'  # Field exstras: {}
    ObjectStorage: ObjectStorageFile


@dataclass
class ContentBlock8:
    """
    Struct that represents a model's reasoning
    """  # Field exstras: {'const': 'thought'}

    type: Literal['thought'] = 'thought'  # Field exstras: {}
    text: str | None = (
        None  # Field exstras: {'description': 'An optional signature - currently, this is only used with Anthropic,\nand is ignored by other providers.'}
    )
    signature: str | None = None
    """
    An optional signature - currently, this is only used with Anthropic,
    and is ignored by other providers.
    """  # Field exstras: {}
    summary: list[ThoughtSummaryBlock] | None = (
        None  # Field exstras: {'description': "When set, this 'Thought' block will only be used for providers\nmatching this type (e.g. `anthropic`). Other providers will emit\na warning and discard the block."}
    )
    field_internal_provider_type: str | None = None
    """
    When set, this 'Thought' block will only be used for providers
    matching this type (e.g. `anthropic`). Other providers will emit
    a warning and discard the block.
    """


@dataclass
class ContentBlock9:
    """
    Represents an unknown provider-specific content block.
    We pass this along as-is without any validation or transformation.
    """  # Field exstras: {'description': 'The underlying content block to be passed to the model provider.'}

    data: Any
    """
    The underlying content block to be passed to the model provider.
    """  # Field exstras: {'const': 'unknown'}
    type: Literal['unknown'] = (
        'unknown'  # Field exstras: {'description': "A fully-qualified name specifying when this content block should\nbe included in the model provider input.\nE.g `tensorzero::model_name::claude-3-7-sonnet-20250219-thinking::provider_name::anthropic-extra-body`\n\nIf set to `Some`, this is compared against the output of `fully_qualified_name` before invoking\na model provider, and stripped from the input if it doesn't match.\nIf set to `None, then this is passed to all model providers.\nIndividual model provider implementation never need to check this field themselves -\nthey only need to produce it with the proper `fully_qualified_name` set."}
    )
    model_provider_name: str | None = None
    """
    A fully-qualified name specifying when this content block should
    be included in the model provider input.
    E.g `tensorzero::model_name::claude-3-7-sonnet-20250219-thinking::provider_name::anthropic-extra-body`

    If set to `Some`, this is compared against the output of `fully_qualified_name` before invoking
    a model provider, and stripped from the input if it doesn't match.
    If set to `None, then this is passed to all model providers.
    Individual model provider implementation never need to check this field themselves -
    they only need to produce it with the proper `fully_qualified_name` set.
    """


@dataclass
class DoubleOptionalExample:
    """
    Example type demonstrating Option<Option<T>> with custom annotations

    This showcases how to use #[schemars(extend(...))] to add custom
    vendor extensions (x-* fields) to the generated JSON schema.
    """  # Field exstras: {'description': 'A regular optional field (single Option)'}

    simple_optional: str | None = None
    """
    A regular optional field (single Option)
    """  # Field exstras: {'description': 'A double-optional field with custom annotation\n\nThe outer Option represents "field may be absent"\nThe inner Option represents "field may be explicitly null"\n\nCustom annotation "x-double-optional" marks this for special handling', 'x_double_optional': True}
    double_optional: str | None | _UnsetType = UNSET
    """
    A double-optional field with custom annotation

    The outer Option represents "field may be absent"
    The inner Option represents "field may be explicitly null"

    Custom annotation "x-double-optional" marks this for special handling
    """  # Field exstras: {'description': 'Another double-optional with multiple custom annotations', 'x_double_optional': True}
    annotated_field: int | None | _UnsetType = UNSET
    """
    Another double-optional with multiple custom annotations
    """


@dataclass
class LazyFile1:  # Field exstras: {}
    Url: Url


@dataclass
class LazyFile3:  # Field exstras: {}
    ObjectStoragePointer: ObjectStoragePointer1


@dataclass
class LazyFile4:  # Field exstras: {}
    ObjectStorage: ObjectStorageFile


@dataclass
class NestedOptionalExample:
    """
    Example with nested structures
    """  # Field exstras: {}

    name: str  # Field exstras: {'x_double_optional': True}
    metadata: NestedMetadata | None | _UnsetType = UNSET


@dataclass
class RawText:
    """
    Struct that represents raw text content that should be passed directly to the model
    without any template processing or validation
    """  # Field exstras: {}

    value: str


@dataclass
class Template:  # Field exstras: {}
    name: str  # Field exstras: {}
    arguments: Arguments


@dataclass
class Text:
    """
    InputMessages are validated against the input schema of the Function
    and then templated and transformed into RequestMessages for a particular Variant.
    They might contain tool calls or tool results along with text.
    The abstraction we use to represent this is ContentBlock, which is a union of Text, ToolCall, and ToolResult.
    ContentBlocks are collected into RequestMessages.
    These RequestMessages are collected into a ModelInferenceRequest,
    which should contain all information needed by a ModelProvider to perform the
    inference that is called for.
    """  # Field exstras: {}

    text: str


@dataclass
class ToolCallChunk:  # Field exstras: {}
    id: str  # Field exstras: {}
    raw_arguments: str  # Field exstras: {}
    raw_name: str | None = None


@dataclass
class ToolResult:
    """
    A ToolResult is the outcome of a ToolCall, which we may want to present back to the model
    """  # Field exstras: {}

    name: str  # Field exstras: {}
    result: str  # Field exstras: {}
    id: str


@dataclass
class TransformExample:
    """
    Example showing a transform function approach
    """  # Field exstras: {}

    regular_field: str  # Field exstras: {}
    double_optional_field: bool | None = None


@dataclass
class Unknown:
    """
    Struct that represents an unknown provider-specific content block.
    We pass this along as-is without any validation or transformation.
    """  # Field exstras: {'description': 'The underlying content block to be passed to the model provider.'}

    data: Any
    """
    The underlying content block to be passed to the model provider.
    """  # Field exstras: {'description': 'A fully-qualified name specifying when this content block should\nbe included in the model provider input.'}
    model_provider_name: str | None = None
    """
    A fully-qualified name specifying when this content block should
    be included in the model provider input.
    """


@dataclass
class UpdateDatapointsResponse:
    """
    A response to a request to update one or more datapoints in a dataset.
    """  # Field exstras: {'description': 'The IDs of the datapoints that were updated.\nThese are newly generated IDs for UpdateDatapoint requests, and they are the same IDs for UpdateDatapointMetadata requests.'}

    ids: list[str]
    """
    The IDs of the datapoints that were updated.
    These are newly generated IDs for UpdateDatapoint requests, and they are the same IDs for UpdateDatapointMetadata requests.
    """


PendingObjectStoreFile = ObjectStorageFile


@dataclass
class ProviderTool:  # Field exstras: {}
    tool: Any  # Field exstras: {'title': 'ProviderToolScope'}
    scope: ProviderToolScope1 | None = None


@dataclass
class InputMessage:
    """
    InputMessage and Role are our representation of the input sent by the client
    prior to any processing into LLM representations below.
    `InputMessage` has a custom deserializer that addresses legacy data formats that we used to support (see input_message.rs).
    """  # Field exstras: {}

    role: Role  # Field exstras: {}
    content: list[
        InputMessageContent1
        | InputMessageContent2
        | InputMessageContent3
        | InputMessageContent4
        | InputMessageContent5
        | InputMessageContent6
        | InputMessageContent7
        | InputMessageContent8
        | InputMessageContent9
        | InputMessageContent10
        | InputMessageContent11
        | InputMessageContent12
        | InputMessageContent13
    ]


@dataclass
class Input:
    """
    A request is made that contains an Input
    """  # Field exstras: {}

    system: str | Arguments | None = None  # Field exstras: {}
    messages: list[InputMessage] | None = field(default_factory=lambda: [])


@dataclass
class DynamicToolParams:
    """
    Wire/API representation of dynamic tool parameters for inference requests.

    This type is the **wire format** for tool configurations used in API requests and responses.
    It distinguishes between static tools (configured in the function) and dynamic tools
    (provided at runtime), allowing clients to reference pre-configured tools by name or
    provide new tools on-the-fly.

    # Purpose
    - Accept tool parameters in inference API requests (e.g., `/inference/{function_name}`)
    - Expose tool configurations in API responses for stored inferences
    - Support Python and TypeScript client bindings
    - Allow runtime customization of tool behavior

    # Fields
    - `allowed_tools`: Names of static tools from function config to use (subset selection)
    - `additional_tools`: New tools defined at runtime (not in static config)
    - `tool_choice`: Override the function's default tool choice strategy
    - `parallel_tool_calls`: Override whether parallel tool calls are enabled
    - `provider_tools`: Provider-specific tool configurations (not persisted to database)

    # Key Differences from ToolCallConfigDatabaseInsert
    - **Separate lists**: Maintains distinction between static (`allowed_tools`) and dynamic (`additional_tools`) tools
    - **By reference**: Static tools referenced by name, not duplicated
    - **Has provider_tools**: Can specify provider-specific tool configurations
    - **Has bindings**: Exposed to Python/TypeScript via `pyo3` and `ts_rs`

    # Conversion to Storage Format
    Converting from `DynamicToolParams` to `ToolCallConfigDatabaseInsert` is a **lossy** operation:
    1. Static tools (from `allowed_tools` names) are resolved from function config
    2. Dynamic tools (from `additional_tools`) are included as-is
    3. Both lists are merged into a single `tools_available` list
    4. The distinction between static and dynamic tools is lost
    5. `provider_tools` are dropped (not stored)

    Use `FunctionConfig::dynamic_tool_params_to_database_insert()` for this conversion.

    # Conversion from Storage Format
    Converting from `ToolCallConfigDatabaseInsert` back to `DynamicToolParams` attempts to reconstruct the original:
    1. Tools that match function config tool names → `allowed_tools`
    2. Tools that don't match function config → `additional_tools`
    3. `provider_tools` is set to `None` (cannot be recovered)

    Use `FunctionConfig::database_insert_to_dynamic_tool_params()` for this conversion.

    # Example
    ```rust,ignore
    // API request with dynamic tool params
    let params = DynamicToolParams {
        allowed_tools: Some(vec!["calculator".to_string()]),  // Use only the calculator tool from config
        additional_tools: Some(vec![Tool {  runtime tool  }]),  // Add a new tool
        tool_choice: Some(ToolChoice::Required),
        parallel_tool_calls: Some(true),
        provider_tools: None,
    };

    // Convert to storage format (merge tools, lose distinction)
    let db_insert = function_config
        .dynamic_tool_params_to_database_insert(params, &static_tools)?
        .unwrap_or_default();

    // db_insert.tools_available now contains both the calculator tool (from config)
    // and the runtime tool (from additional_tools), merged together
    ```

    See also: [`ToolCallConfigDatabaseInsert`] for the storage/database format
    """  # Field exstras: {'description': 'A subset of static tools configured for the function that the inference is allowed to use. Optional.\nIf not provided, all static tools are allowed.'}

    allowed_tools: list[str] | None = None
    """
    A subset of static tools configured for the function that the inference is allowed to use. Optional.
    If not provided, all static tools are allowed.
    """  # Field exstras: {'description': 'Tools that the user provided at inference time (not in function config), in addition to the function-configured\ntools, that are also allowed.'}
    additional_tools: list[Tool] | None = None
    """
    Tools that the user provided at inference time (not in function config), in addition to the function-configured
    tools, that are also allowed.
    """  # Field exstras: {'description': 'User-specified tool choice strategy. If provided during inference, it will override the function-configured tool choice.\nOptional.'}
    tool_choice: ToolChoice1 | ToolChoice2 | None = None
    """
    User-specified tool choice strategy. If provided during inference, it will override the function-configured tool choice.
    Optional.
    """  # Field exstras: {'description': 'Whether to use parallel tool calls in the inference. Optional.\nIf provided during inference, it will override the function-configured parallel tool calls.'}
    parallel_tool_calls: bool | None = None
    """
    Whether to use parallel tool calls in the inference. Optional.
    If provided during inference, it will override the function-configured parallel tool calls.
    """  # Field exstras: {'description': 'Provider-specific tool configurations (not persisted to database)'}
    provider_tools: list[ProviderTool] | None = None
    """
    Provider-specific tool configurations (not persisted to database)
    """


@dataclass
class UpdateChatDatapointRequest:
    """
    An update request for a chat datapoint.
    For any fields that are optional in ChatInferenceDatapoint, the request field distinguishes between an omitted field, `null`, and a value:
    - If the field is omitted, it will be left unchanged.
    - If the field is specified as `null`, it will be set to `null`.
    - If the field has a value, it will be set to the provided value.

    In Rust this is modeled as an `Option<Option<T>>`, where `None` means "unchanged" and `Some(None)` means "set to `null`" and `Some(Some(T))` means "set to the provided value".
    """  # Field exstras: {'description': 'The ID of the datapoint to update. Required.'}

    id: str
    """
    The ID of the datapoint to update. Required.
    """  # Field exstras: {'description': 'Datapoint input. If omitted, it will be left unchanged.'}
    input: Input | None = None
    """
    Datapoint input. If omitted, it will be left unchanged.
    """  # Field exstras: {'description': 'Chat datapoint output. If omitted, it will be left unchanged. If empty, it will be cleared. Otherwise,\nit will overwrite the existing output.'}
    output: (
        list[
            ContentBlockChatOutput1
            | ContentBlockChatOutput2
            | ContentBlockChatOutput3
            | ContentBlockChatOutput4
        ]
        | None
    ) = None
    """
    Chat datapoint output. If omitted, it will be left unchanged. If empty, it will be cleared. Otherwise,
    it will overwrite the existing output.
    """  # Field exstras: {'description': 'Datapoint tool parameters. If omitted, it will be left unchanged. If specified as `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.'}
    tool_params: DynamicToolParams | None = None
    """
    Datapoint tool parameters. If omitted, it will be left unchanged. If specified as `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.
    """  # Field exstras: {'description': 'Datapoint tags. If omitted, it will be left unchanged. If empty, it will be cleared. Otherwise,\nit will be overwrite the existing tags.'}
    tags: dict[str, Any] | None = None
    """
    Datapoint tags. If omitted, it will be left unchanged. If empty, it will be cleared. Otherwise,
    it will be overwrite the existing tags.
    """  # Field exstras: {'description': 'Metadata fields. If omitted, it will be left unchanged.'}
    metadata: DatapointMetadataUpdate | None = None
    """
    Metadata fields. If omitted, it will be left unchanged.
    """


@dataclass
class UpdateJsonDatapointRequest:
    """
    An update request for a JSON datapoint.
    For any fields that are optional in JsonInferenceDatapoint, the request field distinguishes between an omitted field, `null`, and a value:
    - If the field is omitted, it will be left unchanged.
    - If the field is specified as `null`, it will be set to `null`.
    - If the field has a value, it will be set to the provided value.

    In Rust this is modeled as an `Option<Option<T>>`, where `None` means "unchanged" and `Some(None)` means "set to `null`" and `Some(Some(T))` means "set to the provided value".
    """  # Field exstras: {'description': 'The ID of the datapoint to update. Required.'}

    id: str
    """
    The ID of the datapoint to update. Required.
    """  # Field exstras: {'description': 'Datapoint input. If omitted, it will be left unchanged.'}
    input: Input | None = None
    """
    Datapoint input. If omitted, it will be left unchanged.
    """  # Field exstras: {'description': 'JSON datapoint output. If omitted, it will be left unchanged. If `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.\nThis will be parsed and validated against output_schema, and valid `raw` values will be parsed and stored as `parsed`. Invalid `raw` values will\nalso be stored, because we allow invalid outputs in datapoints by design.'}
    output: JsonDatapointOutputUpdate | None = None
    """
    JSON datapoint output. If omitted, it will be left unchanged. If `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.
    This will be parsed and validated against output_schema, and valid `raw` values will be parsed and stored as `parsed`. Invalid `raw` values will
    also be stored, because we allow invalid outputs in datapoints by design.
    """  # Field exstras: {'description': "The output schema of the JSON datapoint. If omitted, it will be left unchanged. If specified as `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.\nIf not provided, the function's output schema will be used."}
    output_schema: Any | None = None
    """
    The output schema of the JSON datapoint. If omitted, it will be left unchanged. If specified as `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.
    If not provided, the function's output schema will be used.
    """  # Field exstras: {'description': 'Datapoint tags. If omitted, it will be left unchanged. If empty, it will be cleared. Otherwise,\nit will be overwrite the existing tags.'}
    tags: dict[str, Any] | None = None
    """
    Datapoint tags. If omitted, it will be left unchanged. If empty, it will be cleared. Otherwise,
    it will be overwrite the existing tags.
    """  # Field exstras: {'description': 'Metadata fields. If omitted, it will be left unchanged.'}
    metadata: DatapointMetadataUpdate | None = None
    """
    Metadata fields. If omitted, it will be left unchanged.
    """


@dataclass
class UpdateDatapointRequest1:
    """
    Request to update a chat datapoint.
    """  # Field exstras: {'description': 'The ID of the datapoint to update. Required.'}

    id: str
    """
    The ID of the datapoint to update. Required.
    """  # Field exstras: {'const': 'chat'}
    type: Literal['chat'] = (
        'chat'  # Field exstras: {'description': 'Datapoint input. If omitted, it will be left unchanged.'}
    )
    input: Input | None = None
    """
    Datapoint input. If omitted, it will be left unchanged.
    """  # Field exstras: {'description': 'Chat datapoint output. If omitted, it will be left unchanged. If empty, it will be cleared. Otherwise,\nit will overwrite the existing output.'}
    output: (
        list[
            ContentBlockChatOutput1
            | ContentBlockChatOutput2
            | ContentBlockChatOutput3
            | ContentBlockChatOutput4
        ]
        | None
    ) = None
    """
    Chat datapoint output. If omitted, it will be left unchanged. If empty, it will be cleared. Otherwise,
    it will overwrite the existing output.
    """  # Field exstras: {'description': 'Datapoint tool parameters. If omitted, it will be left unchanged. If specified as `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.'}
    tool_params: DynamicToolParams | None = None
    """
    Datapoint tool parameters. If omitted, it will be left unchanged. If specified as `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.
    """  # Field exstras: {'description': 'Datapoint tags. If omitted, it will be left unchanged. If empty, it will be cleared. Otherwise,\nit will be overwrite the existing tags.'}
    tags: dict[str, Any] | None = None
    """
    Datapoint tags. If omitted, it will be left unchanged. If empty, it will be cleared. Otherwise,
    it will be overwrite the existing tags.
    """  # Field exstras: {'description': 'Metadata fields. If omitted, it will be left unchanged.'}
    metadata: DatapointMetadataUpdate | None = None
    """
    Metadata fields. If omitted, it will be left unchanged.
    """


@dataclass
class UpdateDatapointRequest2:
    """
    Request to update a JSON datapoint.
    """  # Field exstras: {'description': 'The ID of the datapoint to update. Required.'}

    id: str
    """
    The ID of the datapoint to update. Required.
    """  # Field exstras: {'const': 'json'}
    type: Literal['json'] = (
        'json'  # Field exstras: {'description': 'Datapoint input. If omitted, it will be left unchanged.'}
    )
    input: Input | None = None
    """
    Datapoint input. If omitted, it will be left unchanged.
    """  # Field exstras: {'description': 'JSON datapoint output. If omitted, it will be left unchanged. If `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.\nThis will be parsed and validated against output_schema, and valid `raw` values will be parsed and stored as `parsed`. Invalid `raw` values will\nalso be stored, because we allow invalid outputs in datapoints by design.'}
    output: JsonDatapointOutputUpdate | None = None
    """
    JSON datapoint output. If omitted, it will be left unchanged. If `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.
    This will be parsed and validated against output_schema, and valid `raw` values will be parsed and stored as `parsed`. Invalid `raw` values will
    also be stored, because we allow invalid outputs in datapoints by design.
    """  # Field exstras: {'description': "The output schema of the JSON datapoint. If omitted, it will be left unchanged. If specified as `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.\nIf not provided, the function's output schema will be used."}
    output_schema: Any | None = None
    """
    The output schema of the JSON datapoint. If omitted, it will be left unchanged. If specified as `null`, it will be set to `null`. If specified as a value, it will be set to the provided value.
    If not provided, the function's output schema will be used.
    """  # Field exstras: {'description': 'Datapoint tags. If omitted, it will be left unchanged. If empty, it will be cleared. Otherwise,\nit will be overwrite the existing tags.'}
    tags: dict[str, Any] | None = None
    """
    Datapoint tags. If omitted, it will be left unchanged. If empty, it will be cleared. Otherwise,
    it will be overwrite the existing tags.
    """  # Field exstras: {'description': 'Metadata fields. If omitted, it will be left unchanged.'}
    metadata: DatapointMetadataUpdate | None = None
    """
    Metadata fields. If omitted, it will be left unchanged.
    """


@dataclass
class ContentBlock5:
    """
    Core representation of the types of content that could go into a model provider
    The `PartialEq` impl will panic if we try to compare a `LazyFile`, so we make it
    test-only to prevent production code from panicking.
    This *does not* implement `Deserialize`, since we need object store information
    to produce a `LazyFile::Url`
    """  # Field exstras: {'const': 'file'}

    type: Literal['file'] = 'file'  # Field exstras: {}
    Base64: PendingObjectStoreFile


ContentBlock = (
    ContentBlock1
    | ContentBlock2
    | ContentBlock3
    | ContentBlock4
    | ContentBlock5
    | ContentBlock6
    | ContentBlock7
    | ContentBlock8
    | ContentBlock9
)


@dataclass
class LazyFile2:  # Field exstras: {}
    Base64: PendingObjectStoreFile


LazyFile = LazyFile1 | LazyFile2 | LazyFile3 | LazyFile4


@dataclass
class UpdateDatapointsRequest:
    """
    Request to update one or more datapoints in a dataset.
    """  # Field exstras: {'description': 'The datapoints to update.'}

    datapoints: list[UpdateDatapointRequest1 | UpdateDatapointRequest2]
    """
    The datapoints to update.
    """
