#:schema None
# TODO: add the line above to editor config and remove from here
# NOTE: This is an example configuration file for TensorZero.
#       You can use this file as a reference for your own configuration by adding
#       your own models, functions, and metrics.

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  GENERAL                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[api]
bind_address = "0.0.0.0:3000"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                   MODELS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[models."gpt-3.5-turbo"]
routing = ["openai", "azure"]

[models."gpt-3.5-turbo".providers.openai]
type = "openai"
model_name = "gpt-3.5-turbo"

[models."gpt-3.5-turbo".providers.azure]
type = "azure"
model_name = "gpt-35-turbo"
api_base = "https://your-endpoint.openai.azure.com/"
deployment_id = "gpt-35-turbo"

[models.claude-3-haiku-20240307]
routing = ["anthropic", "aws-bedrock"]

[models.claude-3-haiku-20240307.providers.anthropic]
type = "anthropic"
model_name = "claude-3-haiku-20240307"

[models.claude-3-haiku-20240307.providers.aws-bedrock]
type = "aws_bedrock"
model_id = "anthropic.claude-3-haiku-20240307-v1:0"

[models.test]
routing = ["good"]

[models.test.providers.good]
type = "dummy"
model_name = "good"

[models.error]
routing = ["error"]

[models.error.providers.error]
type = "dummy"
model_name = "error"

[models.test_fallback]
routing = ["error", "good"]

[models.test_fallback.providers.error]
type = "dummy"
model_name = "error"

[models.test_fallback.providers.good]
type = "dummy"
model_name = "good"

[models.json]
routing = ["json"]

[models.json.providers.json]
type = "dummy"
model_name = "json"


# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                 FUNCTIONS                                  │
# └────────────────────────────────────────────────────────────────────────────┘

[functions.generate_draft]
type = "chat"
system_schema = "functions/generate_draft/system_schema.json"
output_schema = "functions/generate_draft/output_schema.json"

[functions.generate_draft.variants.openai_promptA]
type = "chat_completion"
weight = 0.9
model = "gpt-3.5-turbo"
system_template = "functions/generate_draft/promptA/system_template.minijinja"

[functions.generate_draft.variants.openai_promptB]
type = "chat_completion"
weight = 0.1
model = "gpt-3.5-turbo"
system_template = "functions/generate_draft/promptB/system_template.minijinja"

[functions.basic_test]
type = "chat"
system_schema = "functions/basic_test/system_schema.json"

[functions.basic_test.variants.test]
type = "chat_completion"
weight = 1
model = "test"
system_template = "functions/basic_test/prompt/system_template.minijinja"

[functions.model_fallback_test]
type = "chat"
system_schema = "functions/basic_test/system_schema.json"

[functions.model_fallback_test.variants.test]
type = "chat_completion"
weight = 1
model = "test_fallback"
system_template = "functions/basic_test/prompt/system_template.minijinja"

[functions.json_fail]
type = "chat"
system_schema = "functions/basic_test/system_schema.json"
output_schema = "functions/basic_test/output_schema.json"

[functions.json_fail.variants.test]
type = "chat_completion"
weight = 1
model = "test"
system_template = "functions/basic_test/prompt/system_template.minijinja"

[functions.json_succeed]
type = "chat"
system_schema = "functions/basic_test/system_schema.json"
output_schema = "functions/basic_test/output_schema.json"

[functions.json_succeed.variants.test]
type = "chat_completion"
weight = 1
model = "json"
system_template = "functions/basic_test/prompt/system_template.minijinja"

[functions.variant_failover]
type = "chat"
system_schema = "functions/basic_test/system_schema.json"

[functions.variant_failover.variants.good]
type = "chat_completion"
weight = 0.5
model = "test"
system_template = "functions/basic_test/prompt/system_template.minijinja"

[functions.variant_failover.variants.error]
type = "chat_completion"
weight = 0.5
model = "error"
system_template = "functions/basic_test/prompt/system_template.minijinja"


# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  METRICS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[metrics.task_success]
type = "boolean"    # "boolean", "float"
optimize = "max"    # "min", "max"
level = "inference" # "inference", "episode"

[metrics.goal_achieved]
type = "boolean"  # "boolean", "float"
optimize = "max"  # "min", "max"
level = "episode" # "inference", "episode"

[metrics.user_rating]
type = "float"
optimize = "max"
level = "episode"

[metrics.brevity_score]
type = "float"
optimize = "max"
level = "inference"
