//! Wire format types for tool calls and results.
//!
//! This module contains the types used in API requests and responses for tool interactions:
//! - `ToolCall` - A request by an LLM to call a tool
//! - `ToolResult` - The response from a tool call
//! - `ToolChoice` - Strategy for how the LLM should choose tools

#[cfg(feature = "pyo3")]
use pyo3::prelude::*;
use schemars::JsonSchema;
use serde::{Deserialize, Serialize};
use serde_json::Value;
use tensorzero_derive::export_schema;

/// In most cases, tool call arguments are a string.
/// However, when looping back from an inference response, they will be an object.
fn deserialize_tool_call_arguments<'de, D>(deserializer: D) -> Result<String, D::Error>
where
    D: serde::Deserializer<'de>,
{
    use serde::de::Error;
    let value = Value::deserialize(deserializer)?;
    match value {
        Value::String(s) => Ok(s),
        Value::Object(_) => Ok(value.to_string()),
        _ => Err(D::Error::custom(
            "`arguments` must be a string or an object",
        )),
    }
}

#[cfg_attr(feature = "ts-bindings", derive(ts_rs::TS))]
#[derive(Clone, Debug, Deserialize, PartialEq, Serialize, JsonSchema)]
#[cfg_attr(feature = "ts-bindings", ts(export))]
#[cfg_attr(feature = "pyo3", pyclass(get_all, str))]
#[export_schema]
pub struct ToolCall {
    pub id: String,
    pub name: String,
    #[serde(deserialize_with = "deserialize_tool_call_arguments")] // String or Object --> String
    pub arguments: String,
}

impl std::fmt::Display for ToolCall {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let json = serde_json::to_string_pretty(self).map_err(|_| std::fmt::Error)?;
        write!(f, "{json}")
    }
}

#[cfg(feature = "pyo3")]
#[pymethods]
impl ToolCall {
    pub fn __repr__(&self) -> String {
        self.to_string()
    }
}

/// An InferenceResponseToolCall is a request by a model to call a Tool
/// in the form that we return to the client / ClickHouse
/// This includes some synactic sugar (parsing / validation of the tool arguments)
/// in the `arguments` field and the name in the `name` field.
/// We support looping this back through the TensorZero inference API via the ToolCallWrapper
#[cfg_attr(feature = "ts-bindings", derive(ts_rs::TS))]
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, JsonSchema)]
#[cfg_attr(feature = "ts-bindings", ts(export))]
#[cfg_attr(feature = "pyo3", pyclass(str))]
#[export_schema]
pub struct InferenceResponseToolCall {
    /// A Tool Call ID to match up with tool call responses. See #4058.
    pub id: String,

    /// The name of the tool to call, as generated by the model.
    pub raw_name: String,

    /// The raw arguments JSON string of the tool to call, as generated by the model.
    pub raw_arguments: String,

    /// The name of the tool to call, validated against tool configs. If not present, it means the tool call was invalid.
    pub name: Option<String>,

    /// The arguments of the tool to call, validated against tool configs. If not present, it means the tool call arguments were invalid.
    pub arguments: Option<Value>,
}

impl std::fmt::Display for InferenceResponseToolCall {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let json = serde_json::to_string_pretty(self).map_err(|_| std::fmt::Error)?;
        write!(f, "{json}")
    }
}

#[cfg(feature = "pyo3")]
#[pymethods]
impl InferenceResponseToolCall {
    pub fn __repr__(&self) -> String {
        self.to_string()
    }
}

/// `ToolCallWrapper` helps us disambiguate between `ToolCall` (no `raw_*`) and `InferenceResponseToolCall` (has `raw_*`).
/// Typically tool calls come from previous inferences and are therefore outputs of TensorZero (`InferenceResponseToolCall`)
/// but they may also be constructed client side or through the OpenAI endpoint `ToolCall` so we support both via this wrapper.
#[cfg_attr(feature = "ts-bindings", derive(ts_rs::TS))]
#[derive(Clone, Debug, Deserialize, PartialEq, Serialize, JsonSchema)]
#[cfg_attr(feature = "ts-bindings", ts(export))]
#[serde(untagged)]
#[export_schema]
pub enum ToolCallWrapper {
    // The format we store in the database
    #[schemars(title = "InputMessageContentToolCall")]
    ToolCall(ToolCall),
    // The format we send on an inference response, with parsed name and arguments
    #[schemars(title = "InputMessageContentInferenceResponseToolCall")]
    InferenceResponseToolCall(InferenceResponseToolCall),
}

#[derive(JsonSchema)]
pub(crate) struct ToolCallWrapperJsonSchema {
    #[serde(flatten)]
    _tool_call_wrapper: ToolCallWrapper,
}

impl ToolCallWrapper {
    /// Converts a `ToolCallWrapper` into a `ToolCall`.
    ///
    /// - `ToolCallWrapper::ToolCall`: passthrough
    /// - `ToolCallWrapper::InferenceResponseToolCall`: uses raw values, ignores parsed values
    pub fn into_tool_call(self) -> ToolCall {
        self.into()
    }
}

impl InferenceResponseToolCall {
    /// Converts this `InferenceResponseToolCall` into a `ToolCall` using raw values.
    pub fn into_tool_call(self) -> ToolCall {
        self.into()
    }
}

impl From<InferenceResponseToolCall> for ToolCall {
    fn from(tool_call: InferenceResponseToolCall) -> Self {
        ToolCall {
            id: tool_call.id,
            name: tool_call.raw_name,
            arguments: tool_call.raw_arguments,
        }
    }
}

impl From<ToolCallWrapper> for ToolCall {
    fn from(wrapper: ToolCallWrapper) -> Self {
        match wrapper {
            ToolCallWrapper::ToolCall(tool_call) => tool_call,
            ToolCallWrapper::InferenceResponseToolCall(tool_call) => tool_call.into(),
        }
    }
}

/// A ToolResult is the outcome of a ToolCall, which we may want to present back to the model
#[cfg_attr(feature = "pyo3", pyclass(get_all, str))]
#[cfg_attr(feature = "ts-bindings", derive(ts_rs::TS))]
#[derive(Clone, Debug, Deserialize, PartialEq, Serialize, JsonSchema)]
#[cfg_attr(feature = "ts-bindings", ts(export))]
#[serde(deny_unknown_fields)]
#[export_schema]
pub struct ToolResult {
    pub name: String,
    pub result: String,
    pub id: String,
}

impl std::fmt::Display for ToolResult {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let json = serde_json::to_string_pretty(self).map_err(|_| std::fmt::Error)?;
        write!(f, "{json}")
    }
}

#[cfg(feature = "pyo3")]
#[pymethods]
impl ToolResult {
    pub fn __repr__(&self) -> String {
        self.to_string()
    }
}

/// Most inference providers allow the user to force a tool to be used
/// and even specify which tool to be used.
///
/// This enum is used to denote this tool choice.
#[cfg_attr(feature = "ts-bindings", derive(ts_rs::TS))]
#[derive(Clone, Debug, Default, Deserialize, PartialEq, Serialize, JsonSchema)]
#[cfg_attr(feature = "ts-bindings", ts(export))]
#[serde(rename_all = "lowercase")]
#[serde(deny_unknown_fields)]
#[export_schema]
pub enum ToolChoice {
    None,
    #[default]
    Auto,
    Required,
    /// Forces the LLM to call a specific tool. The String is the name of the tool.
    #[schemars(title = "ToolChoiceSpecific")]
    Specific(String),
}
