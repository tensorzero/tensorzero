---
title: GEPA
description: Learn how to use automated prompt engineering to optimize your LLM applications.
---

[GEPA](https://arxiv.org/abs/2507.19457) is an automated prompt engineering algorithm that iteratively refines your [prompt templates](/gateway/create-a-prompt-template) based on an [inference evaluation](/evaluations/inference-evaluations/tutorial).
You can run GEPA using the TensorZero Gateway to optimize the prompt templates of any [TensorZero function](/gateway/configure-functions-and-variants).

GEPA works by repeatedly sampling prompt templates, running evaluations, having an LLM analyze what went well or poorly, and then having an LLM mutate the prompt template based on that analysis.
Mutated templates that improve on the evaluation metrics define a Pareto frontier and can be sampled at later iterations for further refinement.

<Tip>

Learn more about [how to optimize your LLM prompts with GEPA](https://github.com/tensorzero/tensorzero/tree/main/examples/docs/guides/optimization/gepa/) in our Python example on GitHub.

</Tip>

## Optimize an LLM function with GEPA

<Steps>

<Step title="Configure your LLM application">

Define a function and variant for your application.

```toml
[functions.extract_entities]
type = "json"
output_schema = "functions/extract_entities/output_schema.json"

[functions.extract_entities.variants.baseline]
type = "chat_completion"
model = "openai::gpt-5-mini-2025-08-07"
templates.system.path = "functions/extract_entities/initial_prompt/system_template.minijinja"
json_mode = "strict"
```

The variant must have at least one prompt template (e.g., the LLM system instructions).

<Accordion title="Example: Data Extraction (Named Entity Recognition) — Configuration">
```text
You are an assistant that is performing a named entity recognition task.
Your job is to extract entities from a given text.

The entities you are extracting are:

- people
- organizations
- locations
- miscellaneous other entities

Please return the entities in the following JSON format:

{
"person": ["person1", "person2", ...],
"organization": ["organization1", "organization2", ...],
"location": ["location1", "location2", ...],
"miscellaneous": ["miscellaneous1", "miscellaneous2", ...]
}

````
</Accordion>

</Step>

<Step title="Collect your optimization data">

<Tabs>

<Tab title="Historical Inferences">

After deploying the [TensorZero Gateway](/deployment/tensorzero-gateway) with [ClickHouse](/deployment/clickhouse), make [inference calls](/gateway/call-any-llm) to the `extract_entities` function you configured.
TensorZero automatically collects structured data about those inferences, which can later be used as training examples for GEPA.

```python
from tensorzero import ListInferencesRequest

inferences_response = t0.list_inferences(
    request=ListInferencesRequest(
        function_name="extract_entities",
        output_source="inference",
    ),
)
rendered_samples = t0.experimental_render_samples(
    stored_samples=inferences_response.inferences,
    variants={"extract_entities": "baseline"},
)
````

</Tab>

<Tab title="Dataset">

After deploying the [TensorZero Gateway](/deployment/tensorzero-gateway) with [ClickHouse](/deployment/clickhouse), [build a dataset](/gateway/api-reference/datasets-datapoints) for the `extract_entities` function you configured.
You can create datapoints from historical inferences or external/synthetic datasets.

```python
from tensorzero import ListDatapointsRequest

datapoints = t0.list_datapoints(
    dataset_name="extract_entities_dataset",
    request=ListDatapointsRequest(
        function_name="extract_entities",
    ),
)
rendered_samples = t0.experimental_render_samples(
    stored_samples=datapoints.datapoints,
    variants={"extract_entities": "baseline"},
)
```

</Tab>

</Tabs>

GEPA requires two datasets: one for template mutation (train) and one for Pareto frontier estimation (val).

```python
import random

random.shuffle(rendered_samples)
split_idx = len(rendered_samples) // 2
train_samples = rendered_samples[:split_idx]
val_samples = rendered_samples[split_idx:]
```

</Step>

<Step title="Configure an evaluation">

GEPA template refinement is guided by evaluator scores.
Define a [TensorZero Inference Evaluation](/evaluations/inference-evaluations/tutorial) in your application's TensorZero config file.
To demonstrate that GEPA works even with noisy evaluators, we don't provide demonstrations (labels), only an LLM judge.

<Accordion title="Example: Data Extraction (Named Entity Recognition) — Evaluation">
```toml
[evaluations.extract_entities_eval]
type = "static"
function_name = "extract_entities"

[evaluations.extract_entities_eval.evaluators.judge_improvement]
type = "llm_judge"
output_type = "float"
include = { reference_output = true }
optimize = "max"
description = "Compares generated output against reference output for NER quality. Scores: 1 (better), 0 (similar), -1 (worse). Evaluates: correctness (only proper nouns, no common nouns/numbers/metadata), schema compliance, completeness, verbatim entity extraction (exact spelling/capitalization), and absence of duplicate entities."

[evaluations.extract_entities_eval.evaluators.judge_improvement.variants.baseline]
type = "chat_completion"
model = "openai::gpt-5-mini"
system_instructions = "evaluations/extract_entities/judge_improvement/system_instructions.txt"
json_mode = "strict"

````
</Accordion>

<Tip>

The `description` field of an LLM Judge evaluator gives context to the GEPA analyst and mutation LLMs.
Let them know what is being scored and what the score means.

</Tip>

GEPA supports evaluations with any number of evaluators and any evaluator type (LLM judges, code-based metrics, etc.).

</Step>

<Step title="Configure GEPA">

Configure GEPA by specifying the name of your function and evaluation.
You are also free to choose the models used to analyze inferences and generate new templates.
The `analysis_model` reflects on individual inferences, reports on whether they are optimal, need improvement, or are erroneous, and provides suggestions for prompt template improvement.
The `mutation_model` generates new templates based on the collected analysis reports.
We recommend using strong models for these tasks.

```python
from tensorzero import GEPAConfig

optimization_config = GEPAConfig(
    function_name="extract_entities",
    evaluation_name="extract_entities_eval",
    analysis_model="openai::gpt-5.2",
    mutation_model="openai::gpt-5.2",
    initial_variants=["baseline"],
    max_iterations=10,
    max_tokens=16384,
)
````

<Tip>

GEPA optimization can take a while to run, so keep `max_iterations` small.
You can iterate by setting `initial_variants` with the result of a previous GEPA run.

</Tip>

</Step>

<Step title="Launch GEPA">

You can now launch your GEPA optimization job using the TensorZero Gateway:

```python
job_handle = t0.experimental_launch_optimization(
    train_samples=train_samples,
    val_samples=val_samples,
    optimization_config=optimization_config,
)

job_info = t0.experimental_poll_optimization(
    job_handle=job_handle
)
```

</Step>

<Step title="Update your application config">

Review the generated templates and write them to your config directory:

```python
variant_configs = job_info.output["content"]

for variant_name, variant_config in variant_configs.items():
    print(f"\n# Optimized variant: {variant_name}")
    for template_name, template in variant_config["templates"].items():
        print(f"## '{template_name}' template:")
        print(template["path"]["__data"])
```

Finally, add the new variant to your application config.

<Accordion title="Example: Data Extraction (Named Entity Recognition) — Optimized Variant">

```toml
[functions.extract_entities.variants.gepa_optimized]
type = "chat_completion"
model = "openai::gpt-5-mini-2025-08-07"
templates.system.path = "functions/extract_entities/gepa_iter_9/system_template.minijinja"
json_mode = "strict"
```

```text
You are an assistant that is performing a named entity recognition (NER) task.
Your job is to extract named entities from a given text.

## Entity Categories

Extract entities in these four categories:
- **person**: Names of people (e.g., "John Smith", "Dr. Maria Rodriguez")
- **organization**: Names of companies, institutions, agencies, or groups (e.g., "United Nations", "Microsoft", "Department of Justice")
- **location**: Names of geographical locations including countries, cities, regions, landmarks (e.g., "China", "New York", "Mount Everest")
- **miscellaneous**: Other named entities that don't fit the above categories, such as:
  - Specific events (e.g., "Olympic Games", "World Cup", "Canadian Open")
  - Products or brands (e.g., "iPhone", "Windows 10")
  - Nationalities or languages when used as proper nouns (e.g., "French", "English")
  - Artworks, awards, or other uniquely identifiable entities

## Critical Instructions

**What to Extract:**
- Only extract proper nouns and named entities - specific names that identify unique people, places, organizations, or other entities
- Extract entities exactly as they appear in the source text, preserving original spelling, capitalization, and formatting
- Each entity should appear only once in the output - avoid duplicates or subset duplicates

**What NOT to Extract:**
- Common nouns or generic terms (e.g., "talks", "meeting", "statement")
- Generic references without specific names (e.g., "the media", "the government" without a specific government name)
- Numbers or codes that are not part of a named entity (e.g., "7-5", "123")
- Section headers or labels that are not entity names (e.g., "Income Statement Data")

**When No Entities Exist:**
- If the text contains no named entities, return empty arrays for all categories
- Do not force extraction or hallucinate entities when none are present

## Output Format

Return the entities in the following JSON format:

{
    "person": ["person1", "person2", ...],
    "organization": ["organization1", "organization2", ...],
    "location": ["location1", "location2", ...],
    "miscellaneous": ["miscellaneous1", "miscellaneous2", ...]
}
```

</Accordion>

That's it!
You are now ready to deploy your GEPA optimized LLM application!

</Step>

</Steps>

<Tip>

GEPA returns a set of Pareto optimal variants based on the evaluation you defined.
You can roll out your new variants responsibly using [TensorZero Adaptive A/B testing](/experimentation/run-adaptive-ab-tests).

</Tip>

## `GEPAConfig`

Configure GEPA optimization by creating a `GEPAConfig` object with the following parameters:

### Required Parameters

| Parameter         | Type  | Description                                                                       |
| ----------------- | ----- | --------------------------------------------------------------------------------- |
| `function_name`   | `str` | Name of the TensorZero function to optimize.                                      |
| `evaluation_name` | `str` | Name of the evaluation used to score candidate variants.                          |
| `analysis_model`  | `str` | Model used to analyze inference results (e.g., `"anthropic::claude-sonnet-4-5"`). |
| `mutation_model`  | `str` | Model used to generate prompt mutations (e.g., `"anthropic::claude-sonnet-4-5"`). |

### Optional Parameters

| Parameter                        | Type          | Default      | Description                                                                                                                                                                             |
| -------------------------------- | ------------- | ------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `initial_variants`               | `list[str]`   | All variants | List of variant names to initialize GEPA with. If not specified, uses all variants defined for the function.                                                                            |
| `variant_prefix`                 | `str`         | `None`       | Prefix for naming newly generated variants.                                                                                                                                             |
| `batch_size`                     | `int`         | `5`          | Number of training samples to analyze per iteration.                                                                                                                                    |
| `max_iterations`                 | `int`         | `1`          | Maximum number of optimization iterations.                                                                                                                                              |
| `max_concurrency`                | `int`         | `10`         | Maximum number of concurrent inference calls.                                                                                                                                           |
| `seed`                           | `int`         | `None`       | Random seed for reproducibility.                                                                                                                                                        |
| `timeout`                        | `int`         | `300`        | Client timeout in seconds for TensorZero gateway operations.                                                                                                                            |
| `include_inference_for_mutation` | `bool`        | `True`       | Whether to include inference input/output in the analysis passed to the mutation model. Useful for few-shot examples but can cause context overflow with long conversations or outputs. |
| `retries`                        | `RetryConfig` | `None`       | Retry configuration for inference calls during optimization.                                                                                                                            |
| `max_tokens`                     | `int`         | `None`       | Maximum tokens for analysis and mutation model calls. Required for Anthropic models.                                                                                                    |
