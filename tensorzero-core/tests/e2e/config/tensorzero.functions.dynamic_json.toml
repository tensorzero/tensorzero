
[functions.dynamic_json]
type = "json"
system_schema = "../../../fixtures/config/functions/dynamic_json/system_schema.json"
user_schema = "../../../fixtures/config/functions/dynamic_json/user_schema.json"

[functions.dynamic_json.variants.test]
type = "chat_completion"
weight = 1
model = "json"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.anthropic]
type = "chat_completion"
model = "claude-3-haiku-20240307-anthropic"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.anthropic-strict]
type = "chat_completion"
model = "claude-3-haiku-20240307-anthropic"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.anthropic-implicit]
type = "chat_completion"
model = "claude-3-haiku-20240307-anthropic"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.aws-bedrock]
type = "chat_completion"
model = "claude-3-haiku-20240307-aws-bedrock"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.aws-bedrock-deepseek-r1]
type = "chat_completion"
model = "deepseek-r1-aws-bedrock"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 500

[functions.dynamic_json.variants.aws-bedrock-strict]
type = "chat_completion"
model = "claude-3-haiku-20240307-aws-bedrock"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.aws-bedrock-implicit]
type = "chat_completion"
model = "claude-3-haiku-20240307-aws-bedrock"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.azure]
type = "chat_completion"
model = "gpt-4o-mini-azure"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.azure-strict]
type = "chat_completion"
model = "gpt-4o-mini-azure"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.azure-implicit]
type = "chat_completion"
model = "gpt-4o-mini-azure"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.azure-ai-foundry]
type = "chat_completion"
model = "llama-3.3-70b-instruct-azure"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.azure-ai-foundry-strict]
type = "chat_completion"
model = "llama-3.3-70b-instruct-azure"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.azure-ai-foundry-implicit]
type = "chat_completion"
model = "llama-3.3-70b-instruct-azure"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.fireworks]
type = "chat_completion"
model = "fireworks::accounts/fireworks/models/deepseek-v3p1"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.fireworks-strict]
type = "chat_completion"
model = "fireworks::accounts/fireworks/models/deepseek-v3p1"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.fireworks-implicit]
type = "chat_completion"
model = "fireworks::accounts/fireworks/models/deepseek-v3p1"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.gcp-vertex-gemini-flash]
type = "chat_completion"
model = "gemini-2.0-flash-001"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.gcp-vertex-gemini-flash-strict]
type = "chat_completion"
model = "gemini-2.0-flash-001"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.gcp-vertex-gemini-flash-implicit]
type = "chat_completion"
model = "gemini-2.0-flash-001"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.gcp-vertex-gemini-pro]
type = "chat_completion"
model = "gcp-gemini-2.5-pro"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 500

[functions.dynamic_json.variants.gcp-vertex-gemini-pro-implicit]
type = "chat_completion"
model = "gcp-gemini-2.5-pro"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 500

[functions.dynamic_json.variants.gcp-vertex-gemini-flash-lite-tuned]
type = "chat_completion"
model = "gemini-2.0-flash-lite-tuned"
json_mode = "strict"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100

[functions.dynamic_json.variants.google-ai-studio-gemini-flash-8b]
type = "chat_completion"
model = "gemini-2.0-flash-lite"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.google-ai-studio-gemini-flash-8b-strict]
type = "chat_completion"
model = "gemini-2.0-flash-lite"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.google-ai-studio-gemini-flash-8b-implicit]
type = "chat_completion"
model = "gemini-2.0-flash-lite"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.google-ai-studio-gemini-2_5-pro]
type = "chat_completion"
model = "gemini-2.5-pro"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 500

[functions.dynamic_json.variants.google-ai-studio-gemini-2_5-pro-implicit]
type = "chat_completion"
model = "gemini-2.5-pro"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 500

[functions.dynamic_json.variants.gcp-vertex-haiku]
type = "chat_completion"
model = "claude-3-haiku-20240307-gcp-vertex"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.gcp-vertex-haiku-strict]
type = "chat_completion"
model = "claude-3-haiku-20240307-gcp-vertex"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.gcp-vertex-haiku-implicit]
type = "chat_completion"
model = "claude-3-haiku-20240307-gcp-vertex"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.groq]
type = "chat_completion"
model = "groq-qwen"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 500

[functions.dynamic_json.variants.groq-strict]
type = "chat_completion"
model = "groq-qwen"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 500
json_mode = "strict"

[functions.dynamic_json.variants.groq-implicit]
type = "chat_completion"
model = "groq-qwen"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 500

[functions.dynamic_json.variants.mistral]
type = "chat_completion"
model = "open-mistral-nemo-2407"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.mistral-strict]
type = "chat_completion"
model = "open-mistral-nemo-2407"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.openai]
type = "chat_completion"
model = "gpt-4o-mini-2024-07-18"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "strict"
max_tokens = 100

[functions.dynamic_json.variants.openai-responses]
type = "chat_completion"
model = "responses-gpt-4o-mini-2024-07-18"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.openai-responses-strict]
type = "chat_completion"
model = "responses-gpt-4o-mini-2024-07-18"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "strict"
max_tokens = 100

[functions.dynamic_json.variants.openai-strict]
type = "chat_completion"
model = "gpt-4o-mini-2024-07-18"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.openai-o1]
type = "chat_completion"
model = "o1-2024-12-17"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 1000

[functions.dynamic_json.variants.openai-implicit]
type = "chat_completion"
model = "gpt-4o-mini-2024-07-18"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.openai-cot]
type = "experimental_chain_of_thought"
model = "openai::gpt-4.1-nano-2025-04-14"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

## OpenRouter

[functions.dynamic_json.variants.openrouter]
type = "chat_completion"
model = "gpt_4_o_mini_openrouter"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.openrouter-strict]
type = "chat_completion"
model = "gpt_4_o_mini_openrouter"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.openrouter-implicit]
type = "chat_completion"
model = "gpt_4_o_mini_openrouter"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.sglang]
type = "chat_completion"
model = "Qwen/Qwen2.5-1.5B-Instruct"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "strict"
max_tokens = 100

[functions.dynamic_json.variants.sglang-strict]
type = "chat_completion"
model = "Qwen/Qwen2.5-1.5B-Instruct"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.tgi]
type = "chat_completion"
model = "phi-3.5-mini-instruct-tgi"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.tgi-strict]
type = "chat_completion"
model = "phi-3.5-mini-instruct-tgi"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.together]
type = "chat_completion"
model = "llama3.1-8b-instruct-together"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.together-strict]
type = "chat_completion"
model = "llama3.1-8b-instruct-together"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.together-implicit]
type = "chat_completion"
model = "llama3.1-8b-instruct-together"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.vllm]
type = "chat_completion"
model = "qwen2.5-0.5b-instruct-vllm"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.vllm-strict]
type = "chat_completion"
model = "qwen2.5-0.5b-instruct-vllm"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.vllm-implicit]
type = "chat_completion"
model = "qwen2.5-0.5b-instruct-vllm"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "tool"
max_tokens = 100

[functions.dynamic_json.variants.deepseek-chat]
type = "chat_completion"
model = "deepseek-chat"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.deepseek-chat-strict]
type = "chat_completion"
model = "deepseek-chat"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"

[functions.dynamic_json.variants.xai]
type = "chat_completion"
model = "grok_2_1212"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
json_mode = "on"
max_tokens = 100

[functions.dynamic_json.variants.xai-strict]
type = "chat_completion"
model = "grok_2_1212"
system_template = "../../../fixtures/config/functions/dynamic_json/prompt/system_template.minijinja"
user_template = "../../../fixtures/config/functions/dynamic_json/prompt/user_template.minijinja"
max_tokens = 100
json_mode = "strict"
