[functions.weather_helper]
type = "chat"
system_schema = "../../../fixtures/config/functions/weather_helper/system_schema.json"
tools = ["get_temperature"]
tool_choice = "auto"

# This function uses a tool where the config key differs from the display name
# key = "get_temperature_with_name", name = "get_temperature"
# This tests that allowed_tools filtering uses the key, not the display name
[functions.weather_helper_aliased_tool]
type = "chat"
tools = ["get_temperature_with_name"]
tool_choice = "auto"

[functions.weather_helper_aliased_tool.variants.mock]
type = "chat_completion"
weight = 1
model = "tool"
max_tokens = 100

[functions.weather_helper.variants.anthropic-thinking]
type = "chat_completion"
weight = 0
model = "anthropic::claude-sonnet-4-5"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
thinking_budget_tokens = 1024
max_tokens = 1200

[functions.weather_helper.variants.gcp-vertex-anthropic-thinking]
type = "chat_completion"
weight = 0
model = "gcp-vertex-anthropic-claude-haiku-4-5@20251001-thinking"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
# This must be at least as large as `thinking.budget_tokens`
max_tokens = 1200
thinking_budget_tokens = 1024

[functions.weather_helper.variants.gcp-vertex-anthropic-sonnet-thinking]
type = "chat_completion"
weight = 0
model = "gcp-vertex-anthropic-claude-sonnet-4-5@20250929-thinking"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
# This must be at least as large as `thinking.budget_tokens`
max_tokens = 1200
thinking_budget_tokens = 1024

[functions.weather_helper.variants.variant]
type = "chat_completion"
weight = 1
model = "tool"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.split_tool_name]
type = "chat_completion"
model = "dummy::tool_split_name"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.bad_tool]
type = "chat_completion"
model = "bad_tool"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.aws-bedrock]
type = "chat_completion"
model = "claude-haiku-4-5-aws-bedrock"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.aws-bedrock-deepseek-r1]
type = "chat_completion"
model = "deepseek-r1-aws-bedrock"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 500

[functions.weather_helper.variants.aws-bedrock-thinking]
type = "chat_completion"
model = "claude-sonnet-4-5-thinking-aws-bedrock"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 2048
thinking_budget_tokens = 1024

[functions.weather_helper.variants.anthropic]
type = "chat_completion"
model = "claude-haiku-4-5-anthropic"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.anthropic-haiku-4-5-thinking]
type = "chat_completion"
model = "claude-haiku-4-5-thinking"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 2048
thinking_budget_tokens = 1024

[functions.weather_helper.variants.azure]
type = "chat_completion"
model = "gpt-4o-mini-azure"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.fireworks]
type = "chat_completion"
model = "fireworks::accounts/fireworks/models/deepseek-v3p1"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.gcp-vertex-gemini-flash]
type = "chat_completion"
model = "gcp-gemini-2.5-flash"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.gcp-vertex-gemini-pro]
type = "chat_completion"
model = "gcp-gemini-2.5-pro"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 500

[functions.weather_helper.variants.gcp-vertex-gemini-pro-thinking]
type = "chat_completion"
model = "gcp-gemini-2.5-pro-thinking"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 500
# Set to minimum value to speed up tests and save tokens
thinking_budget_tokens = 128

[functions.weather_helper.variants.google-ai-studio-gemini-flash-lite]
type = "chat_completion"
model = "gemini-2.5-flash-lite"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.google-ai-studio-gemini-2_5-pro]
type = "chat_completion"
model = "gemini-2.5-pro"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 500

[functions.weather_helper.variants.google-ai-studio-gemini-3-flash]
type = "chat_completion"
model = "gemini-3-flash"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 500

[functions.weather_helper.variants.gcp-vertex-haiku]
type = "chat_completion"
model = "claude-haiku-4-5-gcp-vertex"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.groq]
type = "chat_completion"
model = "groq-qwen"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 500

[functions.weather_helper.variants.groq-reasoning]
type = "chat_completion"
model = "groq-qwen3-32b"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 800

[functions.weather_helper.variants.groq-reasoning-usage]
type = "chat_completion"
model = "groq-gpt-oss-20b"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"

[functions.weather_helper.variants.mistral]
type = "chat_completion"
model = "open-mistral-nemo-2407"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.deepseek-reasoner]
type = "chat_completion"
model = "deepseek-reasoner"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 800

[functions.weather_helper.variants.fireworks-deepseek]
type = "chat_completion"
model = "deepseek-r1"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 800

[functions.weather_helper.variants.fireworks-gpt-oss-20b]
type = "chat_completion"
model = "gpt-oss-20b-fireworks"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"


[functions.weather_helper.variants.together-deepseek-r1]
type = "chat_completion"
model = "together-deepseek-r1"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 800

[functions.weather_helper.variants.openai]
type = "chat_completion"
model = "gpt-4o-mini-2024-07-18"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.gpt-5-mini]
type = "chat_completion"
model = "openai::gpt-5-mini"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.openai-gpt-5-mini]
type = "chat_completion"
model = "gpt-5-mini-responses"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 2048

[functions.weather_helper.variants.openai-responses]
type = "chat_completion"
model = "responses-gpt-4o-mini-2024-07-18"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.openai-o1]
type = "chat_completion"
model = "o1-2024-12-17"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 1000

[functions.weather_helper.variants.openrouter]
type = "chat_completion"
model = "gpt_4_o_mini_openrouter"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.together-tool]
type = "chat_completion"
model = "llama4-maverick-instruct-together"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.sglang]
type = "chat_completion"
model = "Qwen/Qwen2.5-1.5B-Instruct"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.vllm]
type = "chat_completion"
model = "qwen2.5-0.5b-instruct-vllm"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.xai]
type = "chat_completion"
model = "grok_4_1_fast_non_reasoning"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 100

[functions.weather_helper.variants.xai-reasoning]
type = "chat_completion"
model = "grok-code-fast-1"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 800

# OpenRouter reasoning variants

# Grok 3 Mini with `reasoning_effort`-based reasoning
[functions.weather_helper.variants.openrouter-grok-reasoning]
type = "chat_completion"
model = "grok-code-fast-1-openrouter"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 2048
reasoning_effort = "low"

# Claude Haiku 4.5 with `thinking_budget_tokens`-based reasoning
[functions.weather_helper.variants.openrouter-claude-reasoning]
type = "chat_completion"
model = "claude-haiku-4-5-openrouter"
system_template = "../../../fixtures/config/functions/weather_helper/prompt/system_template.minijinja"
max_tokens = 2048
thinking_budget_tokens = 1024
