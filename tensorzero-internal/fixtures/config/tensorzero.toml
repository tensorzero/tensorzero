# NOTE: This is an example configuration file for TensorZero.
#       You can use this file as a reference for your own configuration by adding
#       your own models, functions, and metrics.

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  GENERAL                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[gateway]
bind_address = "0.0.0.0:3000"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                   MODELS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[models.gpt-4o-mini]
routing = ["openai", "azure"]

[models.gpt-4o-mini.providers.openai]
type = "openai"
model_name = "gpt-4o-mini-2024-07-18"

[models.gpt-4o-mini.providers.azure]
type = "azure"
deployment_id = "gpt-4o-mini"
endpoint = "https://your-endpoint.openai.azure.com"

[models.claude-3-haiku-20240307]
routing = ["anthropic"]

[models.claude-3-haiku-20240307.providers.anthropic]
type = "anthropic"
model_name = "claude-3-haiku-20240307"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                 FUNCTIONS                                  │
# └────────────────────────────────────────────────────────────────────────────┘

[functions.example_generate_draft]
type = "chat"
system_schema = "functions/example_generate_draft/system_schema.json"

[functions.example_generate_draft.variants.openai_promptA]
type = "chat_completion"
weight = 0.9
model = "gpt-4o-mini"
system_template = "functions/example_generate_draft/promptA/system_template.minijinja"

[functions.example_generate_draft.variants.openai_promptB]
type = "chat_completion"
weight = 0.1
model = "gpt-4o-mini"
system_template = "functions/example_generate_draft/promptB/system_template.minijinja"

[functions.example_extract_data]
type = "json"
system_schema = "functions/example_extract_data/system_schema.json"
output_schema = "functions/example_extract_data/output_schema.json"

[functions.example_extract_data.variants.openai_promptA]
type = "chat_completion"
weight = 0.9
model = "gpt-4o-mini"
system_template = "functions/example_extract_data/promptA/system_template.minijinja"

[functions.example_extract_data.variants.openai_promptB]
type = "chat_completion"
weight = 0.1
model = "gpt-4o-mini"
system_template = "functions/example_extract_data/promptB/system_template.minijinja"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  METRICS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[metrics.example_task_success]
type = "boolean"    # "boolean", "float"
optimize = "max"    # "min", "max"
level = "inference" # "inference", "episode"

[metrics.example_user_rating]
type = "float"
optimize = "max"
level = "episode"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  TOOLS                                     │
# └────────────────────────────────────────────────────────────────────────────┘

[tools.example_query_articles]
description = "Query articles from Wikipedia"
parameters = "tools/example_query_articles.json"
