# TensorZero configuration file for the haiku hidden preferences example.

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  GENERAL                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[gateway]
bind_address = "0.0.0.0:3000"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                   MODELS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[models."gpt-4o-2024-08-06"]
routing = ["openai"]

[models."gpt-4o-2024-08-06".providers.openai]
type = "openai"
model_name = "gpt-4o-2024-08-06"

[models."claude-3.5-sonnet-20240620"]
routing = ["anthropic"]

[models."claude-3.5-sonnet-20240620".providers.anthropic]
type = "anthropic"
model_name = "claude-3-5-sonnet-20240620"

[models.claude-3-haiku-20240307]
routing = ["anthropic"]

[models.claude-3-haiku-20240307.providers.anthropic]
type = "anthropic"
model_name = "claude-3-haiku-20240307"

[models."gemini-1.5-pro"]
routing = ["gcp_vertex_gemini"]

[models."gemini-1.5-pro".providers.gcp_vertex_gemini]
type = "gcp_vertex_gemini"
model_id = "gemini-1.5-pro-001"
location = "us-central1"
project_id = "tensorzero-public"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                 FUNCTIONS                                  │
# └────────────────────────────────────────────────────────────────────────────┘

[functions.judge_haiku]
type = "json"
user_schema = "functions/judge_haiku/user_schema.json"
output_schema = "functions/judge_haiku/output_schema.json"

[functions.judge_haiku.variants.judge_prompt]
weight = 1
type = "chat_completion"
model = "gpt-4o-2024-08-06"
system_template = "functions/judge_haiku/judge_prompt/system_template.minijinja"
user_template = "functions/judge_haiku/judge_prompt/user_template.minijinja"
json_mode = "strict"

[functions.write_haiku]
type = "chat"
user_schema = "functions/write_haiku/user_schema.json"

[functions.write_haiku.variants.initial_prompt_haiku]
type = "chat_completion"
weight = 0.25
model = "claude-3-haiku-20240307"
system_template = "functions/write_haiku/initial_prompt/system_template.minijinja"
user_template = "functions/write_haiku/initial_prompt/user_template.minijinja"

[functions.write_haiku.variants.initial_prompt_sonnet]
type = "chat_completion"
weight = 0.25
model = "claude-3.5-sonnet-20240620"
system_template = "functions/write_haiku/initial_prompt/system_template.minijinja"
user_template = "functions/write_haiku/initial_prompt/user_template.minijinja"

[functions.write_haiku.variants.initial_prompt_gpt4o]
type = "chat_completion"
weight = 0.25
model = "gpt-4o-2024-08-06"
system_template = "functions/write_haiku/initial_prompt/system_template.minijinja"
user_template = "functions/write_haiku/initial_prompt/user_template.minijinja"

[functions.write_haiku.variants."initial_prompt_gemini_1.5_pro"]
type = "chat_completion"
weight = 0.25
model = "gemini-1.5-pro"
system_template = "functions/write_haiku/initial_prompt/system_template.minijinja"
user_template = "functions/write_haiku/initial_prompt/user_template.minijinja"


# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  METRICS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[metrics.haiku_score]
type = "boolean"
level = "inference"
optimize = "max"
