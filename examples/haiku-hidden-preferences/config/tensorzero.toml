# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                 FUNCTIONS                                  │
# └────────────────────────────────────────────────────────────────────────────┘

[functions.write_haiku]
type = "chat"
user_schema = "functions/write_haiku/user_schema.json"

[functions.write_haiku.variants.gpt_4o_mini]
type = "chat_completion"
model = "openai::gpt-4o-mini-2024-07-18"
system_template = "functions/write_haiku/initial_prompt/system_template.minijinja"
user_template = "functions/write_haiku/initial_prompt/user_template.minijinja"

# TODO: Once you've fine-tuned your model, add it here like the commented example below

# [functions.write_haiku.variants.gpt_4o_mini_fine_tuned]
# type = "chat_completion"
# model = "openai::ft:gpt-4o-mini-2024-07-18:xxxxxxxx::xxxxxxxx"  # TODO: Replace with your model ID
# system_template = "functions/write_haiku/initial_prompt/system_template.minijinja"
# user_template = "functions/write_haiku/initial_prompt/user_template.minijinja"
# json_mode = "strict"

[functions.judge_haiku]
type = "json"
user_schema = "functions/judge_haiku/user_schema.json"
output_schema = "functions/judge_haiku/output_schema.json"

[functions.judge_haiku.variants.baseline]
type = "chat_completion"
model = "openai::gpt-4o-2024-08-06"
system_template = "functions/judge_haiku/judge_prompt/system_template.minijinja"
user_template = "functions/judge_haiku/judge_prompt/user_template.minijinja"
json_mode = "on"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  METRICS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[metrics.haiku_score]
type = "boolean"
level = "inference"
optimize = "max"
