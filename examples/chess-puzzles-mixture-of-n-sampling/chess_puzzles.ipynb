{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Improving LLM Chess Ability with Mixture-of-N Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import random\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from uuid import UUID\n",
    "\n",
    "import chess\n",
    "import neatplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorzero import AsyncTensorZeroGateway\n",
    "from tqdm import tqdm, trange\n",
    "from utils import AbstractPlayer, proportion_ci, run_puzzle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "neatplot.set_style(\"notex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create a chess player class that takes the current state of the board and calls a TensorZero function to choose a move.\n",
    "We give the LLM access to the current board state as ASCII, the color the player should play as, and the legal moves in Standard Algebraic Notation (SAN).\n",
    "The TensorZero function returns a JSON object with the thinking and the move.\n",
    "We log the thinking and the move, and then return the move to the caller.\n",
    "We also return the episode ID, which we can use to give feedback on the move later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorZeroPlayer(AbstractPlayer):\n",
    "    \"\"\"\n",
    "    A chess player that uses a TensorZero LLM to choose moves.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, client: AsyncTensorZeroGateway, variant_name: Optional[str] = None\n",
    "    ):\n",
    "        self.client = client\n",
    "        self.variant_name = variant_name\n",
    "\n",
    "    async def play(\n",
    "        self, board: chess.Board, episode_id: Optional[UUID] = None\n",
    "    ) -> Tuple[str, Optional[UUID]]:\n",
    "        \"\"\"\n",
    "        Returns the move chosen by the TensorZero LLM in SAN (Standard Algebraic Notation).\n",
    "        \"\"\"\n",
    "        legal_moves_san = [board.san(move) for move in board.legal_moves]\n",
    "\n",
    "        try:\n",
    "            result = await self.client.inference(\n",
    "                function_name=\"play_chess_board\",\n",
    "                input={\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            # We pass the board state, the color of the player, and the legal moves in SAN to\n",
    "                            # TensorZero.\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": {\n",
    "                                \"board\": str(board),\n",
    "                                \"color\": \"white\" if board.turn else \"black\",\n",
    "                                \"legal_moves_san\": legal_moves_san,\n",
    "                            },\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                variant_name=self.variant_name,\n",
    "                episode_id=episode_id,\n",
    "            )\n",
    "            thinking = result.output.parsed[\"thinking\"]\n",
    "            logger.info(f\"Player thinking: {thinking}\")\n",
    "            move = result.output.parsed[\"move\"]\n",
    "            logger.info(f\"Player move: {move}\")\n",
    "            episode_id = result.episode_id\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error occurred: {type(e).__name__}: {e}\")\n",
    "            logger.info(\"Choosing a random legal move as fallback.\")\n",
    "            move = random.choice(legal_moves_san)\n",
    "            return move, episode_id\n",
    "        return move, episode_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the main function that runs many chess puzzles and sends feedback to TensorZero on each episode describing whether the puzzle solution was successful.\n",
    "We'll try a handful of different variants to see how they perform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_puzzles(\n",
    "    player: AbstractPlayer,\n",
    "    puzzle_df: pd.DataFrame,\n",
    "    variant_name: str,\n",
    "    semaphore: asyncio.Semaphore,\n",
    "    client: Optional[AsyncTensorZeroGateway] = None,\n",
    "    disable_progress_bar: bool = False,\n",
    ") -> List[bool]:\n",
    "    \"\"\"\n",
    "    Runs the puzzles in the dataframe and returns the list of successes.\n",
    "    \"\"\"\n",
    "    successes = []\n",
    "    episode_ids = []\n",
    "    num_successes = 0\n",
    "    total_puzzles = len(puzzle_df)\n",
    "    progress_bar = trange(\n",
    "        total_puzzles, desc=f\"[Inference] {variant_name}\", disable=disable_progress_bar\n",
    "    )\n",
    "\n",
    "    tasks = [\n",
    "        asyncio.create_task(run_puzzle(puzzle_df.iloc[i].to_dict(), player, semaphore))\n",
    "        for i in range(total_puzzles)\n",
    "    ]\n",
    "\n",
    "    for task in asyncio.as_completed(tasks):\n",
    "        success, episode_id = await task\n",
    "        successes.append(success)\n",
    "        episode_ids.append(episode_id)\n",
    "        if success:\n",
    "            num_successes += 1\n",
    "        current = len(successes)\n",
    "        logger.info(\n",
    "            f\"Puzzle {current} completed {'successfully' if success else 'unsuccessfully'}\"\n",
    "        )\n",
    "        ci_lower, ci_upper = proportion_ci(num_successes, current)\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"Success\": f\"{num_successes}/{current} CI: ({ci_lower:.2f}, {ci_upper:.2f})\"\n",
    "            },\n",
    "            refresh=True,\n",
    "        )\n",
    "    progress_bar.close()\n",
    "\n",
    "    if client:\n",
    "        for success, episode_id in tqdm(\n",
    "            zip(successes, episode_ids),\n",
    "            total=len(successes),\n",
    "            desc=f\"[Feedback] {variant_name}\",\n",
    "            disable=disable_progress_bar,\n",
    "        ):\n",
    "            if episode_id:\n",
    "                async with semaphore:\n",
    "                    await client.feedback(\n",
    "                        episode_id=episode_id,\n",
    "                        metric_name=\"puzzle_success\",\n",
    "                        value=success,\n",
    "                    )\n",
    "\n",
    "    return successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This train set size will take a while to run (10 minutes with 10 concurrent requests and 1000 examples for the best-of-5 variants) but give statistically significant results\n",
    "# For a quick test, you can use NUM_EXAMPLES = 10\n",
    "NUM_EXAMPLES = 1000\n",
    "puzzle_df = pd.read_csv(\"data/lichess_easy_puzzles_train.csv\")\n",
    "puzzle_df = puzzle_df.head(NUM_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce this value if you're getting rate-limited by OpenAI\n",
    "MAX_CONCURRENT_T0_REQUESTS = 50\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENT_T0_REQUESTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can plot later\n",
    "variant_stats: Dict[str, Dict[str, float]] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try a reasonable prompt with GPT-4o Mini. You can check `config/functions/play_chess_board/chess_prompt/` to see the templates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_name = \"baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with AsyncTensorZeroGateway(\"http://localhost:3000\", timeout=180.0) as client:\n",
    "    results = await run_puzzles(\n",
    "        TensorZeroPlayer(client, variant_name),\n",
    "        puzzle_df,\n",
    "        variant_name,\n",
    "        semaphore,\n",
    "        client,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_successes = sum(results)\n",
    "total_puzzles = len(results)\n",
    "print(\n",
    "    f\"{variant_name}: {num_successes}/{total_puzzles} = {num_successes/total_puzzles:.2f}\"\n",
    ")\n",
    "ci_lower, ci_upper = proportion_ci(num_successes, total_puzzles)\n",
    "print(f\"{variant_name} confidence interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
    "variant_stats[variant_name] = {\n",
    "    \"mean\": num_successes / total_puzzles,\n",
    "    \"ci_lower\": ci_lower,\n",
    "    \"ci_upper\": ci_upper,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try mixture-of-5 sampling with the same prompt and model. You should see a statistically significant improvement in performance by spending more compute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_name = \"mixture_of_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with AsyncTensorZeroGateway(\"http://localhost:3000\", timeout=180.0) as client:\n",
    "    results = await run_puzzles(\n",
    "        TensorZeroPlayer(client, variant_name),\n",
    "        puzzle_df,\n",
    "        variant_name,\n",
    "        semaphore,\n",
    "        client,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_successes = sum(results)\n",
    "total_puzzles = len(results)\n",
    "print(\n",
    "    f\"{variant_name}: {num_successes}/{total_puzzles} = {num_successes/total_puzzles:.2f}\"\n",
    ")\n",
    "ci_lower, ci_upper = proportion_ci(num_successes, total_puzzles)\n",
    "print(f\"{variant_name} confidence interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
    "variant_stats[variant_name] = {\n",
    "    \"mean\": num_successes / total_puzzles,\n",
    "    \"ci_lower\": ci_lower,\n",
    "    \"ci_upper\": ci_upper,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous two variants used the same prompt and model.\n",
    "Let's try a mixture-of-5 variant that uses different prompts for each candidate.\n",
    "You should once again see an improvement in performance!\n",
    "Try experimenting with different prompts to see if you can get even better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_name = \"mixture_of_5_diverse_prompts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with AsyncTensorZeroGateway(\"http://localhost:3000\", timeout=180.0) as client:\n",
    "    results = await run_puzzles(\n",
    "        TensorZeroPlayer(client, variant_name),\n",
    "        puzzle_df,\n",
    "        variant_name,\n",
    "        semaphore,\n",
    "        client,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_successes = sum(results)\n",
    "total_puzzles = len(results)\n",
    "print(\n",
    "    f\"{variant_name}: {num_successes}/{total_puzzles} = {num_successes/total_puzzles:.2f}\"\n",
    ")\n",
    "ci_lower, ci_upper = proportion_ci(num_successes, total_puzzles)\n",
    "print(f\"{variant_name} confidence interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
    "variant_stats[variant_name] = {\n",
    "    \"mean\": num_successes / total_puzzles,\n",
    "    \"ci_lower\": ci_lower,\n",
    "    \"ci_upper\": ci_upper,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "variants = list(variant_stats.keys())\n",
    "means = np.array([variant_stats[v][\"mean\"] for v in variants])\n",
    "ci_lower = np.array([variant_stats[v][\"ci_lower\"] for v in variants])\n",
    "ci_upper = np.array([variant_stats[v][\"ci_upper\"] for v in variants])\n",
    "\n",
    "# Create the bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(variants))\n",
    "bars = ax.bar(x, means, yerr=[means - ci_lower, ci_upper - means], capsize=5, alpha=0.8)\n",
    "\n",
    "# Customize the chart\n",
    "ax.set_ylabel(\"Mean Success Rate\")\n",
    "ax.set_title(\"Success Rate — Chess Puzzles\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(variants, rotation=45, ha=\"right\")\n",
    "# ax.set_ylim(0, 1)  # Set y-axis limits from 0 to 1\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height / 2,\n",
    "        f\"{height:.2f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus (Optional) — Stockfish\n",
    "\n",
    "If you have [Stockfish](https://stockfishchess.org/) installed (`brew install stockfish` on Mac), you can try running the same puzzles with a real chess engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import StockfishPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stockfish is CPU bound so we should only run 1 at a time\n",
    "semaphore = asyncio.Semaphore(1)\n",
    "\n",
    "player = StockfishPlayer(3190)  # very powerful\n",
    "results = await run_puzzles(player, puzzle_df, \"stockfish\", semaphore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_successes = sum(results)\n",
    "total_puzzles = len(results)\n",
    "print(\n",
    "    f\"{variant_name}: {num_successes}/{total_puzzles} = {num_successes/total_puzzles:.2f}\"\n",
    ")\n",
    "ci_lower, ci_upper = proportion_ci(num_successes, total_puzzles)\n",
    "print(f\"{variant_name} confidence interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
    "variant_stats[variant_name] = {\n",
    "    \"mean\": num_successes / total_puzzles,\n",
    "    \"ci_lower\": ci_lower,\n",
    "    \"ci_upper\": ci_upper,\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
