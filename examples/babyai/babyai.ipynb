{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import random\n",
    "from typing import List, Optional, Tuple\n",
    "from uuid import UUID\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from balrog.environments import make_env\n",
    "from omegaconf import OmegaConf\n",
    "from tensorzero import AsyncTensorZeroGateway\n",
    "from tensorzero.util import uuid7\n",
    "from tqdm import trange\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "ACTION_SPACE = [\n",
    "    \"turn left\",\n",
    "    \"turn right\",\n",
    "    \"go forward\",\n",
    "    \"pick up\",\n",
    "    \"drop\",\n",
    "    \"toggle\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load config for BALROG environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"config.yml\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "config = OmegaConf.create(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce this value if you're getting rate-limited by OpenAI\n",
    "MAX_CONCURRENT_T0_REQUESTS = 50\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENT_T0_REQUESTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define run_episode function\n",
    "The run_episode function executes a single rollout of an agent for a BabyAI task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_episode(\n",
    "    client: AsyncTensorZeroGateway,\n",
    "    variant_name: str,\n",
    "    env_name: str,\n",
    "    task_name: str,\n",
    "    episode_idx: int,\n",
    "    config: OmegaConf,\n",
    "    semaphore: asyncio.Semaphore,\n",
    "    history_length: int = 2,\n",
    "    seed: int = 0,\n",
    "    test: bool = False,\n",
    ") -> Tuple[float, float, Optional[UUID]]:\n",
    "    episode_log = {\n",
    "        \"variant\": variant_name,\n",
    "        \"task\": task_name,\n",
    "        \"input_tokens\": 0,\n",
    "        \"output_tokens\": 0,\n",
    "    }\n",
    "    use_history = \"history\" in variant_name\n",
    "    episode_id = uuid7()\n",
    "    env = make_env(env_name, task_name, config)\n",
    "    obs, _ = env.reset(seed=episode_idx + seed)\n",
    "    mission = obs[\"mission\"]\n",
    "    episode_return = 0\n",
    "    history = []\n",
    "    for step in range(env.max_steps):\n",
    "        # Generate action\n",
    "        try:\n",
    "            async with semaphore:\n",
    "                # Generate message content\n",
    "                state = obs[\"text\"][\"long_term_context\"]\n",
    "                # Generate action given message content\n",
    "                response = await client.inference(\n",
    "                    function_name=\"act\",\n",
    "                    variant_name=variant_name,\n",
    "                    input={\n",
    "                        \"system\": {\n",
    "                            \"mission\": mission,\n",
    "                        },\n",
    "                        \"messages\": [\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": {\n",
    "                                    \"observation\": state,\n",
    "                                    \"history\": \"\\n\".join(history[-history_length:]),\n",
    "                                },\n",
    "                            }\n",
    "                        ],\n",
    "                    },\n",
    "                    episode_id=episode_id,\n",
    "                )\n",
    "                episode_log[\"input_tokens\"] += response.usage.input_tokens\n",
    "                episode_log[\"output_tokens\"] += response.usage.output_tokens\n",
    "            action = response.output.parsed[\"action\"]\n",
    "            # Check if action is valid and set to default if not\n",
    "            action = env.check_action_validity(action)\n",
    "        except Exception as e:\n",
    "            # Handle error\n",
    "            logger.error(f\"Error occurred: {type(e).__name__}: {e}\")\n",
    "            logger.info(\"Choosing a random legal move as fallback.\")\n",
    "            action = random.choice(ACTION_SPACE)\n",
    "        # update history\n",
    "        if use_history:\n",
    "            history.append(f\"Observation:{state}\\n\\nYour Response:\\n{action}\\n\")\n",
    "        # Interact with environment\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        # Update episode return\n",
    "        episode_return += reward\n",
    "        # Check if episode is done and break if so\n",
    "        done = terminated or truncated\n",
    "        if done:\n",
    "            break\n",
    "    # See if episode is successful\n",
    "    progression = env.get_stats()[\"progression\"]\n",
    "    # Log feedback\n",
    "    _ = await client.feedback(\n",
    "        metric_name=\"episode_return\",\n",
    "        episode_id=episode_id,\n",
    "        value=episode_return,\n",
    "        dryrun=test,\n",
    "    )\n",
    "    _ = await client.feedback(\n",
    "        metric_name=\"progression\",\n",
    "        episode_id=episode_id,\n",
    "        value=progression,\n",
    "        dryrun=test,\n",
    "    )\n",
    "    episode_log[\"episode_return\"] = episode_return\n",
    "    episode_log[\"num_steps\"] = step + 1\n",
    "    episode_log[\"failed_candidates\"] = env.failed_candidates\n",
    "    episode_log.update(env.get_stats())\n",
    "    episode_log[\"seed\"] = episode_idx\n",
    "    episode_log[\"episode_id\"] = episode_id\n",
    "    return episode_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to run multiple episodes of the agent for a BabyAI task in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_episodes(\n",
    "    client: AsyncTensorZeroGateway,\n",
    "    variant_name: str,\n",
    "    env_name: str,\n",
    "    task_name: str,\n",
    "    num_episodes: int,\n",
    "    config: OmegaConf,\n",
    "    semaphore: asyncio.Semaphore,\n",
    "    disable_progress_bar: bool = False,\n",
    "    history_length: int = 2,\n",
    "    seed: int = 0,\n",
    "    test: bool = False,\n",
    ") -> Tuple[List[float], List[float]]:\n",
    "    progress_bar = trange(\n",
    "        num_episodes,\n",
    "        desc=f\"{env_name} {task_name} {variant_name}\",\n",
    "        disable=disable_progress_bar,\n",
    "    )\n",
    "\n",
    "    tasks = [\n",
    "        asyncio.create_task(\n",
    "            run_episode(\n",
    "                client=client,\n",
    "                variant_name=variant_name,\n",
    "                env_name=env_name,\n",
    "                task_name=task_name,\n",
    "                episode_idx=episode_idx,\n",
    "                config=config,\n",
    "                semaphore=semaphore,\n",
    "                history_length=history_length,\n",
    "                seed=seed,\n",
    "                test=test,\n",
    "            )\n",
    "        )\n",
    "        for episode_idx in range(num_episodes)\n",
    "    ]\n",
    "\n",
    "    num_successes = 0\n",
    "    episode_logs = []\n",
    "    for task in asyncio.as_completed(tasks):\n",
    "        episode_log = await task\n",
    "        if episode_log[\"progression\"] == 1.0:\n",
    "            num_successes += 1\n",
    "        episode_logs.append(episode_log)\n",
    "        current = len(episode_logs)\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_postfix(\n",
    "            {\"Success\": f\"{num_successes}/{current}\"},\n",
    "            refresh=True,\n",
    "        )\n",
    "    progress_bar.close()\n",
    "    return episode_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 200\n",
    "num_episodes = 20\n",
    "task_names = config.tasks.babyai_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "### Generating an action\n",
    "\n",
    "#### System prompt\n",
    "We use the BALROG system prompt:\n",
    "```.minijinja\n",
    "You are an agent playing a simple navigation game.\n",
    "Your goal is to {{ mission }}.\n",
    "The following are the possible actions you can take in the game, followed by a short description of each action:\n",
    "\n",
    "turn left: turn to the left\n",
    "turn right: turn to the right\n",
    "go forward: take one step forward\n",
    "pick up: pick up the object below you\n",
    "drop: drop the object that you are holding\n",
    "toggle: manipulate the object in front of you\n",
    "\n",
    "In a moment I will present you an observation.\n",
    "\n",
    "Tips:\n",
    "\n",
    "- Once the desired object you want to interact or pickup in front of you, you can use the 'toggle' action to interact with it.\n",
    "- It doesn't make sense to repeat the same action over and over if the observation doesn't change.\n",
    "\n",
    "PLAY!\n",
    "```\n",
    "in `config/functions/act/baseline/system.minijinja`.\n",
    "\n",
    "#### User prompt\n",
    "The user prompt is\n",
    "```.minijinja\n",
    "Current Observation:\n",
    "{{ observation }}\n",
    "\n",
    "Only respond with a JSON object with the following schema:\n",
    "\n",
    "{\n",
    "  \"thinking\": \"...\"\n",
    "  \"action\": \"...\"\n",
    "}\n",
    "\n",
    "The \"action\" field is required and must always contain one of the above actions at a time and no other text.\n",
    "\n",
    "Example:\n",
    "\n",
    "User: a wall 4 steps forward\n",
    "a wall 3 steps left\n",
    "Agent: {\"thinking\": \"Since there is a wall 4 steps forward and 3 steps to the left, the best action to take would be to turn right, allowing you to navigate without hitting the walls.\", \"action\": \"turn right\"}\n",
    "```\n",
    "in `config/functions/act/baseline/user.minijinja`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_baseline = []\n",
    "for task_name in task_names:\n",
    "    async with AsyncTensorZeroGateway(\"http://localhost:3000\", timeout=180.0) as client:\n",
    "        results_task = await run_episodes(\n",
    "            client=client,\n",
    "            variant_name=\"baseline\",\n",
    "            env_name=\"babyai\",\n",
    "            task_name=task_name,\n",
    "            num_episodes=num_episodes,\n",
    "            config=config,\n",
    "            semaphore=semaphore,\n",
    "            disable_progress_bar=False,\n",
    "            seed=seed,\n",
    "            test=True,\n",
    "        )\n",
    "        results_baseline.extend(results_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasoning\n",
    "Following the BALROG chain of thought example, we add the instruction \n",
    "```.minijinja\n",
    "Current Observation:\n",
    "{{ observation }}\n",
    "\n",
    "Only respond with a JSON object with the following schema:\n",
    "\n",
    "{\n",
    "  \"thinking\": \"...\"\n",
    "  \"action\": \"...\"\n",
    "}\n",
    "\n",
    "The \"thinking\" field should contain your thought process about what's the best course of action step by step.\n",
    "The \"action\" field is required and must always contain one of the above actions at a time and no other text.\n",
    "\n",
    "Example:\n",
    "\n",
    "User: a wall 4 steps forward\n",
    "a wall 3 steps left\n",
    "Agent: {\"thinking\": \"Since there is a wall 4 steps forward and 3 steps to the left, the best action to take would be to turn right, allowing you to navigate without hitting the walls.\", \"action\": \"turn right\"}\n",
    "```\n",
    "to the user prompt in `config/functions/act/reasoning/user.minijinja`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_reasoning = []\n",
    "for task_name in task_names:\n",
    "    async with AsyncTensorZeroGateway(\"http://localhost:3000\", timeout=180.0) as client:\n",
    "        results_task = await run_episodes(\n",
    "            client=client,\n",
    "            variant_name=\"reasoning\",\n",
    "            env_name=\"babyai\",\n",
    "            task_name=task_name,\n",
    "            num_episodes=num_episodes,\n",
    "            config=config,\n",
    "            semaphore=semaphore,\n",
    "            disable_progress_bar=False,\n",
    "            seed=seed,\n",
    "            test=True,\n",
    "        )\n",
    "        results_reasoning.extend(results_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History\n",
    "\n",
    "We see if adding previous observations and actions helps the performance of the baseline.\n",
    "The user prompt is changed to\n",
    "\n",
    "```.minijinja\n",
    "History:\n",
    "{{ history }}\n",
    "\n",
    "Current Observation:\n",
    "{{ observation }}\n",
    "\n",
    "Only respond with a JSON object with the following schema:\n",
    "\n",
    "{\n",
    "  \"thinking\": \"...\"\n",
    "  \"action\": \"...\"\n",
    "}\n",
    "\n",
    "The \"action\" field is required and must always contain one of the above actions at a time and no other text.\n",
    "\n",
    "Example:\n",
    "\n",
    "User: a wall 4 steps forward\n",
    "a wall 3 steps left\n",
    "Agent: {\"thinking\": \"Since there is a wall 4 steps forward and 3 steps to the left, the best action to take would be to turn right, allowing you to navigate without hitting the walls.\", \"action\": \"turn right\"}\n",
    "```\n",
    "in `config/functions/act/history/user.minijinja`.\n",
    "We add the previous two observations and actions to the field `history` in the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_length = 8\n",
    "\n",
    "results_history = []\n",
    "for task_name in task_names:\n",
    "    async with AsyncTensorZeroGateway(\"http://localhost:3000\", timeout=180.0) as client:\n",
    "        results_task = await run_episodes(\n",
    "            client=client,\n",
    "            variant_name=\"history\",\n",
    "            env_name=\"babyai\",\n",
    "            task_name=task_name,\n",
    "            num_episodes=num_episodes,\n",
    "            config=config,\n",
    "            semaphore=semaphore,\n",
    "            disable_progress_bar=False,\n",
    "            history_length=history_length,\n",
    "            seed=seed,\n",
    "            test=True,\n",
    "        )\n",
    "        results_history.extend(results_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History and reasoning\n",
    "\n",
    "This variant combines the reasoning variant and the history variant.\n",
    "The user prompt is changed to\n",
    "```.minijinja\n",
    "History:\n",
    "{{ history }}\n",
    "\n",
    "Current Observation:\n",
    "{{ observation }}\n",
    "\n",
    "Only respond with a JSON object with the following schema:\n",
    "\n",
    "{\n",
    "  \"thinking\": \"...\"\n",
    "  \"action\": \"...\"\n",
    "}\n",
    "\n",
    "The \"thinking\" field should contain your thought process about what's the best course of action step by step.\n",
    "The \"action\" field is required and must always contain one of the above actions at a time and no other text.\n",
    "\n",
    "Example:\n",
    "\n",
    "User: a wall 4 steps forward\n",
    "a wall 3 steps left\n",
    "Agent: {\"thinking\": \"Since there is a wall 4 steps forward and 3 steps to the left, the best action to take would be to turn right, allowing you to navigate without hitting the walls.\", \"action\": \"turn right\"}\n",
    "```\n",
    "in `config/functions/act/history_and_reasoning/user.minijinja`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_history_and_reasoning = []\n",
    "for task_name in task_names:\n",
    "    async with AsyncTensorZeroGateway(\"http://localhost:3000\", timeout=180.0) as client:\n",
    "        results_task = await run_episodes(\n",
    "            client=client,\n",
    "            variant_name=\"history_and_reasoning\",\n",
    "            env_name=\"babyai\",\n",
    "            task_name=task_name,\n",
    "            num_episodes=num_episodes,\n",
    "            config=config,\n",
    "            semaphore=semaphore,\n",
    "            disable_progress_bar=False,\n",
    "            history_length=history_length,\n",
    "            seed=seed,\n",
    "            test=True,\n",
    "        )\n",
    "        results_history_and_reasoning.extend(results_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    results_baseline\n",
    "    + results_reasoning\n",
    "    + results_history\n",
    "    + results_history_and_reasoning\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby(\"variant\")[\"progression\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.pointplot(\n",
    "    data=summary,\n",
    "    x=\"variant\",\n",
    "    y=\"mean\",\n",
    "    linestyle=\"none\",\n",
    "    capsize=0.1,\n",
    "    err_kws={\"linewidth\": 1},\n",
    "    color=\"C0\",\n",
    "    markers=\"o\",\n",
    ")\n",
    "\n",
    "# Add error bars for ±1 SEM\n",
    "ax.errorbar(\n",
    "    summary[\"variant\"],\n",
    "    summary[\"mean\"],\n",
    "    yerr=summary[\"sem\"],\n",
    "    fmt=\"o\",\n",
    "    color=\"C0\",\n",
    "    capsize=5,\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title(\"Task success rate\")\n",
    "ax.set_ylabel(\"Value ± 1 SEM\")\n",
    "ax.set_xlabel(\"Variant\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby(\"variant\")[\"episode_return\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.pointplot(\n",
    "    data=summary,\n",
    "    x=\"variant\",\n",
    "    y=\"mean\",\n",
    "    linestyle=\"none\",\n",
    "    capsize=0.1,\n",
    "    err_kws={\"linewidth\": 1},\n",
    "    color=\"C0\",\n",
    "    markers=\"o\",\n",
    ")\n",
    "\n",
    "# Add error bars for ±1 SEM\n",
    "ax.errorbar(\n",
    "    summary[\"variant\"],\n",
    "    summary[\"mean\"],\n",
    "    yerr=summary[\"sem\"],\n",
    "    fmt=\"o\",\n",
    "    color=\"C0\",\n",
    "    capsize=5,\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title(\"Episode return\")\n",
    "ax.set_ylabel(\"Value ± 1 SEM\")\n",
    "ax.set_xlabel(\"Variant\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby(\"variant\")[\"num_steps\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.pointplot(\n",
    "    data=summary,\n",
    "    x=\"variant\",\n",
    "    y=\"mean\",\n",
    "    linestyle=\"none\",\n",
    "    capsize=0.1,\n",
    "    err_kws={\"linewidth\": 1},\n",
    "    color=\"C0\",\n",
    "    markers=\"o\",\n",
    ")\n",
    "\n",
    "# Add error bars for ±1 SEM\n",
    "ax.errorbar(\n",
    "    summary[\"variant\"],\n",
    "    summary[\"mean\"],\n",
    "    yerr=summary[\"sem\"],\n",
    "    fmt=\"o\",\n",
    "    color=\"C0\",\n",
    "    capsize=5,\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title(\"Episode length\")\n",
    "ax.set_ylabel(\"Value ± 1 SEM\")\n",
    "ax.set_xlabel(\"Variant\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode generated token count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby(\"variant\")[\"output_tokens\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.pointplot(\n",
    "    data=summary,\n",
    "    x=\"variant\",\n",
    "    y=\"mean\",\n",
    "    linestyle=\"none\",\n",
    "    capsize=0.1,\n",
    "    err_kws={\"linewidth\": 1},\n",
    "    color=\"C0\",\n",
    "    markers=\"o\",\n",
    ")\n",
    "\n",
    "# Add error bars for ±1 SEM\n",
    "ax.errorbar(\n",
    "    summary[\"variant\"],\n",
    "    summary[\"mean\"],\n",
    "    yerr=summary[\"sem\"],\n",
    "    fmt=\"o\",\n",
    "    color=\"C0\",\n",
    "    capsize=5,\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title(\"Episode generated token count\")\n",
    "ax.set_ylabel(\"Value ± 1 SEM\")\n",
    "ax.set_xlabel(\"Variant\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode input token count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby(\"variant\")[\"input_tokens\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.pointplot(\n",
    "    data=summary,\n",
    "    x=\"variant\",\n",
    "    y=\"mean\",\n",
    "    linestyle=\"none\",\n",
    "    capsize=0.1,\n",
    "    err_kws={\"linewidth\": 1},\n",
    "    color=\"C0\",\n",
    "    markers=\"o\",\n",
    ")\n",
    "\n",
    "# Add error bars for ±1 SEM\n",
    "ax.errorbar(\n",
    "    summary[\"variant\"],\n",
    "    summary[\"mean\"],\n",
    "    yerr=summary[\"sem\"],\n",
    "    fmt=\"o\",\n",
    "    color=\"C0\",\n",
    "    capsize=5,\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title(\"Episode input token count\")\n",
    "ax.set_ylabel(\"Value ± 1 SEM\")\n",
    "ax.set_xlabel(\"Variant\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving performance with fine tuning\n",
    "\n",
    "The results above show that the history_and_reasoning variant performs yields the best success rate.\n",
    "Here we describe how to improve the performance of the history_and_reasoning variant by fine-tuning it on a separate set of random episodes.\n",
    "\n",
    "First we run a set of episodes for each taskusing the history_and_reasoning variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes_ft = 200\n",
    "seed_ft = 0\n",
    "\n",
    "for task_name in task_names:\n",
    "    async with AsyncTensorZeroGateway(\"http://localhost:3000\", timeout=180.0) as client:\n",
    "        results_task = await run_episodes(\n",
    "            client=client,\n",
    "            variant_name=\"history_and_reasoning\",\n",
    "            env_name=\"babyai\",\n",
    "            task_name=task_name,\n",
    "            num_episodes=num_episodes_ft,\n",
    "            config=config,\n",
    "            semaphore=semaphore,\n",
    "            disable_progress_bar=False,\n",
    "            history_length=history_length,\n",
    "            seed=seed_ft,\n",
    "            test=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We provide two option for fine-tuning a model: using a notebook or using the tensorzero web interface.\n",
    "\n",
    "### Fine-tuning using a notebook\n",
    "\n",
    "To fine-tune a model, you can use the notebook at `recipes/supervised-fine-tuning/metrics/openai/`. \n",
    "You will need to change the values of the following variables to:\n",
    "```.python\n",
    "CONFIG_PATH=\"../../../../examples/babyai/config/tensorzero.toml\n",
    "FUNCTION_NAME = \"act\"\n",
    "METRIC_NAME = \"episode_return\"\n",
    "TEMPLATE_VARIANT_NAME = \"history_and_reasoning\"\n",
    "FLOAT_METRIC_THRESHOLD = 0.7\n",
    "```\n",
    "After running the notebook, you will need to add the fine-tuned model to your `tensorzero.toml` with the `model_id` given in the notebook. And add a 'history_and_reasoning_ft' variant to the function `act` that uses the fine-tuned model.\n",
    "\n",
    "### Fine-tuning using the tensorzero web interface\n",
    "\n",
    "To fine-tune a model using the tensorzero web interface, you can go to http://localhost:4000, and click on \"Supervised Fine-tuning\"\n",
    "\n",
    "![alt text](img/homepage.png \"Homepage\")\n",
    "\n",
    "Then, just fill in the form and click on \"Start Fine-tuning Job\".\n",
    "\n",
    "![alt text](img/sft_form.png \"SFT form\")\n",
    "\n",
    "When the job is finished, you will need to copy and past the fine-tuned model configto your `tensorzero.toml` file and add a `history_and_reasoning_ft` variant to the function `act`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the fine-tuned \n",
    "\n",
    "After fine-tuning, you can run the following code to evaluate the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_history_and_reasoning_ft = []\n",
    "for task_name in task_names:\n",
    "    async with AsyncTensorZeroGateway(\"http://localhost:3000\", timeout=180.0) as client:\n",
    "        results_task = await run_episodes(\n",
    "            client=client,\n",
    "            variant_name=\"history_and_reasoning_ft\",\n",
    "            env_name=\"babyai\",\n",
    "            task_name=task_name,\n",
    "            num_episodes=num_episodes,\n",
    "            config=config,\n",
    "            semaphore=semaphore,\n",
    "            disable_progress_bar=False,\n",
    "            history_length=history_length,\n",
    "            seed=seed,\n",
    "            test=True,\n",
    "        )\n",
    "        results_history_and_reasoning_ft.extend(results_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We combine the results of the fine-tuned model with the results of the history_and_reasoning variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft = pd.DataFrame(results_history_and_reasoning_ft)\n",
    "\n",
    "df = pd.concat([df, df_ft])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see below that the fine-tuned model performs better than the history_and_reasoning variant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby(\"variant\")[\"progression\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.pointplot(\n",
    "    data=summary,\n",
    "    x=\"variant\",\n",
    "    y=\"mean\",\n",
    "    linestyle=\"none\",\n",
    "    capsize=0.1,\n",
    "    err_kws={\"linewidth\": 1},\n",
    "    color=\"C0\",\n",
    "    markers=\"o\",\n",
    ")\n",
    "\n",
    "# Add error bars for ±1 SEM\n",
    "ax.errorbar(\n",
    "    summary[\"variant\"],\n",
    "    summary[\"mean\"],\n",
    "    yerr=summary[\"sem\"],\n",
    "    fmt=\"o\",\n",
    "    color=\"C0\",\n",
    "    capsize=5,\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title(\"Task success rate\")\n",
    "ax.set_ylabel(\"Value ± 1 SEM\")\n",
    "ax.set_xlabel(\"Variant\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby(\"variant\")[\"episode_return\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.pointplot(\n",
    "    data=summary,\n",
    "    x=\"variant\",\n",
    "    y=\"mean\",\n",
    "    linestyle=\"none\",\n",
    "    capsize=0.1,\n",
    "    err_kws={\"linewidth\": 1},\n",
    "    color=\"C0\",\n",
    "    markers=\"o\",\n",
    ")\n",
    "\n",
    "# Add error bars for ±1 SEM\n",
    "ax.errorbar(\n",
    "    summary[\"variant\"],\n",
    "    summary[\"mean\"],\n",
    "    yerr=summary[\"sem\"],\n",
    "    fmt=\"o\",\n",
    "    color=\"C0\",\n",
    "    capsize=5,\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title(\"Episode return\")\n",
    "ax.set_ylabel(\"Value ± 1 SEM\")\n",
    "ax.set_xlabel(\"Variant\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby(\"variant\")[\"num_steps\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.pointplot(\n",
    "    data=summary,\n",
    "    x=\"variant\",\n",
    "    y=\"mean\",\n",
    "    linestyle=\"none\",\n",
    "    capsize=0.1,\n",
    "    err_kws={\"linewidth\": 1},\n",
    "    color=\"C0\",\n",
    "    markers=\"o\",\n",
    ")\n",
    "\n",
    "# Add error bars for ±1 SEM\n",
    "ax.errorbar(\n",
    "    summary[\"variant\"],\n",
    "    summary[\"mean\"],\n",
    "    yerr=summary[\"sem\"],\n",
    "    fmt=\"o\",\n",
    "    color=\"C0\",\n",
    "    capsize=5,\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title(\"Episode length\")\n",
    "ax.set_ylabel(\"Value ± 1 SEM\")\n",
    "ax.set_xlabel(\"Variant\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode generated token count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby(\"variant\")[\"output_tokens\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.pointplot(\n",
    "    data=summary,\n",
    "    x=\"variant\",\n",
    "    y=\"mean\",\n",
    "    linestyle=\"none\",\n",
    "    capsize=0.1,\n",
    "    err_kws={\"linewidth\": 1},\n",
    "    color=\"C0\",\n",
    "    markers=\"o\",\n",
    ")\n",
    "\n",
    "# Add error bars for ±1 SEM\n",
    "ax.errorbar(\n",
    "    summary[\"variant\"],\n",
    "    summary[\"mean\"],\n",
    "    yerr=summary[\"sem\"],\n",
    "    fmt=\"o\",\n",
    "    color=\"C0\",\n",
    "    capsize=5,\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title(\"Episode generated token count\")\n",
    "ax.set_ylabel(\"Value ± 1 SEM\")\n",
    "ax.set_xlabel(\"Variant\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode input token count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby(\"variant\")[\"input_tokens\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.pointplot(\n",
    "    data=summary,\n",
    "    x=\"variant\",\n",
    "    y=\"mean\",\n",
    "    linestyle=\"none\",\n",
    "    capsize=0.1,\n",
    "    err_kws={\"linewidth\": 1},\n",
    "    color=\"C0\",\n",
    "    markers=\"o\",\n",
    ")\n",
    "\n",
    "# Add error bars for ±1 SEM\n",
    "ax.errorbar(\n",
    "    summary[\"variant\"],\n",
    "    summary[\"mean\"],\n",
    "    yerr=summary[\"sem\"],\n",
    "    fmt=\"o\",\n",
    "    color=\"C0\",\n",
    "    capsize=5,\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title(\"Episode input token count\")\n",
    "ax.set_ylabel(\"Value ± 1 SEM\")\n",
    "ax.set_xlabel(\"Variant\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-world-naive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
