# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                 FUNCTIONS                                  │
# └────────────────────────────────────────────────────────────────────────────┘

[functions.extract_entities]
type = "json"
output_schema = "functions/extract_entities/output_schema.json"

[functions.extract_entities.variants.gpt_4o]
type = "chat_completion"
model = "openai::gpt-4o-2024-08-06"
system_template = "functions/extract_entities/initial_prompt/system_template.minijinja"
json_mode = "strict"

[functions.extract_entities.variants.gpt_4o_mini]
type = "chat_completion"
model = "openai::gpt-4o-mini-2024-07-18"
system_template = "functions/extract_entities/initial_prompt/system_template.minijinja"
json_mode = "strict"

# TODO: Once you've fine-tuned your model, add it here like the commented example below

# [functions.extract_entities.variants.gpt_4o_mini_fine_tuned]
# type = "chat_completion"
# model = "openai::ft:gpt-4o-mini-2024-07-18:xxxxxxxx::xxxxxxxx"
# system_template = "functions/extract_entities/initial_prompt/system_template.minijinja"
# json_mode = "strict"

# [functions.extract_entities.variants.gpt_4o_mini_dicl]
# type = "experimental_dynamic_in_context_learning"
# embedding_model = "openai::text-embedding-3-small"
# model = "openai::gpt-4o-mini-2024-07-18"
# k = 10
# system_instructions = "functions/extract_entities/initial_prompt/system_template.minijinja"
# json_mode = "strict"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  METRICS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[metrics.exact_match]
type = "boolean"
level = "inference"
optimize = "max"

[metrics.jaccard_similarity]
type = "float"
level = "inference"
optimize = "max"

[metrics.valid_output]
type = "boolean"
level = "inference"
optimize = "max"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                 EVALUATIONS                                │
# └────────────────────────────────────────────────────────────────────────────┘

[evaluations.extract_entities_eval]
type = "static"
function_name = "extract_entities"

[evaluations.extract_entities_eval.evaluators.exact_match]
type = "exact_match"

[evaluations.extract_entities_eval.evaluators.judge_improvement]
type = "llm_judge"
output_type = "float"
include = { reference_output = true }
optimize = "max"
description = "Compares generated output against reference output for NER quality. Scores: 1 (better), 0 (similar), -1 (worse). Prioritizes correctness, schema compliance, completeness, and clarity."

[evaluations.extract_entities_eval.evaluators.judge_improvement.variants.baseline]
type = "chat_completion"
model = "openai::gpt-5-mini"
system_instructions = "evaluations/extract_entities/judge_improvement/system_instructions.txt"
json_mode = "strict"
