# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                 FUNCTIONS                                  │
# └────────────────────────────────────────────────────────────────────────────┘

[functions.extract_entities]
type = "json"
output_schema = "functions/extract_entities/output_schema.json"

[functions.extract_entities.variants.gpt_4o]
type = "chat_completion"
model = "openai::gpt-4o-2024-08-06"
system_template = "functions/extract_entities/initial_prompt/system_template.minijinja"
json_mode = "strict"

[functions.extract_entities.variants.gpt_4o_mini]
type = "chat_completion"
model = "openai::gpt-4o-mini-2024-07-18"
system_template = "functions/extract_entities/initial_prompt/system_template.minijinja"
json_mode = "strict"

# TODO: Once you've fine-tuned your model, add it here like the commented example below

# [functions.extract_entities.variants.gpt_4o_mini_fine_tuned]
# type = "chat_completion"
# model = "openai::ft:gpt-4o-mini-2024-07-18:xxxxxxxx::xxxxxxxx"
# system_template = "functions/extract_entities/initial_prompt/system_template.minijinja"
# json_mode = "strict"

# [functions.extract_entities.variants.gpt_4o_mini_dicl]
# type = "experimental_dynamic_in_context_learning"
# embedding_model = "openai::text-embedding-3-small"
# model = "openai::gpt-4o-mini-2024-07-18"
# k = 10
# system_instructions = "functions/extract_entities/initial_prompt/system_template.minijinja"
# json_mode = "strict"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  METRICS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[metrics.exact_match]
type = "boolean"
level = "inference"
optimize = "max"

[metrics.jaccard_similarity]
type = "float"
level = "inference"
optimize = "max"

[metrics.valid_output]
type = "boolean"
level = "inference"
optimize = "max"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                EVALUATIONS                                 │
# └────────────────────────────────────────────────────────────────────────────┘

[evaluations.extract_entities_llm_judge]
type = "inference"
function_name = "extract_entities"
description = "LLM judge-based evaluation for entity extraction quality"

[evaluations.extract_entities_llm_judge.evaluators.ner_quality_judge]
type = "llm_judge"
input_format = "serialized"
output_type = "float"
optimize = "max"
cutoff = 0.7
include = { reference_output = true}

[evaluations.extract_entities_llm_judge.evaluators.ner_quality_judge.variants.default]
type = "chat_completion"
model = "openai::gpt-4o-mini"
temperature = 0.0
json_mode = "strict"
system_instructions = "evaluations/extract_entities_llm_judge/evaluators/ner_quality_judge/variants/default/system_instructions.txt"
retries = { num_retries = 0, max_delay_s = 10.0 }
