# TensorZero Configuration
nameOverride: ""
fullnameOverride: ""

# Gateway Configuration
gateway:
  replicaCount: 1
  command: ["gateway"]
  args:
    - --config-file=/app/config/tensorzero.toml

  image:
    repository: tensorzero/gateway
    tag: latest
    pullPolicy: IfNotPresent

  service:
    type: ClusterIP
    port: 3000

  additionalEnv:
    secretName: "tensorzero-secret"
    keys:
      - name: TENSORZERO_CLICKHOUSE_URL
        key: TENSORZERO_CLICKHOUSE_URL
      - name: TENSORZERO_GATEWAY_URL
        key: TENSORZERO_GATEWAY_URL
      - name: OPENAI_API_KEY
        key: OPENAI_API_KEY
      # TODO: include other model provider credentials as needed

  resources:
    limits:
      cpu: 2000m
      memory: 4096Mi
    requests:
      cpu: 2000m
      memory: 4096Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}
  ingress:
    enabled: true
    hosts:
      - host: tensorzero-gateway.local # TODO: change this to the correct host
        paths:
          - path: /
            pathType: Prefix

# UI Configuration
ui:
  deploy: true # TODO: change this to false if you don't want to deploy the UI
  replicaCount: 1
  image:
    repository: tensorzero/ui
    tag: latest
    pullPolicy: IfNotPresent

  service:
    type: ClusterIP
    port: 4000

  additionalEnv:
    secretName: "tensorzero-secret"
    keys:
      - name: TENSORZERO_CLICKHOUSE_URL
        key: TENSORZERO_CLICKHOUSE_URL
      - name: TENSORZERO_GATEWAY_URL
        key: TENSORZERO_GATEWAY_URL

  resources:
    limits:
      cpu: 1000m
      memory: 1024Mi
    requests:
      cpu: 500m
      memory: 512Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}

  ingress:
    enabled: true
    hosts:
      - host: tensorzero-ui.local # TODO: change this to the correct host
        paths:
          - path: /
            pathType: Prefix

# TensorZero Configuration
configMap:
  data:
    tensorzero.toml: |
      [functions.my_function_name]
      type = "chat"

      [functions.my_function_name.variants.my_variant_name]
      type = "chat_completion"
      model = "openai::gpt-4o-mini"
