{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00dfeb0",
   "metadata": {},
   "source": [
    "## Example: NER + SFT + DPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73cb0ae",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "767c156c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import toml\n",
    "from clickhouse_connect import get_client\n",
    "from tensorzero import AsyncTensorZeroGateway, InferenceResponse\n",
    "from IPython.display import clear_output\n",
    "from minijinja import Environment\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "703152d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"config/tensorzero.toml\"\n",
    "FUNCTION_NAME = \"extract_entities\"\n",
    "TEMPLATE_VARIANT_NAME = \"gpt_4o_mini\"\n",
    "MODEL_NAME = \"gpt-4o-2024-08-06\"\n",
    "VAL_FRACTION = 0.2\n",
    "MAX_SAMPLES = 500\n",
    "\n",
    "\n",
    "TENSORZERO_GATEWAY_URL = \"http://localhost:3000\"\n",
    "\n",
    "\n",
    "\n",
    "assert \"OPENAI_API_KEY\" in os.environ\n",
    "assert \"TENSORZERO_CLICKHOUSE_URL\" in os.environ\n",
    "\n",
    "openai_client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bd53c",
   "metadata": {},
   "source": [
    "### STEP 1: SFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42b3fd",
   "metadata": {},
   "source": [
    "### STEP 2: DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fc2f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(CONFIG_PATH)\n",
    "#config = json.load(open(CONFIG_PATH)) if CONFIG_PATH.endswith(\".json\") else {}\n",
    "\n",
    "assert config_path.exists(), f\"{CONFIG_PATH} does not exist\"\n",
    "assert config_path.is_file(), f\"{CONFIG_PATH} is not a file\"\n",
    "\n",
    "with config_path.open(\"r\") as f:\n",
    "    config = toml.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d242a6a5",
   "metadata": {},
   "source": [
    "Ensure that the function and variant being fine-tuned are present in the provided config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c1c9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"functions\" in config, \"No `[functions]` section found in config\"\n",
    "assert \"variants\" in config[\"functions\"][FUNCTION_NAME], (\n",
    "    f\"No variants section found for function `{FUNCTION_NAME}`\"\n",
    ")\n",
    "assert TEMPLATE_VARIANT_NAME in config[\"functions\"][FUNCTION_NAME][\"variants\"], (\n",
    "    f\"No variant named `{TEMPLATE_VARIANT_NAME}` found in function `{FUNCTION_NAME}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d01cc42",
   "metadata": {},
   "source": [
    "Retrieve the configuration for the variant with the templates we will use for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "247f9f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_type = config[\"functions\"][FUNCTION_NAME][\"type\"]\n",
    "variant = config[\"functions\"][FUNCTION_NAME][\"variants\"][TEMPLATE_VARIANT_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63881094",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {}\n",
    "\n",
    "if \"assistant_template\" in variant:\n",
    "    assistant_template_path = config_path.parent / variant[\"assistant_template\"]\n",
    "    with assistant_template_path.open(\"r\") as f:\n",
    "        templates[\"assistant\"] = f.read()\n",
    "\n",
    "if \"system_template\" in variant:\n",
    "    system_template_path = config_path.parent / variant[\"system_template\"]\n",
    "    with system_template_path.open(\"r\") as f:\n",
    "        templates[\"system\"] = f.read()\n",
    "\n",
    "if \"user_template\" in variant:\n",
    "    user_template_path = config_path.parent / variant[\"user_template\"]\n",
    "    with user_template_path.open(\"r\") as f:\n",
    "        templates[\"user\"] = f.read()\n",
    "\n",
    "env = Environment(templates=templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28ede1",
   "metadata": {},
   "source": [
    "Initialize the ClickHouse client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d462c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"TENSORZERO_CLICKHOUSE_URL\" in os.environ, (\n",
    "    \"TENSORZERO_CLICKHOUSE_URL environment variable not set\"\n",
    ")\n",
    "\n",
    "clickhouse_client = get_client(dsn=os.environ[\"TENSORZERO_CLICKHOUSE_URL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9052e80",
   "metadata": {},
   "source": [
    "Determine the ClickHouse table name for the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ec0d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_table_name = {\"json\": \"JsonInference\"}.get(function_type)\n",
    "\n",
    "if inference_table_name is None:\n",
    "    raise ValueError(f\"Unsupported function type: {function_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9663f9e9",
   "metadata": {},
   "source": [
    "Query ClickHouse for inference, feedback, and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Query ClickHouse for data\n",
    "# ---------------------------\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    i.variant_name AS variant,\n",
    "    i.episode_id AS episode_id,\n",
    "    i.input AS input,\n",
    "    i.output AS non_preferred_output,\n",
    "    d.value AS preferred_output\n",
    "FROM\n",
    "    JsonInference AS i\n",
    "INNER JOIN DemonstrationFeedback AS d ON i.id = d.inference_id\n",
    "WHERE\n",
    "    (i.function_name = %(function_name)s)\n",
    "LIMIT %(max_samples)s\n",
    "\"\"\"\n",
    "\n",
    "params = {\"function_name\": FUNCTION_NAME, \"max_samples\": MAX_SAMPLES}\n",
    "df = clickhouse_client.query_df(query, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e6b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dpo(example):\n",
    "    return {\n",
    "        \"input\": {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": example[\"prompt\"]}]\n",
    "        },\n",
    "        \"preferred_output\": [{\"role\": \"assistant\", \"content\": example[\"completion\"]}],\n",
    "        \"non_preferred_output\": [{\"role\": \"assistant\", \"content\": json.loads(example[\"non_preferred_output\"])[\"raw\"]}]\n",
    "    }\n",
    "\n",
    "dpo_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        input_data = json.loads(row[\"input\"])\n",
    "        output_data = json.loads(row[\"preferred_output\"])\n",
    "        prompt = input_data[\"messages\"][-1][\"content\"]\n",
    "        completion = output_data[\"raw\"]\n",
    "        dpo_rows.append({\"prompt\": prompt, \"completion\": completion, \"non_preferred_output\": row[\"non_preferred_output\"]})\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "dpo_dataset = [format_dpo(r) for r in dpo_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da88ab92",
   "metadata": {},
   "source": [
    "## (Data format would go here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d92c31",
   "metadata": {},
   "source": [
    "Upload the prepared datasets to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b55b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dataset_to_openai(df, openai_client) -> str:\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".jsonl\", delete=False) as f:\n",
    "        for item in df[\"openai_messages\"]:\n",
    "            json.dump(item, f)\n",
    "            f.write(\"\\n\")\n",
    "        f.flush()\n",
    "\n",
    "        print(f\"File persisted on path [{f.name}]\")\n",
    "\n",
    "        with open(f.name, \"rb\") as file:\n",
    "            file_object = openai_client.files.create(file=file, purpose=\"fine-tune\")\n",
    "\n",
    "        return file_object.id\n",
    "\n",
    "\n",
    "openai_client = openai.OpenAI()\n",
    "\n",
    "dpo_fine_tuning_object_id = upload_dataset_to_openai(train_df, openai_client)\n",
    "val_file_object_id = upload_dataset_to_openai(val_df, openai_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6242ec9",
   "metadata": {},
   "source": [
    "Launch the fine-tuning job and wait for it to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb70fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_job = openai_client.fine_tuning.jobs.create(\n",
    "    training_file=dpo_fine_tuning_object_id,\n",
    "    validation_file=val_file_object_id,\n",
    "    model=MODEL_NAME,\n",
    "    method={\n",
    "        \"type\": \"dpo\",\n",
    "        \"dpo\": {\n",
    "            \"hyperparameters\": {\"beta\": 0.2},\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    try:\n",
    "        job_status = openai_client.fine_tuning.jobs.retrieve(fine_tuning_job.id)\n",
    "        pprint(job_status.to_dict())\n",
    "        if job_status.status in (\"succeeded\", \"failed\", \"cancelled\"):\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "print(f\"The fine-tuning job has compeleted with result {job_status.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe01ba2",
   "metadata": {},
   "source": [
    "TODO: Adding the fine-tuned model to the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = job_status.fine_tuned_model\n",
    "model_config = {\n",
    "    \"models\": {\n",
    "        fine_tuned_model: {\n",
    "            \"routing\": [\"openai\"],\n",
    "            \"providers\": {\"openai\": {\"type\": \"openai\", \"model_name\": fine_tuned_model}},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(toml.dumps(model_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba9979",
   "metadata": {},
   "source": [
    "TODO: Adding a new variant to your function to use the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3576241",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_config = {\n",
    "    \"type\": \"chat_completion\",\n",
    "    \"model\": fine_tuned_model,\n",
    "}\n",
    "\n",
    "system_template = variant.get(\"system_template\")\n",
    "if system_template:\n",
    "    variant_config[\"system_template\"] = system_template\n",
    "\n",
    "user_template = variant.get(\"user_template\")\n",
    "if user_template:\n",
    "    variant_config[\"user_template\"] = user_template\n",
    "\n",
    "assistant_template = variant.get(\"assistant_template\")\n",
    "if assistant_template:\n",
    "    variant_config[\"assistant_template\"] = assistant_template\n",
    "\n",
    "full_variant_config = {\n",
    "    \"functions\": {FUNCTION_NAME: {\"variants\": {fine_tuned_model: variant_config}}}\n",
    "}\n",
    "\n",
    "print(toml.dumps(full_variant_config))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
