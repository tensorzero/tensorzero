# TensorZero configuration file for the `haiku_hidden_preferences` example.

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  GENERAL                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[gateway]
bind_address = "0.0.0.0:3000"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                   MODELS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[models."llama3.1-8b-instruct"]
routing = ["together"]

[models."llama3.1-8b-instruct".providers.together]
type = "together"
model_name = "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                 FUNCTIONS                                  │
# └────────────────────────────────────────────────────────────────────────────┘

[functions.solve_math_problem]
type = "chat"


[functions.solve_math_problem.variants.llama-8b-baseline]
weight = 1
type = "chat_completion"
model = "llama3.1-8b-instruct"
system_template = "functions/solve_math_problem/llama-8b-baseline/system.minijinja"


# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  METRICS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[metrics.correct]
type = "boolean"
level = "inference"
optimize = "max"
